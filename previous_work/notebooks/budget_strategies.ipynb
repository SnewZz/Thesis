{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats as st\n",
    "import itertools\n",
    "import operator\n",
    "\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get currently working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# load functions from other notebooks\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb').replace(\"\\\\\", \"/\")\n",
    "%run $helpers_file\n",
    "\n",
    "# # load the autoreload extension\n",
    "# %load_ext autoreload\n",
    "# # Set extension to reload modules every time before executing code\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['../spotlight_ext']:\n",
    "    module_path = os.path.abspath(os.path.join(base_dir, p))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "random_state = np.random.RandomState(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## !jupyter nbconvert budget_strategies.ipynb --no-input --no-prompt --to pdf\n",
    "# os.system(\"jupyter nbconvert budget_strategies.ipynb --no-input --no-prompt --to pdf\")\n",
    "# os.system(\"jupyter nbconvert budget_strategies.ipynb --config ~/.jupyter/jupyter_nbconvert_config.py --to slides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare models/datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the pretrained models \"lstm\" (entire_model_1m_20interactions.pt) and \"pooling\" (pooling_model_1m_20interactions.pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implicit_model = load_model('implicit_factorization')\n",
    "lstm_model = load_model(model_type='entire')\n",
    "pooling_model = load_model('pooling')\n",
    "\n",
    "pretrained_models = {\n",
    "    'lstm': lstm_model,\n",
    "    'pooling': pooling_model,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the dataset Movielens with the variant 1M. Then divide it into a training set and a testing set. And finally this code limits the length of each sequence of elements in the 2 sets to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "\n",
    "# get dataset \n",
    "dataset = get_movielens_dataset(variant='1M')\n",
    "train, test = random_train_test_split(dataset, random_state=random_state)\n",
    "\n",
    "max_sequence_length = 20\n",
    "train = train.to_sequence(max_sequence_length=max_sequence_length)\n",
    "test = test.to_sequence(max_sequence_length=max_sequence_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Compute the similarity matrix based on cosine similarity\n",
    "#### 2. Compute the similarity matrix based on Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453cf3bc6d014748835eb2693540b421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pooling_sims_matrix = gpu_embeddings_to_cosine_similarity_matrix(\n",
    "    pooling_model._net.item_embeddings(\n",
    "        torch.arange(0, dataset.num_items, dtype=torch.int64)\n",
    "    )).detach().numpy()\n",
    "\n",
    "jaccard_sims_matrix = compute_sim_matrix(dataset, 'jaccard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various implemented Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseStrategy:\n",
    "    class_name = None\n",
    "\n",
    "    def __init__(self, item, interactions, max_length, init_budget, negative_mode,  model=None, random_pick=False):\n",
    "\n",
    "        self.target_item = item\n",
    "        self.original_interactions = interactions\n",
    "        self.max_length = max_length\n",
    "        self.visited_ = set()\n",
    "        self.model = model\n",
    "        self.last_comb_cost = 0\n",
    "        self.random_pick = random_pick\n",
    "        self.top_k = 10\n",
    "        self.negative_mode = negative_mode\n",
    "        self.budget = init_budget\n",
    "\n",
    "    #Must be implemented by subclasses. Used to select the next item to recommand to the user.\n",
    "    def next_comb(self, reverse=False):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \n",
    "    def _get_pos(self, number):\n",
    "        bits = []\n",
    "        for i, c in enumerate(bin(number)[:1:-1], 1):\n",
    "            if c == '0':\n",
    "                bits.append(i)\n",
    "        return bits\n",
    "\n",
    "    #Method to reset the costs of the last recommended combination\n",
    "    def reset_costs(self):\n",
    "        self.last_comb_cost = 0\n",
    "\n",
    "    #Returns the initial budget\n",
    "    def get_init_budget(self):\n",
    "        return self.budget"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSelection\n",
    "#### This class is a subclass of the \"BaseStrategy\" class, representing a random item selection strategy for the sequential recommendation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSelection(BaseStrategy):\n",
    "    class_name = 'Random'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, negative_mode):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, negative_mode)\n",
    "\n",
    "    # The _next_item method selects a random integer between 1 and the maximum length of the sequence. \n",
    "    # It checks if the integer is already in the set of visited integers, and if it is, selects another integer until a non-visited integer is found. \n",
    "    # Finally, the selected integer is added to the set of visited integers, and returned.\n",
    "    def _next_item(self):\n",
    "        self.budget -= 1\n",
    "        if self.negative_mode:\n",
    "            return self._next_item_negative_mode()\n",
    "        else:\n",
    "            return self._next_item_positive_mode()\n",
    "    \n",
    "    def _next_item_negative_mode(self):\n",
    "        length = self.dataset.num_items\n",
    "        number = random.sample(range(1, pow(2, length)), 1)[0]\n",
    "        while number in self.visited_ or self.original_interactions:\n",
    "            number = random.sample(range(1, pow(2, length)), 1)[0]\n",
    "        self.visited_.add(number)\n",
    "        return number\n",
    "\n",
    "    def _next_item_positive_mode(self):\n",
    "        length = self.max_length\n",
    "        number = random.sample(range(1, pow(2, length)), 1)[0]\n",
    "        while number in self.visited_:\n",
    "            number = random.sample(range(1, pow(2, length)), 1)[0]\n",
    "        self.visited_.add(number)\n",
    "        return number\n",
    "    #The next_comb method generates a new sequence by removing items at positions indicated by the binary digits of the integer returned \n",
    "    # by _next_item from the original sequence of interactions. \n",
    "    # The resulting sequence, along with the current budget, is returned as a tuple.\n",
    "    def next_comb(self, reverse=False):\n",
    "        number = self._next_item()\n",
    "\n",
    "        bits = self._get_pos(number)\n",
    "        if self.negative_mode : \n",
    "            seq = np.add(self.original_interactions, bits)\n",
    "        else : \n",
    "            seq = np.delete(self.original_interactions, bits)\n",
    "\n",
    "        return (seq, self.budget)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MostSimilarSelection\n",
    "#### This class is a subclass of the \"BaseStrategy\" class, it is used to select the most similar item to the current item based on the similarity measure defined by the sim_type parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MostSimilarSelection(BaseStrategy):\n",
    "    class_name = 'Sim-Matrix'\n",
    "\n",
    "    supported_sim_matrix = {\n",
    "        'pooling': pooling_sims_matrix,\n",
    "        'jaccard': jaccard_sims_matrix\n",
    "    }\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, negative_mode, sim_type='pooling'):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, negative_mode)\n",
    "\n",
    "        self.visited_.add(0)\n",
    "        self.reverse_checks = []\n",
    "        self.is_materialized = False\n",
    "\n",
    "        self._get_sim_ranking(sim_type)\n",
    "\n",
    "    # The next_comb method returns the next combination of items to be recommended. \n",
    "    # If reverse is True, it returns a combination that has been previously seen, otherwise it returns a new combination. The method also updates the visited set.\n",
    "    def next_comb(self, reverse=False):\n",
    "        if reverse:\n",
    "            self._materialize_list()\n",
    "            selected_item_indices = self.reverse_checks.pop(\n",
    "                random.randrange(len(self.reverse_checks)) if self.random_pick else 0\n",
    "            ) if len(self.reverse_checks) else []\n",
    "        else:\n",
    "            self.visited_.add(max(self.visited_) + 1)\n",
    "            selected_item_indices = np.where(np.isin(\n",
    "                self.rk_items,\n",
    "                list(set(self.rk_items).difference(set(self.visited_)))\n",
    "            ))[0]\n",
    "        seq = self.original_interactions[selected_item_indices] if len(selected_item_indices) else None\n",
    "        return seq\n",
    "    \n",
    "    # The _get_sim_ranking method calculates the similarity ranking between the target item and the other items in the interaction history \n",
    "    # based on the similarity measure defined by the sim_type parameter.\n",
    "    def _get_sim_ranking(self, sim_type):\n",
    "        if self.negative_mode:\n",
    "            ranked_items = st.rankdata(-self.supported_sim_matrix[sim_type][self.target_item, self.original_interactions])\n",
    "        else:\n",
    "            ranked_items = st.rankdata(self.supported_sim_matrix[sim_type][self.target_item, self.original_interactions])\n",
    "        self.rk_items = self.max_length - ranked_items + 1\n",
    "\n",
    "    # The _materialize_list method generates a list of all possible combinations of items that have not been visited, \n",
    "    # except for the empty combination and the combination that contains all items. \n",
    "    # It stores these combinations in the reverse_checks list to be used later in the next_comb method when reverse is True.\n",
    "    def _materialize_list(self):\n",
    "        if not self.is_materialized:\n",
    "            psize = len(self.visited_) - 1  # do not consider initial added zero value\n",
    "            # do not take account none/all excluded interacted items\n",
    "            prods = sorted(list(map(list, itertools.product([0, 1], repeat=psize)))[1:-1], key=sum)\n",
    "#             last_item_indices = np.where(np.isin(\n",
    "#                 self.rk_items,\n",
    "#                 list(set(self.rk_items).difference(set(self.visited_)))\n",
    "#             ))\n",
    "\n",
    "            lvisited_ = np.asarray(list(self.visited_))[1:]\n",
    "            for p in prods:\n",
    "                self.reverse_checks.append(np.where(np.isin(\n",
    "                    self.rk_items,\n",
    "                    list(set(self.rk_items).difference(lvisited_[np.nonzero(np.multiply(p, lvisited_))])))\n",
    "                ))\n",
    "\n",
    "            self.is_materialized = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MostSimilarSelectionByJaccard\n",
    "#### This class inherits from the MostSimilarSelection class. This class specifies the jaccard matrix method as similarity measure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MostSimilarSelectionByJaccard(MostSimilarSelection):\n",
    "    class_name = 'Jaccard-on-Sim-Matrix'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model, 'jaccard')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomMostSimilarSelection\n",
    "#### This class inherits from the MostSimilarSelection class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class RandomMostSimilarSelection(MostSimilarSelection):\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.random_pick = True \n",
    "        #The random_pick attribute is used in the parent class's next_comb method to determine whether to pick a random item from the list \n",
    "        # of reverse checks or pick the first one. When random_pick is True, a random item is picked."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LossSimilarSelection\n",
    "#### This class inherits frome the BaseStrategy class. This class defines a search strategy for selecting items based on their similarity to previously selected items, while also considering their loss (difference between predicted and actual values) in a ranking problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossSimilarSelection(BaseStrategy):\n",
    "    class_name = 'BFS'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, early_term=False):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model)\n",
    "\n",
    "        self.q = Queue()\n",
    "        self.q.enqueue(([False] * len(self.original_interactions), StaticVars.INT_MAX, 0))\n",
    "\n",
    "        self.thres = len(self.original_interactions) + 1\n",
    "        self.early_termination = early_term\n",
    "\n",
    "    # Helper : This method is called whenever a solution is found for the current \n",
    "    # mask of the items. It computes the loss of the solution and updates the queue \n",
    "    # accordingly.\n",
    "    def _update_queue(self, is_solved):\n",
    "        self.compute_loss(is_solved)\n",
    "\n",
    "    # Helper : \n",
    "    def _next_item(self):\n",
    "        mask, t_score, is_solved = self.q.dequeue()\n",
    "        while self.early_termination and sum(mask) == self.thres:\n",
    "            q_data = self.q.dequeue()\n",
    "            if q_data is None: break\n",
    "\n",
    "            mask, t_score, is_solved = q_data\n",
    "\n",
    "        if is_solved == 2:\n",
    "            t_score, kth_score = self.get_score(mask)\n",
    "\n",
    "            if (t_score / kth_score) < 1: self.thres = sum(mask)\n",
    "\n",
    "        return (is_solved, mask, self.budget)\n",
    "\n",
    "    # The next_comb method returns the next combination of items and the remaining budget.\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "\n",
    "        if self.q.size() > 0:\n",
    "            solved_flag, item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "            self._update_queue(solved_flag)\n",
    "        else: self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)\n",
    "\n",
    "    # This method computes the loss of the solution. If the solution is not yet solved, it searches for the next combination of items \n",
    "    # to evaluate by calling the search method. \n",
    "    # If the solution is solved, it searches for the previous combination of items by calling the search method with forward=False.\n",
    "    def compute_loss(self, is_solved=False):\n",
    "        self.last_comb_cost = 0\n",
    "\n",
    "        if not is_solved: self.search(forward=True, s=is_solved)\n",
    "        else: self.search(forward=False, s=is_solved)\n",
    "\n",
    "    def search(self, forward=True, s=False):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        valid_items = np.where(np.logical_not(m_mask) if forward else m_mask)[0]\n",
    "        if valid_items.size > 1:\n",
    "            for idx in valid_items:\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "                self.add(m_mask, s)\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "    # The get_score method returns the score of an item based on its predicted value and its rank among the top-k items.\n",
    "    def get_score(self, d):\n",
    "        perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=d))\n",
    "\n",
    "        self.budget -= 1\n",
    "        # predict next top-k items about to be selected\n",
    "        preds = self.model.predict(perm)\n",
    "        if self.negative_mode:\n",
    "            preds[perm] = StaticVars.FLOAT_MAX\n",
    "        else:\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "        rk_data = st.rankdata(-preds, method='ordinal')\n",
    "\n",
    "        return (preds[self.target_item], preds[(rk_data == self.top_k).nonzero()][0])\n",
    "\n",
    "    # The add method adds a new combination to the queue and updates the visited set.\n",
    "    def add(self, d, s):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "            perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=d))\n",
    "\n",
    "            if not s:\n",
    "                t_score, kth_score = self.get_score(d)\n",
    "\n",
    "                if self.q.size() == 0: self.q.enqueue((d.copy(), t_score, 1 if (t_score / kth_score) < 1 else 0))\n",
    "\n",
    "                if t_score < self.q.get(0)[1]:  # get only the assigned score\n",
    "                    self.q.setter(0, (d.copy(), t_score, 1 if (t_score / kth_score) < 1 else 0))\n",
    "            else:\n",
    "                self.q.enqueue((d.copy(), StaticVars.INT_MAX, 2))\n",
    "\n",
    "            self.visited_.add(mask_to_int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DFSwithLossSelection\n",
    "#### This class inherits from LossSimilarSelection class. It performs a depth-first search with loss selection to recommend items to users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFSwithLossSelection(LossSimilarSelection):\n",
    "    class_name = 'DFS'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.candidate_solutions = Stack()\n",
    "\n",
    "    # Helper : it calculates the losses of each item in the interactions and sorts them in ascending order. \n",
    "    # It then sets the mask of the interactions array so that the item with the lowest loss is masked.\n",
    "    def _get_sim_ranking(self):\n",
    "        res = self.compute_losses()\n",
    "\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        if self.negative_mode:\n",
    "            m_mask[max(res, key=lambda item: item[0])[1]] = True\n",
    "        else:\n",
    "            m_mask[min(res, key=lambda item: item[0])[1]] = True\n",
    "        self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "    def _materialize_list(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "\n",
    "        if np.sum(m_mask) > 1:\n",
    "            res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "            for idx in sorted(res, key=lambda item: item[0], reverse=True):\n",
    "                m_mask[idx[1]] = False\n",
    "                self.candidate_solutions.push(m_mask.copy())\n",
    "                m_mask[idx[1]] = True\n",
    "\n",
    "        m_mask = self.candidate_solutions.pop()\n",
    "        while m_mask is not None and int(''.join(map(str, m_mask.astype(int))), 2) in self.visited_:\n",
    "            m_mask = self.candidate_solutions.pop()\n",
    "\n",
    "        self.visited_.add(0 if m_mask is None else int(''.join(map(str, m_mask.astype(int))), 2))\n",
    "        self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True if m_mask is None else m_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomLossSimilarSelection\n",
    "#### This class inherits from LossSimilarSelection class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class RandomLossSimilarSelection(LossSimilarSelection):\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.random_pick = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FixedRankingLossSimilarSelection\n",
    "##### This class is a subclass of LossSimilarSelection. It implements a strategy for selecting the next item based on the fixed ranking of the similarity between items. The strategy implemented by this class is to recommend items in a fixed order based on their similarity score. The order is determined by the ranking of the similarity matrix. The method next_comb is used to retrieve the next combination of items in the fixed order. It selects the next item based on a precomputed fixed ranking of the items in the candidate list, which is obtained by sorting the items according to their similarity loss. The next item to be removed is the one with the highest rank. This means that the sequence of items to be removed is deterministic and fixed in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class FixedRankingLossSimilarSelection(LossSimilarSelection):\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.rk_items = []\n",
    "        self._get_sim_ranking()\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        if reverse:\n",
    "            self._materialize_list()\n",
    "        else:\n",
    "            m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "            m_mask[self.rk_items.pop(0)] = True\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return seq if len(seq) else None\n",
    "\n",
    "    def _get_sim_ranking(self):\n",
    "        res = self.compute_losses()\n",
    "\n",
    "        ranked_items = np.asarray(res).argsort(axis=0)\n",
    "        self.rk_items = [item[0] for item in ranked_items]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BestFSLossSelection \n",
    "#### This class inherits from LossSimilarSelection. It implements a strategy for selecting the best candidate solutions by using a best-first search algorithm. By using a best-first search strategy, this class is able to explore promising candidate solutions first and therefore is expected to find better solutions faster than other strategies like random selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import heapq as hq\n",
    "\n",
    "\n",
    "class BestFSLossSelection(LossSimilarSelection):\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.set = set()\n",
    "        self.tiebraker = itertools.count()\n",
    "\n",
    "    def _materialize_list(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "\n",
    "        if not self.is_materialized:\n",
    "            if np.sum(m_mask) > 1:\n",
    "                res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "                for idx in res:\n",
    "                    m_mask[idx[1]] = False\n",
    "                    self.reverse_checks.append((idx[0], next(self.tiebraker), m_mask.copy()))\n",
    "                    self.set.add(int(''.join(map(str, m_mask.copy().astype(int))), 2))\n",
    "                    m_mask[idx[1]] = True\n",
    "\n",
    "                hq.heapify(self.reverse_checks)\n",
    "\n",
    "            self.is_materialized = True\n",
    "\n",
    "        _, _, m_mask = hq.heappop(self.reverse_checks) if len(self.reverse_checks) > 0 else (None, None, True)\n",
    "        self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "        if np.sum(m_mask) > 1:\n",
    "            m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "            res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "            for idx in res:\n",
    "                m_mask[idx[1]] = False\n",
    "                self.add(m_mask.copy(), idx[0])\n",
    "                m_mask[idx[1]] = True\n",
    "\n",
    "    def add(self, d, pri):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if mask_to_int not in self.set:\n",
    "            hq.heappush(self.reverse_checks, (pri, next(self.tiebraker), d))\n",
    "            self.set.add(mask_to_int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TopDownBestFSLossSelection\n",
    "#### This class inherits from LossSimilarSelection class. The strategy implemented here is to select the most promising combinations of items in a top-down fashion based on their scores. The goal is probably to reduce the search space and speed up the selection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import heapq as hq\n",
    "\n",
    "\n",
    "class TopDownBestFSLossSelection(LossSimilarSelection):\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.best_score_per_cardinality = [StaticVars.FLOAT_MAX] * self.max_length\n",
    "        self.set = set()\n",
    "        self.tiebraker = itertools.count()\n",
    "\n",
    "    def set_score(self, cardinality, target_score, kth_score):\n",
    "        reverse_search = False\n",
    "        score = target_score / kth_score\n",
    "        if score < self.best_score_per_cardinality[cardinality]:\n",
    "            self.best_score_per_cardinality[cardinality] = score\n",
    "\n",
    "            if score > 1.0: reverse_search = True\n",
    "\n",
    "        return reverse_search\n",
    "\n",
    "    def _materialize_list(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "\n",
    "        if not self.is_materialized:\n",
    "            if np.sum(m_mask) > 1:\n",
    "                res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "                for idx in res:\n",
    "                    m_mask[idx[1]] = False\n",
    "                    self.reverse_checks.append((idx[0], next(self.tiebraker), m_mask.copy()))\n",
    "                    self.set.add(int(''.join(map(str, m_mask.copy().astype(int))), 2))\n",
    "                    m_mask[idx[1]] = True\n",
    "\n",
    "                hq.heapify(self.reverse_checks)\n",
    "\n",
    "            self.is_materialized = True\n",
    "\n",
    "        _, _, m_mask = hq.heappop(self.reverse_checks) if len(self.reverse_checks) > 0 else (None, None, True)\n",
    "        self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "        if np.sum(m_mask) > 1:\n",
    "            m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "            res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "            for idx in res:\n",
    "                m_mask[idx[1]] = False\n",
    "                self.add(m_mask.copy(), idx[0])\n",
    "                m_mask[idx[1]] = True\n",
    "\n",
    "    def add(self, d, pri):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if mask_to_int not in self.set:\n",
    "            hq.heappush(self.reverse_checks, (pri, next(self.tiebraker), d))\n",
    "            self.set.add(mask_to_int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DFSwithFixedRankingLossSelection\n",
    "#### It inherits from FixedRankingLossSimilarSelection. It provides a strategy for selecting items based on the fixed ranking loss similarity metric using a depth-first search algorithm. It generates the next combination of items to be considered for selection by either removing the first item from the ranking list or by materializing the list of all possible combinations of the remaining items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class DFSwithFixedRankingLossSelection(FixedRankingLossSimilarSelection):\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        if reverse:\n",
    "            self._materialize_list()\n",
    "        else:\n",
    "            m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "            m_mask[self.rk_items.pop(0)] = True\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return seq if len(seq) else None\n",
    "\n",
    "    def _materialize_list(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "\n",
    "        if np.sum(m_mask) > 1:\n",
    "            res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "            if not self.is_materialized:\n",
    "                for idx in sorted(res, key=lambda item: item[0]):\n",
    "                    m_mask[idx[1]] = False\n",
    "                    self.reverse_checks.append(m_mask.copy())\n",
    "                    m_mask[idx[1]] = True\n",
    "\n",
    "                self.is_materialized = True\n",
    "            else:\n",
    "                m_mask[min(res, key=lambda item: item[0])[1]] = False\n",
    "                self.reverse_checks.insert(0, m_mask)\n",
    "\n",
    "        m_mask = self.reverse_checks.pop(\n",
    "            random.randrange(len(self.reverse_checks)) if self.random_pick else 0\n",
    "        ) if len(self.reverse_checks) else True\n",
    "        self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BestFSFixedLossSelection\n",
    "#### It inherits from the FixedRankingLossSimilarSelection. The BestFSFixedLossSelection strategy is a selection strategy that uses a variation of the best-first search algorithm to select the next item in the recommendation sequence. The strategy starts by initializing a priority queue and a set to keep track of the explored states. Each state corresponds to a binary mask representing the items that have been selected so far. The priority queue is initialized with a single state that corresponds to an empty mask.\n",
    "\n",
    "#### At each step, the strategy materializes the current mask by computing the set of unmasked items and selecting the item that has the lowest loss. If the mask has not been explored before, the strategy adds it to the set of explored states, pushes it to the priority queue with a priority that is based on the loss of the selected item and a tie-breaking counter, and updates the best score for the current cardinality.\n",
    "\n",
    "#### If the mask has been explored before, the strategy does not add it to the priority queue again but updates the best score for the current cardinality if the current score is better. The strategy then selects the state with the highest priority from the priority queue and materializes it to select the next item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import heapq as hq\n",
    "\n",
    "\n",
    "class BestFSFixedLossSelection(FixedRankingLossSimilarSelection):\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.best_score_per_cardinality = [-StaticVars.FLOAT_MAX] * self.max_length\n",
    "        self.set = set()\n",
    "        self.tiebraker = itertools.count()\n",
    "\n",
    "#     is not currently used\n",
    "#     def set_score(self, cardinality, target_score, kth_score):\n",
    "#         is_updated = False\n",
    "#         if self.best_score_per_cardinality[cardinality] > (target_score / kth_score):\n",
    "#             self.best_score_per_cardinality[cardinality] = target_score / kth_score\n",
    "#             is_updated = True\n",
    "\n",
    "#         return is_updated\n",
    "\n",
    "    def _materialize_list(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "\n",
    "        if not self.is_materialized:\n",
    "            if np.sum(m_mask) > 1:\n",
    "                res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "                for idx in res:\n",
    "                    m_mask[idx[1]] = False\n",
    "                    self.reverse_checks.append((idx[0], next(self.tiebraker), m_mask.copy()))\n",
    "                    self.set.add(int(''.join(map(str, m_mask.copy().astype(int))), 2))\n",
    "                    m_mask[idx[1]] = True\n",
    "\n",
    "                hq.heapify(self.reverse_checks)\n",
    "\n",
    "            self.is_materialized = True\n",
    "\n",
    "        _, _, m_mask = hq.heappop(self.reverse_checks) if len(self.reverse_checks) > 0 else (None, None, True)\n",
    "        self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "        if np.sum(m_mask) > 1:\n",
    "            m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "            res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "            for idx in res:\n",
    "                m_mask[idx[1]] = False\n",
    "                self.add(m_mask.copy(), idx[0])\n",
    "                m_mask[idx[1]] = True\n",
    "\n",
    "    def add(self, d, pri):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if mask_to_int not in self.set:\n",
    "            hq.heappush(self.reverse_checks, (pri, next(self.tiebraker), d))\n",
    "            self.set.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiDirectionalSelection(BaseStrategy):\n",
    "    class_name = 'BiDirectional'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, weights=(1, 0), alpha=0.9, normalization='default'):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model)\n",
    "\n",
    "        self.tiebraker = itertools.count()\n",
    "        self.q = [(1, StaticVars.INT_MAX, next(self.tiebraker), [False] * len(self.original_interactions), self.budget)]\n",
    "        hq.heapify(self.q)\n",
    "\n",
    "#         self.w_loss, self.w_custom = weights if len(weights) == 2 else (1, 0)\n",
    "        self.alpha = alpha\n",
    "        self.norm = normalization\n",
    "\n",
    "    def _update_queue(self, is_solved):\n",
    "        self.compute_loss(is_solved)\n",
    "\n",
    "    def _next_item(self):\n",
    "        is_solved, _, _, mask, budget = hq.heappop(self.q)\n",
    "        return (is_solved, mask, budget)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "        if self.q:\n",
    "            solved_flag, item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "            self._update_queue(solved_flag)\n",
    "        else: self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)\n",
    "\n",
    "    def compute_loss(self, is_solved=False):\n",
    "        self.search(forward=True, s=is_solved)\n",
    "        self.search(forward=False, s=is_solved)\n",
    "\n",
    "    def search(self, forward=True, s=False):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        valid_items = np.where(np.logical_not(m_mask) if forward else m_mask)[0]\n",
    "        if valid_items.size > 1:\n",
    "            for idx in valid_items:\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "                self.add(m_mask, s)\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "    def get_custom_score(self, c):\n",
    "#         return self.w_custom * (c / self.max_length)\n",
    "        return c / self.max_length\n",
    "\n",
    "    def get_score(self, d):\n",
    "        self.budget -= 1\n",
    "\n",
    "        # predict next top-k items about to be selected\n",
    "        perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=d))\n",
    "        preds = self.model.predict(perm)\n",
    "\n",
    "        if self.norm == 'kth_norm':\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "            rk_data = st.rankdata(-preds, method='ordinal')\n",
    "\n",
    "            t_score = preds[self.target_item] / preds[(rk_data == self.top_k).nonzero()][0]\n",
    "        elif self.norm == 'rescale':\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "            rk_data = st.rankdata(-preds, method='ordinal')\n",
    "\n",
    "            max_val = rk_data[0]\n",
    "            min_val = rk_data[-1]\n",
    "            t_score = (max_val - preds[self.target_item]) / (max_val - min_val)\n",
    "        else:  # default case\n",
    "            tensor = F.softmax(torch.from_numpy(preds).float(), dim=0)\n",
    "            preds = tensor.numpy()\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "\n",
    "            t_score = preds[self.target_item]\n",
    "\n",
    "        return self.alpha * t_score + (1 - self.alpha) * self.get_custom_score(np.sum(d))\n",
    "\n",
    "    def add(self, d, s):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "            t_score = self.get_score(d)\n",
    "            hq.heappush(self.q, (int(not s), t_score, next(self.tiebraker), d.copy(), self.budget))\n",
    "\n",
    "            self.visited_.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class BruteForceSelection(BaseStrategy):\n",
    "    class_name = 'BruteForce'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model)\n",
    "\n",
    "        self.q = Queue()\n",
    "        self.q.enqueue(([False] * len(self.original_interactions), self.budget))\n",
    "\n",
    "    def _expand_queue(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        valid_items = np.where(np.logical_not(m_mask))[0]\n",
    "        if valid_items.size > 1:\n",
    "            for idx in valid_items:\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "                self.add(m_mask)\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "    def _next_item(self):\n",
    "        mask, budget = self.q.dequeue()\n",
    "        return (mask, budget)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "\n",
    "        if reverse: self.q.clear()\n",
    "\n",
    "        if self.q.size() > 0:\n",
    "            item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "            self._expand_queue()\n",
    "        else:\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)\n",
    "\n",
    "    def add(self, d):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "            self.budget -= 1\n",
    "            self.q.enqueue((d.copy(), self.budget))\n",
    "            self.visited_.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComboSelection(BiDirectionalSelection):\n",
    "    class_name = 'Combo'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, weights=(1, 0), alpha=0.9, normalization='default'):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model, weights, alpha, normalization)\n",
    "\n",
    "        self.alpha = 1\n",
    "\n",
    "        self.q_init = Queue()\n",
    "        self.q_init.enqueue((StaticVars.INT_MAX, [False] * len(self.original_interactions), self.budget))\n",
    "        self.init_queue()\n",
    "\n",
    "        self.tiebraker = itertools.count()\n",
    "        self.q = []\n",
    "        hq.heapify(self.q)\n",
    "\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def init_queue(self):\n",
    "        _, m_mask, budget = self.q_init.dequeue()\n",
    "        m_mask = np.asarray(m_mask)\n",
    "\n",
    "        valid_items = np.where(np.logical_not(m_mask))[0]\n",
    "        for idx in valid_items:\n",
    "            m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "            mask_to_int = int(''.join(map(str, m_mask.astype(int))), 2)\n",
    "            if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "                t_score = self.get_score(m_mask)\n",
    "                self.q_init.enqueue((t_score, m_mask.copy(), self.budget))\n",
    "\n",
    "                self.visited_.add(mask_to_int)\n",
    "\n",
    "            m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "        pair_combs = []\n",
    "        for c in itertools.combinations(range(len(self.original_interactions)), 2):\n",
    "            m = [False] * len(self.original_interactions)\n",
    "            m[c[0]], m[c[1]] = not m[c[0]], not m[c[1]]\n",
    "            pair_combs.append((self.q_init.get(c[0])[0] + self.q_init.get(c[1])[0], m.copy()))\n",
    "\n",
    "        pair_combs.sort(key=operator.itemgetter(0))\n",
    "        for c in pair_combs:\n",
    "            self.budget -= 1\n",
    "            self.q_init.enqueue((0, c[1], self.budget))\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "\n",
    "        if self.q_init.size() > 0:\n",
    "            s, item_mask, budget = self.q_init.dequeue()\n",
    "            item_mask = np.asarray(item_mask)\n",
    "            solved_flag = False\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "\n",
    "            self.add(item_mask, False)\n",
    "        elif self.q:\n",
    "            solved_flag, item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "\n",
    "            self._update_queue(solved_flag)\n",
    "        else: self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_backend_strategy(backend):\n",
    "    if 'random' == backend:\n",
    "        return RandomSelection\n",
    "    elif 'most_sim' == backend:\n",
    "        return MostSimilarSelection\n",
    "    elif 'most_sim_jaccard' == backend:\n",
    "        return MostSimilarSelectionByJaccard\n",
    "    elif 'bfs' == backend:\n",
    "        return LossSimilarSelection\n",
    "    elif 'random_most_sim' == backend:\n",
    "        return RandomMostSimilarSelection\n",
    "    elif 'random_loss_sim' == backend:\n",
    "        return RandomLossSimilarSelection\n",
    "    elif 'fixed_loss_sim' == backend:\n",
    "        return FixedRankingLossSimilarSelection\n",
    "    elif 'dfs_loss_sim' == backend:\n",
    "        return DFSwithLossSelection\n",
    "    elif 'dfs_fixed_loss_sim' == backend:\n",
    "        return DFSwithFixedRankingLossSelection\n",
    "    elif 'bestFS_loss' == backend:\n",
    "        return BestFSLossSelection\n",
    "    elif 'bestFS_fixed_loss' == backend:\n",
    "        return BestFSFixedLossSelection\n",
    "    elif 'topdown_loss' == backend:\n",
    "        return TopDownBestFSLossSelection\n",
    "    elif 'bidirectional' == backend:\n",
    "        return BiDirectionalSelection\n",
    "    elif 'brute_force' == backend:\n",
    "        return BruteForceSelection\n",
    "    elif 'combo' == backend:\n",
    "        return ComboSelection\n",
    "    else: print('Unknown strategy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution of implemented strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategies inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_applied = 'lstm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Random**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: Random\n",
      "<Sequence interactions dataset (13131 sequences x 20 sequence length)>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0db0ee759f40d78b424773906eeb33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id :  1\n",
      "user_id :  2\n",
      "user_id :  3\n",
      "user_id :  4\n",
      "user_id :  5\n",
      "[-0.         -0.4886701  -1.2704934  ...  1.4422629   0.21140254\n",
      "  0.10461938]\n",
      "items_interacted :  [230 257 359 130 358 329 372 227 324 301 253 239 107 305 266 315  60 331\n",
      " 123 357]\n",
      "user_id :  6\n",
      "user_id :  7\n",
      "user_id :  8\n",
      "[-0.        -1.7293239  0.7516235 ...  1.2451138  0.8454702  2.057247 ]\n",
      "items_interacted :  [384 461 236 478  86 457 511  60 323 443 360 473 472 514 456 481 119 450\n",
      " 453 444]\n",
      "user_id :  9\n",
      "[-0.         -0.01268113 -0.72315276 ...  1.8612478   1.2578342\n",
      "  0.7910427 ]\n",
      "items_interacted :  [ 24 105 126 523 268  22 337  40 506 318 317  90 539 227 273 114 549 323\n",
      " 529  94]\n",
      "user_id :  10\n",
      "[-0.         -2.4513376   0.45527014 ...  1.0769624   1.3857057\n",
      "  1.618092  ]\n",
      "items_interacted :  [539 734 647 759 742  20 592 569 563  22  42 612 671  15 547 613  11 662\n",
      " 435 660]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 10it [00:07,  1.27it/s]              \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\Thesis\\previous_work\\notebooks\\budget_strategies.ipynb Cell 47\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/Thesis/previous_work/notebooks/budget_strategies.ipynb#X64sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m backend \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrandom\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/Thesis/previous_work/notebooks/budget_strategies.ipynb#X64sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m random_cfs \u001b[39m=\u001b[39m [\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/Thesis/previous_work/notebooks/budget_strategies.ipynb#X64sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     _find_cfs(test, pretrained_models[\u001b[39m'\u001b[39;49m\u001b[39mlstm\u001b[39;49m\u001b[39m'\u001b[39;49m], get_backend_strategy(backend), [\u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m, \u001b[39m5\u001b[39;49m, \u001b[39m7\u001b[39;49m], no_users\u001b[39m=\u001b[39;49m\u001b[39m6000\u001b[39;49m, init_budget\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/Thesis/previous_work/notebooks/budget_strategies.ipynb#X64sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='random', init_budget=1000)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/Thesis/previous_work/notebooks/budget_strategies.ipynb#X64sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m ]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/Thesis/previous_work/notebooks/budget_strategies.ipynb#X64sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mstore\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrandom_cfs\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27548\\2801879085.py:100\u001b[0m, in \u001b[0;36m_find_cfs\u001b[1;34m(dataset, model, strategy_func, target_item_pos, no_users, init_budget, max_allowed_permutations, top_k, total_CFs, num_processes, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m         best_tot_loss_data[pos] \u001b[39m=\u001b[39m []\n\u001b[0;32m     99\u001b[0m         \u001b[39mfor\u001b[39;00m user_id \u001b[39min\u001b[39;00m trange(\u001b[39m1\u001b[39m, num_users \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39musers loop\u001b[39m\u001b[39m'\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 100\u001b[0m             best_tot_loss_data[pos]\u001b[39m.\u001b[39mextend(_retrieve_solutions((\n\u001b[0;32m    101\u001b[0m                 user_id, dataset, model, strategy_func, pos, init_budget, top_k, kwargs)))\n\u001b[0;32m    103\u001b[0m \u001b[39mreturn\u001b[39;00m best_tot_loss_data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27548\\2801879085.py:36\u001b[0m, in \u001b[0;36m_retrieve_solutions\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mif\u001b[39;00m perm \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mbreak\u001b[39;00m  \u001b[39m# there is no need to continue searching\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m# predict next top-k items about to be selected \u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m preds \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39;49mpredict(perm)\n\u001b[0;32m     37\u001b[0m preds[perm] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mStaticVars\u001b[39m.\u001b[39mFLOAT_MAX\n\u001b[0;32m     38\u001b[0m rk_data \u001b[39m=\u001b[39m st\u001b[39m.\u001b[39mrankdata(\u001b[39m-\u001b[39mpreds, method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mordinal\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\Thesis\\previous_work\\spotlight_ext\\spotlight\\sequence\\implicit.py:326\u001b[0m, in \u001b[0;36mImplicitSequenceModel.predict\u001b[1;34m(self, sequences, item_ids)\u001b[0m\n\u001b[0;32m    323\u001b[0m sequence_var \u001b[39m=\u001b[39m gpu(sequences, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_cuda)\n\u001b[0;32m    324\u001b[0m item_var \u001b[39m=\u001b[39m gpu(item_ids, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_cuda)\n\u001b[1;32m--> 326\u001b[0m _, sequence_representations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_net\u001b[39m.\u001b[39;49muser_representation(sequence_var)\n\u001b[0;32m    327\u001b[0m size \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(item_var),) \u001b[39m+\u001b[39m sequence_representations\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m:]\n\u001b[0;32m    328\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_net(sequence_representations\u001b[39m.\u001b[39mexpand(\u001b[39m*\u001b[39msize),\n\u001b[0;32m    329\u001b[0m                 item_var)\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\Thesis\\previous_work\\spotlight_ext\\spotlight\\sequence\\representations.py:224\u001b[0m, in \u001b[0;36mLSTMNet.user_representation\u001b[1;34m(self, item_sequences)\u001b[0m\n\u001b[0;32m    219\u001b[0m sequence_embeddings \u001b[39m=\u001b[39m (F\u001b[39m.\u001b[39mpad(sequence_embeddings,\n\u001b[0;32m    220\u001b[0m                              (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m))\n\u001b[0;32m    221\u001b[0m                        \u001b[39m.\u001b[39msqueeze(\u001b[39m3\u001b[39m))\n\u001b[0;32m    222\u001b[0m sequence_embeddings \u001b[39m=\u001b[39m sequence_embeddings\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m--> 224\u001b[0m user_representations, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(sequence_embeddings)\n\u001b[0;32m    225\u001b[0m user_representations \u001b[39m=\u001b[39m user_representations\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m    227\u001b[0m \u001b[39mreturn\u001b[39;00m user_representations[:, :, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], user_representations[:, :, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    811\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    813\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    815\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    816\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "backend = 'random'\n",
    "random_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='random', init_budget=1000)\n",
    "]\n",
    "\n",
    "%store random_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of item IDs in the dataset\n",
    "item_ids = list(dataset.item_ids)\n",
    "\n",
    "# Set the number of items you want to select (e.g., 20)\n",
    "num_items_to_select = 20\n",
    "\n",
    "# Randomly select 20 item IDs from the list\n",
    "selected_item_ids = random.sample(item_ids, num_items_to_select)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0 45  3  7 21  6 34 11 36]]\n",
      "[[  0   0 128 166 168 102  77  54 144 165 140  55 173  57  98  91 118  75\n",
      "  155 127]]\n",
      "[[  0   0   0   0   0   0   0   0   0 197 124 125 190 114 186 196  59 200\n",
      "  191 177]]\n",
      "{1: [1, 2467, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477, 2466, 2478, 2480, 2481, 2482, 2483, 2484, 2485], 2: [3492, 3600, 3601, 3602, 3004, 3603, 3010, 3573, 3610, 3611, 3469, 1806, 3616, 3226, 3655, 3654, 3653, 3621, 3380, 3638], 3: [1, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 2467, 2479, 2481, 2482, 2483, 2484, 2485, 2486]}\n"
     ]
    }
   ],
   "source": [
    "def find_best_items_with_jaccard(dataset, target_item, users, jaccard_sims_matrix, number_items=20):\n",
    "    \"\"\"\n",
    "    Find the top best \"number_items\" for each user that, when added to their interactions list,\n",
    "    have the highest Jaccard similarity to the target item based on the given similarity matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - users: List of user indices.\n",
    "    - jaccard_sims_matrix: Jaccard similarity matrix.\n",
    "    - user_interactions: Dictionary where keys are user indices and values are their interaction lists.\n",
    "    - number_items: The number of items to select for each user.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary where keys are user indices and values are lists of the top best items for each user.\n",
    "    \"\"\"\n",
    "    \n",
    "    best_items_for_users = {}\n",
    "\n",
    "    for user_index in users:\n",
    "        # Get the user's interactions and items not in interactions\n",
    "        user_interactions_list = dataset.sequences[dataset.user_ids == user_index]\n",
    "        \n",
    "        items_not_in_interactions = np.setdiff1d(range(jaccard_sims_matrix.shape[1]), user_interactions_list)\n",
    "        \n",
    "        print(user_interactions_list)\n",
    "\n",
    "        ranked_items = st.rankdata(jaccard_sims_matrix[user_interactions_list[0][target_item], items_not_in_interactions])\n",
    "\n",
    "        # Get the top best items\n",
    "        top_items_indices = np.argsort(ranked_items)[:number_items]\n",
    "\n",
    "        best_items = [list(items_not_in_interactions)[idx] for idx in top_items_indices]\n",
    "\n",
    "        best_items_for_users[user_index] = best_items\n",
    "\n",
    "    return best_items_for_users\n",
    "\n",
    "users_to_process = [1, 2, 3]  # Replace with your list of user indices\n",
    "best_items_jaccard = find_best_items_with_jaccard(test, 2, users_to_process, jaccard_sims_matrix, 20)\n",
    "print(best_items_jaccard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Most Similar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_on_embeddings_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], [3, 5, 7], no_users=500, backend='most_sim', init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='most_sim', init_budget=1000)\n",
    "]\n",
    "jaccard_on_embeddings_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], [3, 5, 7], no_users=500, backend='most_sim_jaccard', init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='most_sim_jaccard', init_budget=1000),\n",
    "]\n",
    "\n",
    "%store cosine_on_embeddings_cfs\n",
    "%store jaccard_on_embeddings_cfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilize ylosses for similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BFS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [10:02, 30.12s/it]              "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [16:37, 32.95s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [21:32, 31.92s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [24:55, 37.40s/it]\n",
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BFS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [07:38, 22.94s/it]              "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [12:35, 24.95s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [16:30, 24.51s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [19:19, 28.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'bfs_yloss_cfs' (list)\n"
     ]
    }
   ],
   "source": [
    "backend = 'bfs'\n",
    "bfs_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000, early_term=True),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='loss_sim', init_budget=1000)\n",
    "]\n",
    "\n",
    "%store bfs_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('Running BFS strategy with fixed ordering...')\n",
    "\n",
    "bfs_fixed_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], [3, 5, 7], no_users=500, backend='fixed_loss_sim', init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='fixed_loss_sim', init_budget=1000),\n",
    "]\n",
    "\n",
    "%store bfs_fixed_yloss_cfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilize similarities based on yloss with DFS backward search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: DFS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [00:28,  1.44s/it]              "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [00:45,  1.49s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [00:59,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'dfs_yloss_cfs' (list)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "backend='dfs_loss_sim'\n",
    "dfs_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [3, 5, 7], no_users=500, init_budget=1000),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='dfs_loss_sim', init_budget=1000)\n",
    "]\n",
    "\n",
    "%store dfs_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "backend='dfs_fixed_loss_sim'\n",
    "dfs_fixed_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [3, 5, 7], no_users=500, init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['pooling'], get_backend_strategy(backend), [3, 5, 7], no_users=500, init_budget=1000)\n",
    "]\n",
    "\n",
    "%store dfs_fixed_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "backend='bestFS_loss'\n",
    "bestfs_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [3, 5, 7], no_users=500, init_budget=1000),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='bestFS_loss', init_budget=1000)\n",
    "]\n",
    "\n",
    "%store bestfs_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print('Running BestFS strategy with fixed ordering...')\n",
    "\n",
    "bestfs_fixed_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], [3, 5, 7], no_users=500, backend='bestFS_fixed_loss', init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='bestFS_fixed_loss', init_budget=1000)\n",
    "]\n",
    "\n",
    "%store bestfs_fixed_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "backend='topdown_loss'\n",
    "topdown_bestfs_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [3, 5, 7], no_users=500, init_budget=1000),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='topdown_loss', init_budget=1000)\n",
    "]\n",
    "\n",
    "%store topdown_bestfs_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BiDirectional\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [1:44:19, 312.97s/it]           "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [3:28:41, 443.47s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f942fb4df897464b99d03a1d27a9c69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "target position loop: 40it [7:00:22, 630.56s/it]\n",
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BiDirectional\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [1:46:46, 320.32s/it]           "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [3:33:05, 452.67s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97590ebcd26646d2b3921216131ceed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "target position loop: 40it [7:11:45, 647.64s/it]\n",
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BiDirectional\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "target position loop: 20it [1:20:25, 241.30s/it]           "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [2:39:30, 338.44s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [3:58:44, 389.55s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [5:18:24, 477.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'bidirectional_cfs' (list)\n"
     ]
    }
   ],
   "source": [
    "backend='bidirectional'\n",
    "bidirectional_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000, alpha=1e-3, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000, alpha=0.5, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000, alpha=0.999, normalization='default'),\n",
    "]\n",
    "\n",
    "%store bidirectional_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BruteForce\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [2:59:30, 538.52s/it]           "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [4:11:08, 505.90s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [4:28:50, 385.98s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='users loop'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [4:33:42, 410.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'brute_force_cfs' (list)\n"
     ]
    }
   ],
   "source": [
    "backend='brute_force'\n",
    "brute_force_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=100000),\n",
    "]\n",
    "\n",
    "%store brute_force_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: Combo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [2:34:47, 464.38s/it]           "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "target position loop: 30it [4:57:44, 628.26s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [7:22:14, 717.36s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [9:48:58, 883.47s/it]\n",
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: Combo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46641deafb164ee6a03b42a96aa9043f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "target position loop: 30it [4:53:52, 623.89s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1732bb87c9439ab309944eba8113a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "target position loop: 40it [9:47:29, 881.24s/it]\n",
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: Combo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "target position loop: 20it [1:46:07, 318.37s/it]           "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [3:32:31, 451.70s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "target position loop: 40it [5:18:15, 519.91s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [7:05:47, 638.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'combo_cfs' (list)\n"
     ]
    }
   ],
   "source": [
    "backend='combo'\n",
    "combo_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000, alpha=1e-3, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000, alpha=0.5, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000, alpha=0.999, normalization='default'),\n",
    "]\n",
    "\n",
    "%store combo_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
