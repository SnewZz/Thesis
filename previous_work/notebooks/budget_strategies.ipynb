{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats as st\n",
    "import itertools\n",
    "import operator\n",
    "\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get currently working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# load functions from other notebooks\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb').replace(\"\\\\\", \"/\")\n",
    "%run $helpers_file\n",
    "\n",
    "# # load the autoreload extension\n",
    "# %load_ext autoreload\n",
    "# # Set extension to reload modules every time before executing code\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['../spotlight_ext']:\n",
    "    module_path = os.path.abspath(os.path.join(base_dir, p))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "random_state = np.random.RandomState(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## !jupyter nbconvert budget_strategies.ipynb --no-input --no-prompt --to pdf\n",
    "# os.system(\"jupyter nbconvert budget_strategies.ipynb --no-input --no-prompt --to pdf\")\n",
    "# os.system(\"jupyter nbconvert budget_strategies.ipynb --config ~/.jupyter/jupyter_nbconvert_config.py --to slides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare models/datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the pretrained models \"lstm\" (entire_model_1m_20interactions.pt) and \"pooling\" (pooling_model_1m_20interactions.pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implicit_model = load_model('implicit_factorization')\n",
    "lstm_model = load_model(model_type='entire')\n",
    "pooling_model = load_model('pooling')\n",
    "\n",
    "pretrained_models = {\n",
    "    'lstm': lstm_model,\n",
    "    'pooling': pooling_model,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the dataset Movielens with the variant 1M. Then divide it into a training set and a testing set. And finally this code limits the length of each sequence of elements in the 2 sets to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "\n",
    "# get dataset \n",
    "dataset = get_movielens_dataset(variant='1M')\n",
    "train, test = random_train_test_split(dataset, random_state=random_state)\n",
    "\n",
    "max_sequence_length = 20\n",
    "train = train.to_sequence(max_sequence_length=max_sequence_length)\n",
    "test = test.to_sequence(max_sequence_length=max_sequence_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Compute the similarity matrix based on cosine similarity\n",
    "#### 2. Compute the similarity matrix based on Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb7b8e049ef40868e0d7d14e8de312e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pooling_sims_matrix = gpu_embeddings_to_cosine_similarity_matrix(\n",
    "    pooling_model._net.item_embeddings(\n",
    "        torch.arange(0, dataset.num_items, dtype=torch.int64)\n",
    "    )).detach().numpy()\n",
    "\n",
    "jaccard_sims_matrix = compute_sim_matrix(dataset, 'jaccard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various implemented Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseStrategy:\n",
    "    class_name = None\n",
    "\n",
    "    def __init__(self, item, interactions, max_length, init_budget, model=None, random_pick=False):\n",
    "\n",
    "        self.target_item = item\n",
    "        self.original_interactions = interactions\n",
    "        self.max_length = max_length\n",
    "        self.visited_ = set()\n",
    "        self.model = model\n",
    "        self.last_comb_cost = 0\n",
    "        self.random_pick = random_pick\n",
    "        self.top_k = 10\n",
    "\n",
    "        self.budget = init_budget\n",
    "\n",
    "    #Must be implemented by subclasses. Used to select the next item to recommand to the user.\n",
    "    def next_comb(self, reverse=False):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \n",
    "    def _get_pos(self, number):\n",
    "        bits = []\n",
    "        for i, c in enumerate(bin(number)[:1:-1], 1):\n",
    "            if c == '0':\n",
    "                bits.append(i)\n",
    "        return bits\n",
    "\n",
    "    #Method to reset the costs of the last recommended combination\n",
    "    def reset_costs(self):\n",
    "        self.last_comb_cost = 0\n",
    "\n",
    "    #Returns the initial budget\n",
    "    def get_init_budget(self):\n",
    "        return self.budget"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSelection\n",
    "#### This class is a subclass of the \"BaseStrategy\" class, representing a random item selection strategy for the sequential recommendation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSelection(BaseStrategy):\n",
    "    class_name = 'Random'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget)\n",
    "\n",
    "    # The _next_item method selects a random integer between 1 and the maximum length of the sequence. \n",
    "    # It checks if the integer is already in the set of visited integers, and if it is, selects another integer until a non-visited integer is found. \n",
    "    # Finally, the selected integer is added to the set of visited integers, and returned.\n",
    "    def _next_item(self):\n",
    "        self.budget -= 1\n",
    "\n",
    "        #number = np.random.choice(np.setdiff1d(range(1, pow(2, self.max_length)), self.visited_))\n",
    "        number = random.sample(range(1, pow(2, self.max_length)), 1)[0]\n",
    "        while number in self.visited_:\n",
    "            number = random.sample(range(1, pow(2, self.max_length)), 1)[0]\n",
    "        self.visited_.add(number)\n",
    "        return number\n",
    "\n",
    "    #The next_comb method generates a new sequence by removing items at positions indicated by the binary digits of the integer returned \n",
    "    # by _next_item from the original sequence of interactions. \n",
    "    # The resulting sequence, along with the current budget, is returned as a tuple.\n",
    "    def next_comb(self, reverse=False):\n",
    "        number = self._next_item()\n",
    "\n",
    "        bits = self._get_pos(number)\n",
    "        seq = np.delete(self.original_interactions, bits)\n",
    "\n",
    "        return (seq, self.budget)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MostSimilarSelection\n",
    "#### This class is a subclass of the \"BaseStrategy\" class, it is used to select the most similar item to the current item based on the similarity measure defined by the sim_type parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MostSimilarSelection(BaseStrategy):\n",
    "    class_name = 'Sim-Matrix'\n",
    "\n",
    "    supported_sim_matrix = {\n",
    "        'pooling': pooling_sims_matrix,\n",
    "        'jaccard': jaccard_sims_matrix\n",
    "    }\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, model, sim_type='pooling'):\n",
    "        super().__init__(item, interactions, max_sequence_length)\n",
    "\n",
    "        self.visited_.add(0)\n",
    "        self.reverse_checks = []\n",
    "        self.is_materialized = False\n",
    "\n",
    "        self._get_sim_ranking(sim_type)\n",
    "\n",
    "    # The next_comb method returns the next combination of items to be recommended. \n",
    "    # If reverse is True, it returns a combination that has been previously seen, otherwise it returns a new combination. The method also updates the visited set.\n",
    "    def next_comb(self, reverse=False):\n",
    "        if reverse:\n",
    "            self._materialize_list()\n",
    "            selected_item_indices = self.reverse_checks.pop(\n",
    "                random.randrange(len(self.reverse_checks)) if self.random_pick else 0\n",
    "            ) if len(self.reverse_checks) else []\n",
    "        else:\n",
    "            self.visited_.add(max(self.visited_) + 1)\n",
    "            selected_item_indices = np.where(np.isin(\n",
    "                self.rk_items,\n",
    "                list(set(self.rk_items).difference(set(self.visited_)))\n",
    "            ))[0]\n",
    "        seq = self.original_interactions[selected_item_indices] if len(selected_item_indices) else None\n",
    "        return seq\n",
    "    \n",
    "    # The _get_sim_ranking method calculates the similarity ranking between the target item and the other items in the interaction history \n",
    "    # based on the similarity measure defined by the sim_type parameter.\n",
    "    def _get_sim_ranking(self, sim_type):\n",
    "        ranked_items = st.rankdata(self.supported_sim_matrix[sim_type][self.target_item, self.original_interactions])\n",
    "        self.rk_items = self.max_length - ranked_items + 1\n",
    "\n",
    "    # The _materialize_list method generates a list of all possible combinations of items that have not been visited, \n",
    "    # except for the empty combination and the combination that contains all items. \n",
    "    # It stores these combinations in the reverse_checks list to be used later in the next_comb method when reverse is True.\n",
    "    def _materialize_list(self):\n",
    "        if not self.is_materialized:\n",
    "            psize = len(self.visited_) - 1  # do not consider initial added zero value\n",
    "            # do not take account none/all excluded interacted items\n",
    "            prods = sorted(list(map(list, itertools.product([0, 1], repeat=psize)))[1:-1], key=sum)\n",
    "#             last_item_indices = np.where(np.isin(\n",
    "#                 self.rk_items,\n",
    "#                 list(set(self.rk_items).difference(set(self.visited_)))\n",
    "#             ))\n",
    "\n",
    "            lvisited_ = np.asarray(list(self.visited_))[1:]\n",
    "            for p in prods:\n",
    "                self.reverse_checks.append(np.where(np.isin(\n",
    "                    self.rk_items,\n",
    "                    list(set(self.rk_items).difference(lvisited_[np.nonzero(np.multiply(p, lvisited_))])))\n",
    "                ))\n",
    "\n",
    "            self.is_materialized = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MostSimilarSelectionByJaccard\n",
    "#### This class inherits from the MostSimilarSelection class. This class specifies the jaccard matrix method as similarity measure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MostSimilarSelectionByJaccard(MostSimilarSelection):\n",
    "    class_name = 'Jaccard-on-Sim-Matrix'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model, 'jaccard')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomMostSimilarSelection\n",
    "#### This class inherits from the MostSimilarSelection class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class RandomMostSimilarSelection(MostSimilarSelection):\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.random_pick = True \n",
    "        #The random_pick attribute is used in the parent class's next_comb method to determine whether to pick a random item from the list \n",
    "        # of reverse checks or pick the first one. When random_pick is True, a random item is picked."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LossSimilarSelection\n",
    "#### This class inherits frome the BaseStrategy class. This class defines a search strategy for selecting items based on their similarity to previously selected items, while also considering their loss (difference between predicted and actual values) in a ranking problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossSimilarSelection(BaseStrategy):\n",
    "    class_name = 'BFS'\n",
    "\n",
    "#     def next_comb(self, reverse=False):\n",
    "#         if reverse:\n",
    "#             self._materialize_list()\n",
    "#         else:\n",
    "#             self._get_sim_ranking()\n",
    "\n",
    "#         seq = np.ma.compressed(self.ma_arr)\n",
    "#         return seq if len(seq) else None\n",
    "\n",
    "#     def compute_losses(self, inv_mask=False):\n",
    "#         res = []\n",
    "#         self.last_comb_cost = 0\n",
    "\n",
    "#         m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "#         tmp_ma_arr = np.ma.masked_array(self.original_interactions, mask=np.logical_not(m_mask) if inv_mask else m_mask)\n",
    "#         for idx in tmp_ma_arr.nonzero()[0]:\n",
    "#             m_mask[idx] = not m_mask[idx]\n",
    "#             if np.any(np.invert(m_mask)):\n",
    "#                 perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=m_mask))\n",
    "\n",
    "#                 # predict next top-k items about to be selected\n",
    "#                 preds = self.model.predict(perm)\n",
    "#                 preds[perm] = -StaticVars.FLOAT_MAX\n",
    "#                 t_score = preds[self.target_item]\n",
    "#                 res.append([t_score, idx])\n",
    "\n",
    "#                 self.last_comb_cost += 1\n",
    "# #             else: res.append([0, -1])\n",
    "\n",
    "#             m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "#         return res\n",
    "\n",
    "#     def _materialize_list(self):\n",
    "#         if not self.is_materialized:\n",
    "#             m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "#             psize = sum(m_mask)\n",
    "#             # do not take account none/all excluded interacted items\n",
    "#             prods = sorted(list(map(list, itertools.product([0, 1], repeat=psize)))[1:-1], key=sum)\n",
    "\n",
    "#             lvisited_ = np.where(m_mask == True)[0]\n",
    "#             for p in prods:\n",
    "#                 curr_mask = np.ma.getmaskarray(self.ma_arr).copy()\n",
    "#                 curr_mask[lvisited_[np.nonzero(np.multiply(p, lvisited_))]] = 0\n",
    "\n",
    "#                 self.reverse_checks.append(curr_mask)\n",
    "\n",
    "#             self.is_materialized = True\n",
    "\n",
    "#         m_mask = self.reverse_checks.pop(\n",
    "#             random.randrange(len(self.reverse_checks)) if self.random_pick else 0\n",
    "#         ) if len(self.reverse_checks) else True\n",
    "#         self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, early_term=False):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model)\n",
    "\n",
    "        self.q = Queue()\n",
    "        self.q.enqueue(([False] * len(self.original_interactions), StaticVars.INT_MAX, 0))\n",
    "\n",
    "        self.thres = len(self.original_interactions) + 1\n",
    "        self.early_termination = early_term\n",
    "\n",
    "    # Helper : This method is called whenever a solution is found for the current mask of the items. It computes the loss of the solution and updates the queue accordingly.\n",
    "    def _update_queue(self, is_solved):\n",
    "        self.compute_loss(is_solved)\n",
    "\n",
    "    # Helper : \n",
    "    def _next_item(self):\n",
    "        mask, t_score, is_solved = self.q.dequeue()\n",
    "        while self.early_termination and sum(mask) == self.thres:\n",
    "            q_data = self.q.dequeue()\n",
    "            if q_data is None: break\n",
    "\n",
    "            mask, t_score, is_solved = q_data\n",
    "\n",
    "        if is_solved == 2:\n",
    "            t_score, kth_score = self.get_score(mask)\n",
    "\n",
    "            if (t_score / kth_score) < 1: self.thres = sum(mask)\n",
    "\n",
    "        return (is_solved, mask, self.budget)\n",
    "\n",
    "    # The next_comb method returns the next combination of items and the remaining budget.\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "\n",
    "        if self.q.size() > 0:\n",
    "            solved_flag, item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "            self._update_queue(solved_flag)\n",
    "        else: self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)\n",
    "\n",
    "    # This method computes the loss of the solution. If the solution is not yet solved, it searches for the next combination of items \n",
    "    # to evaluate by calling the search method. \n",
    "    # If the solution is solved, it searches for the previous combination of items by calling the search method with forward=False.\n",
    "    def compute_loss(self, is_solved=False):\n",
    "        self.last_comb_cost = 0\n",
    "\n",
    "        if not is_solved: self.search(forward=True, s=is_solved)\n",
    "        else: self.search(forward=False, s=is_solved)\n",
    "\n",
    "    def search(self, forward=True, s=False):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        valid_items = np.where(np.logical_not(m_mask) if forward else m_mask)[0]\n",
    "        if valid_items.size > 1:\n",
    "            for idx in valid_items:\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "                self.add(m_mask, s)\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "    # The get_score method returns the score of an item based on its predicted value and its rank among the top-k items.\n",
    "    def get_score(self, d):\n",
    "        perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=d))\n",
    "\n",
    "        self.budget -= 1\n",
    "        # predict next top-k items about to be selected\n",
    "        preds = self.model.predict(perm)\n",
    "        preds[perm] = -StaticVars.FLOAT_MAX\n",
    "        rk_data = st.rankdata(-preds, method='ordinal')\n",
    "\n",
    "        return (preds[self.target_item], preds[(rk_data == self.top_k).nonzero()][0])\n",
    "\n",
    "    # The add method adds a new combination to the queue and updates the visited set.\n",
    "    def add(self, d, s):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "            perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=d))\n",
    "\n",
    "            if not s:\n",
    "                t_score, kth_score = self.get_score(d)\n",
    "\n",
    "                if self.q.size() == 0: self.q.enqueue((d.copy(), t_score, 1 if (t_score / kth_score) < 1 else 0))\n",
    "\n",
    "                if t_score < self.q.get(0)[1]:  # get only the assigned score\n",
    "                    self.q.setter(0, (d.copy(), t_score, 1 if (t_score / kth_score) < 1 else 0))\n",
    "            else:\n",
    "                self.q.enqueue((d.copy(), StaticVars.INT_MAX, 2))\n",
    "\n",
    "            self.visited_.add(mask_to_int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DFSwithLossSelection\n",
    "#### This class inherits from LossSimilarSelection class. It performs a depth-first search with loss selection to recommend items to users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFSwithLossSelection(LossSimilarSelection):\n",
    "    class_name = 'DFS'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.candidate_solutions = Stack()\n",
    "\n",
    "    # Helper : it calculates the losses of each item in the interactions and sorts them in ascending order. \n",
    "    # It then sets the mask of the interactions array so that the item with the lowest loss is masked.\n",
    "    def _get_sim_ranking(self):\n",
    "        res = self.compute_losses()\n",
    "\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        m_mask[min(res, key=lambda item: item[0])[1]] = True\n",
    "        self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "    def _materialize_list(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "\n",
    "        if np.sum(m_mask) > 1:\n",
    "            res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "            for idx in sorted(res, key=lambda item: item[0], reverse=True):\n",
    "                m_mask[idx[1]] = False\n",
    "                self.candidate_solutions.push(m_mask.copy())\n",
    "                m_mask[idx[1]] = True\n",
    "\n",
    "        m_mask = self.candidate_solutions.pop()\n",
    "        while m_mask is not None and int(''.join(map(str, m_mask.astype(int))), 2) in self.visited_:\n",
    "            m_mask = self.candidate_solutions.pop()\n",
    "\n",
    "        self.visited_.add(0 if m_mask is None else int(''.join(map(str, m_mask.astype(int))), 2))\n",
    "        self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True if m_mask is None else m_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomLossSimilarSelection\n",
    "#### This class inherits from LossSimilarSelection class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class RandomLossSimilarSelection(LossSimilarSelection):\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.random_pick = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FixedRankingLossSimilarSelection\n",
    "##### This class is a subclass of LossSimilarSelection. It implements a strategy for selecting the next item based on the fixed ranking of the similarity between items. The strategy implemented by this class is to recommend items in a fixed order based on their similarity score. The order is determined by the ranking of the similarity matrix. The method next_comb is used to retrieve the next combination of items in the fixed order. It selects the next item based on a precomputed fixed ranking of the items in the candidate list, which is obtained by sorting the items according to their similarity loss. The next item to be removed is the one with the highest rank. This means that the sequence of items to be removed is deterministic and fixed in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class FixedRankingLossSimilarSelection(LossSimilarSelection):\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.rk_items = []\n",
    "        self._get_sim_ranking()\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        if reverse:\n",
    "            self._materialize_list()\n",
    "        else:\n",
    "            m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "            m_mask[self.rk_items.pop(0)] = True\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return seq if len(seq) else None\n",
    "\n",
    "    def _get_sim_ranking(self):\n",
    "        res = self.compute_losses()\n",
    "\n",
    "        ranked_items = np.asarray(res).argsort(axis=0)\n",
    "        self.rk_items = [item[0] for item in ranked_items]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BestFSLossSelection \n",
    "#### This class inherits from LossSimilarSelection. It implements a strategy for selecting the best candidate solutions by using a best-first search algorithm. By using a best-first search strategy, this class is able to explore promising candidate solutions first and therefore is expected to find better solutions faster than other strategies like random selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import heapq as hq\n",
    "\n",
    "\n",
    "class BestFSLossSelection(LossSimilarSelection):\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.set = set()\n",
    "        self.tiebraker = itertools.count()\n",
    "\n",
    "    def _materialize_list(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "\n",
    "        if not self.is_materialized:\n",
    "            if np.sum(m_mask) > 1:\n",
    "                res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "                for idx in res:\n",
    "                    m_mask[idx[1]] = False\n",
    "                    self.reverse_checks.append((idx[0], next(self.tiebraker), m_mask.copy()))\n",
    "                    self.set.add(int(''.join(map(str, m_mask.copy().astype(int))), 2))\n",
    "                    m_mask[idx[1]] = True\n",
    "\n",
    "                hq.heapify(self.reverse_checks)\n",
    "\n",
    "            self.is_materialized = True\n",
    "\n",
    "        _, _, m_mask = hq.heappop(self.reverse_checks) if len(self.reverse_checks) > 0 else (None, None, True)\n",
    "        self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "        if np.sum(m_mask) > 1:\n",
    "            m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "            res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "            for idx in res:\n",
    "                m_mask[idx[1]] = False\n",
    "                self.add(m_mask.copy(), idx[0])\n",
    "                m_mask[idx[1]] = True\n",
    "\n",
    "    def add(self, d, pri):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if mask_to_int not in self.set:\n",
    "            hq.heappush(self.reverse_checks, (pri, next(self.tiebraker), d))\n",
    "            self.set.add(mask_to_int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TopDownBestFSLossSelection\n",
    "#### This class inherits from LossSimilarSelection class. The strategy implemented here is to select the most promising combinations of items in a top-down fashion based on their scores. The goal is probably to reduce the search space and speed up the selection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import heapq as hq\n",
    "\n",
    "\n",
    "class TopDownBestFSLossSelection(LossSimilarSelection):\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.best_score_per_cardinality = [StaticVars.FLOAT_MAX] * self.max_length\n",
    "        self.set = set()\n",
    "        self.tiebraker = itertools.count()\n",
    "\n",
    "    def set_score(self, cardinality, target_score, kth_score):\n",
    "        reverse_search = False\n",
    "        score = target_score / kth_score\n",
    "        if score < self.best_score_per_cardinality[cardinality]:\n",
    "            self.best_score_per_cardinality[cardinality] = score\n",
    "\n",
    "            if score > 1.0: reverse_search = True\n",
    "\n",
    "        return reverse_search\n",
    "\n",
    "    def _materialize_list(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "\n",
    "        if not self.is_materialized:\n",
    "            if np.sum(m_mask) > 1:\n",
    "                res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "                for idx in res:\n",
    "                    m_mask[idx[1]] = False\n",
    "                    self.reverse_checks.append((idx[0], next(self.tiebraker), m_mask.copy()))\n",
    "                    self.set.add(int(''.join(map(str, m_mask.copy().astype(int))), 2))\n",
    "                    m_mask[idx[1]] = True\n",
    "\n",
    "                hq.heapify(self.reverse_checks)\n",
    "\n",
    "            self.is_materialized = True\n",
    "\n",
    "        _, _, m_mask = hq.heappop(self.reverse_checks) if len(self.reverse_checks) > 0 else (None, None, True)\n",
    "        self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "        if np.sum(m_mask) > 1:\n",
    "            m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "            res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "            for idx in res:\n",
    "                m_mask[idx[1]] = False\n",
    "                self.add(m_mask.copy(), idx[0])\n",
    "                m_mask[idx[1]] = True\n",
    "\n",
    "    def add(self, d, pri):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if mask_to_int not in self.set:\n",
    "            hq.heappush(self.reverse_checks, (pri, next(self.tiebraker), d))\n",
    "            self.set.add(mask_to_int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DFSwithFixedRankingLossSelection\n",
    "#### It inherits from FixedRankingLossSimilarSelection. It provides a strategy for selecting items based on the fixed ranking loss similarity metric using a depth-first search algorithm. It generates the next combination of items to be considered for selection by either removing the first item from the ranking list or by materializing the list of all possible combinations of the remaining items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class DFSwithFixedRankingLossSelection(FixedRankingLossSimilarSelection):\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        if reverse:\n",
    "            self._materialize_list()\n",
    "        else:\n",
    "            m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "            m_mask[self.rk_items.pop(0)] = True\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return seq if len(seq) else None\n",
    "\n",
    "    def _materialize_list(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "\n",
    "        if np.sum(m_mask) > 1:\n",
    "            res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "            if not self.is_materialized:\n",
    "                for idx in sorted(res, key=lambda item: item[0]):\n",
    "                    m_mask[idx[1]] = False\n",
    "                    self.reverse_checks.append(m_mask.copy())\n",
    "                    m_mask[idx[1]] = True\n",
    "\n",
    "                self.is_materialized = True\n",
    "            else:\n",
    "                m_mask[min(res, key=lambda item: item[0])[1]] = False\n",
    "                self.reverse_checks.insert(0, m_mask)\n",
    "\n",
    "        m_mask = self.reverse_checks.pop(\n",
    "            random.randrange(len(self.reverse_checks)) if self.random_pick else 0\n",
    "        ) if len(self.reverse_checks) else True\n",
    "        self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BestFSFixedLossSelection\n",
    "#### It inherits from the FixedRankingLossSimilarSelection. The BestFSFixedLossSelection strategy is a selection strategy that uses a variation of the best-first search algorithm to select the next item in the recommendation sequence. The strategy starts by initializing a priority queue and a set to keep track of the explored states. Each state corresponds to a binary mask representing the items that have been selected so far. The priority queue is initialized with a single state that corresponds to an empty mask.\n",
    "\n",
    "#### At each step, the strategy materializes the current mask by computing the set of unmasked items and selecting the item that has the lowest loss. If the mask has not been explored before, the strategy adds it to the set of explored states, pushes it to the priority queue with a priority that is based on the loss of the selected item and a tie-breaking counter, and updates the best score for the current cardinality.\n",
    "\n",
    "#### If the mask has been explored before, the strategy does not add it to the priority queue again but updates the best score for the current cardinality if the current score is better. The strategy then selects the state with the highest priority from the priority queue and materializes it to select the next item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import heapq as hq\n",
    "\n",
    "\n",
    "class BestFSFixedLossSelection(FixedRankingLossSimilarSelection):\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model)\n",
    "\n",
    "        self.best_score_per_cardinality = [-StaticVars.FLOAT_MAX] * self.max_length\n",
    "        self.set = set()\n",
    "        self.tiebraker = itertools.count()\n",
    "\n",
    "#     is not currently used\n",
    "#     def set_score(self, cardinality, target_score, kth_score):\n",
    "#         is_updated = False\n",
    "#         if self.best_score_per_cardinality[cardinality] > (target_score / kth_score):\n",
    "#             self.best_score_per_cardinality[cardinality] = target_score / kth_score\n",
    "#             is_updated = True\n",
    "\n",
    "#         return is_updated\n",
    "\n",
    "    def _materialize_list(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "\n",
    "        if not self.is_materialized:\n",
    "            if np.sum(m_mask) > 1:\n",
    "                res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "                for idx in res:\n",
    "                    m_mask[idx[1]] = False\n",
    "                    self.reverse_checks.append((idx[0], next(self.tiebraker), m_mask.copy()))\n",
    "                    self.set.add(int(''.join(map(str, m_mask.copy().astype(int))), 2))\n",
    "                    m_mask[idx[1]] = True\n",
    "\n",
    "                hq.heapify(self.reverse_checks)\n",
    "\n",
    "            self.is_materialized = True\n",
    "\n",
    "        _, _, m_mask = hq.heappop(self.reverse_checks) if len(self.reverse_checks) > 0 else (None, None, True)\n",
    "        self.ma_arr = np.ma.masked_array(self.original_interactions, mask=m_mask)\n",
    "\n",
    "        if np.sum(m_mask) > 1:\n",
    "            m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "            res = self.compute_losses(inv_mask=True)\n",
    "\n",
    "            for idx in res:\n",
    "                m_mask[idx[1]] = False\n",
    "                self.add(m_mask.copy(), idx[0])\n",
    "                m_mask[idx[1]] = True\n",
    "\n",
    "    def add(self, d, pri):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if mask_to_int not in self.set:\n",
    "            hq.heappush(self.reverse_checks, (pri, next(self.tiebraker), d))\n",
    "            self.set.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiDirectionalSelection(BaseStrategy):\n",
    "    class_name = 'BiDirectional'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, weights=(1, 0), alpha=0.9, normalization='default'):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model)\n",
    "\n",
    "        self.tiebraker = itertools.count()\n",
    "        self.q = [(1, StaticVars.INT_MAX, next(self.tiebraker), [False] * len(self.original_interactions), self.budget)]\n",
    "        hq.heapify(self.q)\n",
    "\n",
    "#         self.w_loss, self.w_custom = weights if len(weights) == 2 else (1, 0)\n",
    "        self.alpha = alpha\n",
    "        self.norm = normalization\n",
    "\n",
    "    def _update_queue(self, is_solved):\n",
    "        self.compute_loss(is_solved)\n",
    "\n",
    "    def _next_item(self):\n",
    "        is_solved, _, _, mask, budget = hq.heappop(self.q)\n",
    "        return (is_solved, mask, budget)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "        if self.q:\n",
    "            solved_flag, item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "            self._update_queue(solved_flag)\n",
    "        else: self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)\n",
    "\n",
    "    def compute_loss(self, is_solved=False):\n",
    "        self.search(forward=True, s=is_solved)\n",
    "        self.search(forward=False, s=is_solved)\n",
    "\n",
    "    def search(self, forward=True, s=False):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        valid_items = np.where(np.logical_not(m_mask) if forward else m_mask)[0]\n",
    "        if valid_items.size > 1:\n",
    "            for idx in valid_items:\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "                self.add(m_mask, s)\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "    def get_custom_score(self, c):\n",
    "#         return self.w_custom * (c / self.max_length)\n",
    "        return c / self.max_length\n",
    "\n",
    "    def get_score(self, d):\n",
    "        self.budget -= 1\n",
    "\n",
    "        # predict next top-k items about to be selected\n",
    "        perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=d))\n",
    "        preds = self.model.predict(perm)\n",
    "\n",
    "        if self.norm == 'kth_norm':\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "            rk_data = st.rankdata(-preds, method='ordinal')\n",
    "\n",
    "            t_score = preds[self.target_item] / preds[(rk_data == self.top_k).nonzero()][0]\n",
    "        elif self.norm == 'rescale':\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "            rk_data = st.rankdata(-preds, method='ordinal')\n",
    "\n",
    "            max_val = rk_data[0]\n",
    "            min_val = rk_data[-1]\n",
    "            t_score = (max_val - preds[self.target_item]) / (max_val - min_val)\n",
    "        else:  # default case\n",
    "            tensor = F.softmax(torch.from_numpy(preds).float(), dim=0)\n",
    "            preds = tensor.numpy()\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "\n",
    "            t_score = preds[self.target_item]\n",
    "\n",
    "        return self.alpha * t_score + (1 - self.alpha) * self.get_custom_score(np.sum(d))\n",
    "\n",
    "    def add(self, d, s):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "            t_score = self.get_score(d)\n",
    "            hq.heappush(self.q, (int(not s), t_score, next(self.tiebraker), d.copy(), self.budget))\n",
    "\n",
    "            self.visited_.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class BruteForceSelection(BaseStrategy):\n",
    "    class_name = 'BruteForce'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model)\n",
    "\n",
    "        self.q = Queue()\n",
    "        self.q.enqueue(([False] * len(self.original_interactions), self.budget))\n",
    "\n",
    "    def _expand_queue(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        valid_items = np.where(np.logical_not(m_mask))[0]\n",
    "        if valid_items.size > 1:\n",
    "            for idx in valid_items:\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "                self.add(m_mask)\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "    def _next_item(self):\n",
    "        mask, budget = self.q.dequeue()\n",
    "        return (mask, budget)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "\n",
    "        if reverse: self.q.clear()\n",
    "\n",
    "        if self.q.size() > 0:\n",
    "            item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "            self._expand_queue()\n",
    "        else:\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)\n",
    "\n",
    "    def add(self, d):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "            self.budget -= 1\n",
    "            self.q.enqueue((d.copy(), self.budget))\n",
    "            self.visited_.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComboSelection(BiDirectionalSelection):\n",
    "    class_name = 'Combo'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, weights=(1, 0), alpha=0.9, normalization='default'):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model, weights, alpha, normalization)\n",
    "\n",
    "        self.alpha = 1\n",
    "\n",
    "        self.q_init = Queue()\n",
    "        self.q_init.enqueue((StaticVars.INT_MAX, [False] * len(self.original_interactions), self.budget))\n",
    "        self.init_queue()\n",
    "\n",
    "        self.tiebraker = itertools.count()\n",
    "        self.q = []\n",
    "        hq.heapify(self.q)\n",
    "\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def init_queue(self):\n",
    "        _, m_mask, budget = self.q_init.dequeue()\n",
    "        m_mask = np.asarray(m_mask)\n",
    "\n",
    "        valid_items = np.where(np.logical_not(m_mask))[0]\n",
    "        for idx in valid_items:\n",
    "            m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "            mask_to_int = int(''.join(map(str, m_mask.astype(int))), 2)\n",
    "            if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "                t_score = self.get_score(m_mask)\n",
    "                self.q_init.enqueue((t_score, m_mask.copy(), self.budget))\n",
    "\n",
    "                self.visited_.add(mask_to_int)\n",
    "\n",
    "            m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "        pair_combs = []\n",
    "        for c in itertools.combinations(range(len(self.original_interactions)), 2):\n",
    "            m = [False] * len(self.original_interactions)\n",
    "            m[c[0]], m[c[1]] = not m[c[0]], not m[c[1]]\n",
    "            pair_combs.append((self.q_init.get(c[0])[0] + self.q_init.get(c[1])[0], m.copy()))\n",
    "\n",
    "        pair_combs.sort(key=operator.itemgetter(0))\n",
    "        for c in pair_combs:\n",
    "            self.budget -= 1\n",
    "            self.q_init.enqueue((0, c[1], self.budget))\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "\n",
    "        if self.q_init.size() > 0:\n",
    "            s, item_mask, budget = self.q_init.dequeue()\n",
    "            item_mask = np.asarray(item_mask)\n",
    "            solved_flag = False\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "\n",
    "            self.add(item_mask, False)\n",
    "        elif self.q:\n",
    "            solved_flag, item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "\n",
    "            self._update_queue(solved_flag)\n",
    "        else: self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_backend_strategy(backend):\n",
    "    if 'random' == backend:\n",
    "        return RandomSelection\n",
    "    elif 'most_sim' == backend:\n",
    "        return MostSimilarSelection\n",
    "    elif 'most_sim_jaccard' == backend:\n",
    "        return MostSimilarSelectionByJaccard\n",
    "    elif 'bfs' == backend:\n",
    "        return LossSimilarSelection\n",
    "    elif 'random_most_sim' == backend:\n",
    "        return RandomMostSimilarSelection\n",
    "    elif 'random_loss_sim' == backend:\n",
    "        return RandomLossSimilarSelection\n",
    "    elif 'fixed_loss_sim' == backend:\n",
    "        return FixedRankingLossSimilarSelection\n",
    "    elif 'dfs_loss_sim' == backend:\n",
    "        return DFSwithLossSelection\n",
    "    elif 'dfs_fixed_loss_sim' == backend:\n",
    "        return DFSwithFixedRankingLossSelection\n",
    "    elif 'bestFS_loss' == backend:\n",
    "        return BestFSLossSelection\n",
    "    elif 'bestFS_fixed_loss' == backend:\n",
    "        return BestFSFixedLossSelection\n",
    "    elif 'topdown_loss' == backend:\n",
    "        return TopDownBestFSLossSelection\n",
    "    elif 'bidirectional' == backend:\n",
    "        return BiDirectionalSelection\n",
    "    elif 'brute_force' == backend:\n",
    "        return BruteForceSelection\n",
    "    elif 'combo' == backend:\n",
    "        return ComboSelection\n",
    "    else: print('Unknown strategy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution of implemented strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategies inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_applied = 'lstm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Random**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = 'random'\n",
    "random_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='random', init_budget=1000)\n",
    "]\n",
    "\n",
    "%store random_cfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Most Similar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend='most_sim'\n",
    "\n",
    "cosine_on_embeddings_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [3, 5, 7], no_users=500, init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['pooling'], get_backend_strategy(backend), [3, 5, 7], no_users=500,  init_budget=1000)\n",
    "]\n",
    "\n",
    "backend='most_sim_jaccard'\n",
    "\n",
    "jaccard_on_embeddings_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [3, 5, 7], no_users=500, init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['pooling'], get_backend_strategy(backend), [3, 5, 7], no_users=500, init_budget=1000),\n",
    "]\n",
    "\n",
    "%store cosine_on_embeddings_cfs\n",
    "%store jaccard_on_embeddings_cfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilize ylosses for similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "backend = 'bfs'\n",
    "bfs_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000, early_term=True),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='loss_sim', init_budget=1000)\n",
    "]\n",
    "\n",
    "%store bfs_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BFS strategy with fixed ordering...\n",
      "The backend used is: BFS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4dc184808db4b3a911f173e521e7642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 10it [00:02,  3.42it/s]              \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 5 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\original_testing\\Thesis\\previous_work\\notebooks\\budget_strategies.ipynb Cell 52\u001b[0m line \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y102sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mRunning BFS strategy with fixed ordering...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y102sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m backend\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfixed_loss_sim\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y102sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m bfs_fixed_yloss_cfs \u001b[39m=\u001b[39m [\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y102sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     _find_cfs(test, pretrained_models[\u001b[39m'\u001b[39;49m\u001b[39mlstm\u001b[39;49m\u001b[39m'\u001b[39;49m], get_backend_strategy(backend), [\u001b[39m3\u001b[39;49m], no_users\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, init_budget\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y102sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     _find_cfs(test, pretrained_models[\u001b[39m'\u001b[39m\u001b[39mpooling\u001b[39m\u001b[39m'\u001b[39m], get_backend_strategy(backend), [\u001b[39m3\u001b[39m], no_users\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m, init_budget\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y102sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y102sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mstore\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbfs_fixed_yloss_cfs\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5028\\2050766523.py:87\u001b[0m, in \u001b[0;36m_find_cfs\u001b[1;34m(dataset, model, strategy_func, target_item_pos, no_users, init_budget, max_allowed_permutations, top_k, total_CFs, num_processes, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m             best_tot_loss_data[pos] \u001b[39m=\u001b[39m []\n\u001b[0;32m     85\u001b[0m             \u001b[39mfor\u001b[39;00m user_id \u001b[39min\u001b[39;00m trange(\u001b[39m1\u001b[39m, num_users \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39musers loop\u001b[39m\u001b[39m'\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):  \u001b[39m# dataset.num_users):\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     \u001b[39m#                 best_tot_loss_data[pos].append(_total_loss)\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m                 best_tot_loss_data[pos]\u001b[39m.\u001b[39mextend(_retrieve_solutions((\n\u001b[0;32m     88\u001b[0m                     user_id, dataset, model, strategy_func, pos, init_budget, top_k, kwargs)))\n\u001b[0;32m     91\u001b[0m \u001b[39m#         pool = Pool(processes=min(num_processes, cpu_count() - 1, 4), initargs=(RLock(),), initializer=tqdm.set_lock)\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39m#         with Pool(processes=min(num_processes, cpu_count() - 1, 2), initializer=init, initargs=(l,)) as pool:\u001b[39;00m\n\u001b[0;32m     93\u001b[0m     \u001b[39m#         jobs = [pool.apply_async(_retrieve_solutions, args=((n,dataset,model,strategy_func,pos,init_budget,top_k,kwargs),)) \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m#                 )), total=num_users))\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[39m# #                 r = list(tqdm(p.imap(_foo, range(30)), total=30))\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m best_tot_loss_data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5028\\2050766523.py:21\u001b[0m, in \u001b[0;36m_retrieve_solutions\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     19\u001b[0m search_info \u001b[39m=\u001b[39m InteractionsInfo(user_id, target_item, items_interacted, init_budget)\n\u001b[0;32m     20\u001b[0m loss \u001b[39m=\u001b[39m ComputeLoss(target_item, items_interacted, top_k)\n\u001b[1;32m---> 21\u001b[0m strategy \u001b[39m=\u001b[39m sf(target_item, items_interacted, d\u001b[39m.\u001b[39;49mmax_sequence_length, init_budget, m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     23\u001b[0m counter \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     24\u001b[0m budget \u001b[39m=\u001b[39m strategy\u001b[39m.\u001b[39mget_init_budget()\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes 5 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "print('Running BFS strategy with fixed ordering...')\n",
    "\n",
    "backend='fixed_loss_sim'\n",
    "\n",
    "bfs_fixed_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [3], no_users=30, init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['pooling'], get_backend_strategy(backend), [3], no_users=30, init_budget=1000),\n",
    "]\n",
    "\n",
    "%store bfs_fixed_yloss_cfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilize similarities based on yloss with DFS backward search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "backend='dfs_loss_sim'\n",
    "dfs_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [3, 5, 7], no_users=500, init_budget=1000),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='dfs_loss_sim', init_budget=1000)\n",
    "]\n",
    "\n",
    "%store dfs_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "backend='dfs_fixed_loss_sim'\n",
    "dfs_fixed_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [3, 5, 7], no_users=500, init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['pooling'], get_backend_strategy(backend), [3, 5, 7], no_users=500, init_budget=1000)\n",
    "]\n",
    "\n",
    "%store dfs_fixed_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "backend='bestFS_loss'\n",
    "bestfs_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [3, 5, 7], no_users=500, init_budget=1000),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='bestFS_loss', init_budget=1000)\n",
    "]\n",
    "\n",
    "%store bestfs_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print('Running BestFS strategy with fixed ordering...')\n",
    "\n",
    "bestfs_fixed_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], [3, 5, 7], no_users=500, backend='bestFS_fixed_loss', init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='bestFS_fixed_loss', init_budget=1000)\n",
    "]\n",
    "\n",
    "%store bestfs_fixed_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "backend='topdown_loss'\n",
    "topdown_bestfs_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [3, 5, 7], no_users=500, init_budget=1000),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='topdown_loss', init_budget=1000)\n",
    "]\n",
    "\n",
    "%store topdown_bestfs_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BiDirectional\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e41c6d158e47ef8141757300fd57da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [00:59,  2.96s/it]              "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c72efab7379446eaa5f18e239fb840b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [01:52,  3.93s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22a539b7c174c56982edb9559d17ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [02:46,  4.50s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c21e14612474fb99a448a9e80417c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [03:40,  5.51s/it]\n",
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BiDirectional\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947c4794428649d8bbe2732266beaf1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [01:09,  3.45s/it]              "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e37ac6afc804835aa2016970eeff592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [01:17,  3.89s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\original_testing\\Thesis\\previous_work\\notebooks\\budget_strategies.ipynb Cell 59\u001b[0m line \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m backend\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbidirectional\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m bidirectional_cfs \u001b[39m=\u001b[39m [\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     _find_cfs(test, pretrained_models[\u001b[39m'\u001b[39m\u001b[39mlstm\u001b[39m\u001b[39m'\u001b[39m], get_backend_strategy(backend), [\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m7\u001b[39m], no_users\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m, init_budget\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m, normalization\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     _find_cfs(test, pretrained_models[\u001b[39m'\u001b[39;49m\u001b[39mlstm\u001b[39;49m\u001b[39m'\u001b[39;49m], get_backend_strategy(backend), [\u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m, \u001b[39m5\u001b[39;49m, \u001b[39m7\u001b[39;49m], no_users\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, init_budget\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, alpha\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m, normalization\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdefault\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     _find_cfs(test, pretrained_models[\u001b[39m'\u001b[39m\u001b[39mlstm\u001b[39m\u001b[39m'\u001b[39m], get_backend_strategy(backend), [\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m7\u001b[39m], no_users\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m, init_budget\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m0.999\u001b[39m, normalization\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mstore\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbidirectional_cfs\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5028\\2050766523.py:87\u001b[0m, in \u001b[0;36m_find_cfs\u001b[1;34m(dataset, model, strategy_func, target_item_pos, no_users, init_budget, max_allowed_permutations, top_k, total_CFs, num_processes, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m             best_tot_loss_data[pos] \u001b[39m=\u001b[39m []\n\u001b[0;32m     85\u001b[0m             \u001b[39mfor\u001b[39;00m user_id \u001b[39min\u001b[39;00m trange(\u001b[39m1\u001b[39m, num_users \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39musers loop\u001b[39m\u001b[39m'\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):  \u001b[39m# dataset.num_users):\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     \u001b[39m#                 best_tot_loss_data[pos].append(_total_loss)\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m                 best_tot_loss_data[pos]\u001b[39m.\u001b[39mextend(_retrieve_solutions((\n\u001b[0;32m     88\u001b[0m                     user_id, dataset, model, strategy_func, pos, init_budget, top_k, kwargs)))\n\u001b[0;32m     91\u001b[0m \u001b[39m#         pool = Pool(processes=min(num_processes, cpu_count() - 1, 4), initargs=(RLock(),), initializer=tqdm.set_lock)\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39m#         with Pool(processes=min(num_processes, cpu_count() - 1, 2), initializer=init, initargs=(l,)) as pool:\u001b[39;00m\n\u001b[0;32m     93\u001b[0m     \u001b[39m#         jobs = [pool.apply_async(_retrieve_solutions, args=((n,dataset,model,strategy_func,pos,init_budget,top_k,kwargs),)) \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m#                 )), total=num_users))\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[39m# #                 r = list(tqdm(p.imap(_foo, range(30)), total=30))\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m best_tot_loss_data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5028\\2050766523.py:26\u001b[0m, in \u001b[0;36m_retrieve_solutions\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     24\u001b[0m budget \u001b[39m=\u001b[39m strategy\u001b[39m.\u001b[39mget_init_budget()\n\u001b[0;32m     25\u001b[0m \u001b[39mwhile\u001b[39;00m budget \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 26\u001b[0m     perm, curr_budget \u001b[39m=\u001b[39m strategy\u001b[39m.\u001b[39;49mnext_comb(reverse\u001b[39m=\u001b[39;49msearch_info\u001b[39m.\u001b[39;49msolution_found)\n\u001b[0;32m     28\u001b[0m     \u001b[39mif\u001b[39;00m perm \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mbreak\u001b[39;00m  \u001b[39m# there is no need to continue searching\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[39m# predict next top-k items about to be selected\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\original_testing\\Thesis\\previous_work\\notebooks\\budget_strategies.ipynb Cell 59\u001b[0m line \u001b[0;36mBiDirectionalSelection.next_comb\u001b[1;34m(self, reverse)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     solved_flag, item_mask, budget \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_item()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mma_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mmasked_array(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_interactions, mask\u001b[39m=\u001b[39mitem_mask\u001b[39m.\u001b[39mcopy())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_queue(solved_flag)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39melse\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mma_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mmasked_array(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_interactions, mask\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m seq \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mcompressed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mma_arr)\n",
      "\u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\original_testing\\Thesis\\previous_work\\notebooks\\budget_strategies.ipynb Cell 59\u001b[0m line \u001b[0;36mBiDirectionalSelection._update_queue\u001b[1;34m(self, is_solved)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_queue\u001b[39m(\u001b[39mself\u001b[39m, is_solved):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(is_solved)\n",
      "\u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\original_testing\\Thesis\\previous_work\\notebooks\\budget_strategies.ipynb Cell 59\u001b[0m line \u001b[0;36mBiDirectionalSelection.compute_loss\u001b[1;34m(self, is_solved)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_loss\u001b[39m(\u001b[39mself\u001b[39m, is_solved\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msearch(forward\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, s\u001b[39m=\u001b[39;49mis_solved)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch(forward\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, s\u001b[39m=\u001b[39mis_solved)\n",
      "\u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\original_testing\\Thesis\\previous_work\\notebooks\\budget_strategies.ipynb Cell 59\u001b[0m line \u001b[0;36mBiDirectionalSelection.search\u001b[1;34m(self, forward, s)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m valid_items:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     m_mask[idx] \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m m_mask[idx]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd(m_mask, s)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     m_mask[idx] \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m m_mask[idx]\n",
      "\u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\original_testing\\Thesis\\previous_work\\notebooks\\budget_strategies.ipynb Cell 59\u001b[0m line \u001b[0;36mBiDirectionalSelection.add\u001b[1;34m(self, d, s)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m mask_to_int \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mmap\u001b[39m(\u001b[39mstr\u001b[39m, d\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m))), \u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m \u001b[39mif\u001b[39;00m (mask_to_int \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisited_) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbudget \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     t_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_score(d)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     hq\u001b[39m.\u001b[39mheappush(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq, (\u001b[39mint\u001b[39m(\u001b[39mnot\u001b[39;00m s), t_score, \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtiebraker), d\u001b[39m.\u001b[39mcopy(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbudget))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisited_\u001b[39m.\u001b[39madd(mask_to_int)\n",
      "\u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\original_testing\\Thesis\\previous_work\\notebooks\\budget_strategies.ipynb Cell 59\u001b[0m line \u001b[0;36mBiDirectionalSelection.get_score\u001b[1;34m(self, d)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m# predict next top-k items about to be selected\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m perm \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mcompressed(np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mmasked_array(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_interactions, mask\u001b[39m=\u001b[39md))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(perm)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mkth_norm\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/original_testing/Thesis/previous_work/notebooks/budget_strategies.ipynb#Y112sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     preds[perm] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mStaticVars\u001b[39m.\u001b[39mFLOAT_MAX\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\original_testing\\Thesis\\previous_work\\spotlight_ext\\spotlight\\sequence\\implicit.py:328\u001b[0m, in \u001b[0;36mImplicitSequenceModel.predict\u001b[1;34m(self, sequences, item_ids)\u001b[0m\n\u001b[0;32m    326\u001b[0m _, sequence_representations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_net\u001b[39m.\u001b[39muser_representation(sequence_var)\n\u001b[0;32m    327\u001b[0m size \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(item_var),) \u001b[39m+\u001b[39m sequence_representations\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 328\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_net(sequence_representations\u001b[39m.\u001b[39;49mexpand(\u001b[39m*\u001b[39;49msize),\n\u001b[0;32m    329\u001b[0m                 item_var)\n\u001b[0;32m    331\u001b[0m \u001b[39mreturn\u001b[39;00m cpu(out)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mflatten()\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\original_testing\\Thesis\\previous_work\\spotlight_ext\\spotlight\\sequence\\representations.py:254\u001b[0m, in \u001b[0;36mLSTMNet.forward\u001b[1;34m(self, user_representations, targets)\u001b[0m\n\u001b[0;32m    249\u001b[0m target_embedding \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_embeddings(targets)\n\u001b[0;32m    250\u001b[0m                     \u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m    251\u001b[0m                     \u001b[39m.\u001b[39msqueeze())\n\u001b[0;32m    252\u001b[0m target_bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_biases(targets)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m--> 254\u001b[0m dot \u001b[39m=\u001b[39m ((user_representations \u001b[39m*\u001b[39;49m target_embedding)\n\u001b[0;32m    255\u001b[0m        \u001b[39m.\u001b[39msum(\u001b[39m1\u001b[39m)\n\u001b[0;32m    256\u001b[0m        \u001b[39m.\u001b[39msqueeze())\n\u001b[0;32m    258\u001b[0m \u001b[39mreturn\u001b[39;00m target_bias \u001b[39m+\u001b[39m dot\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "backend='bidirectional'\n",
    "bidirectional_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000, alpha=1e-3, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000, alpha=0.5, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1, 3, 5, 7], no_users=6000, init_budget=1000, alpha=0.999, normalization='default'),\n",
    "]\n",
    "\n",
    "%store bidirectional_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend='brute_force'\n",
    "brute_force_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1], no_users=30, init_budget=100000),\n",
    "]\n",
    "\n",
    "%store brute_force_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend='combo'\n",
    "combo_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1], no_users=30, init_budget=1000, alpha=1e-3, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1], no_users=30, init_budget=1000, alpha=0.5, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [1], no_users=30, init_budget=1000, alpha=0.999, normalization='default'),\n",
    "]\n",
    "\n",
    "%store combo_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
