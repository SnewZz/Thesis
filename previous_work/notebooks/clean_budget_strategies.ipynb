{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats as st\n",
    "import itertools\n",
    "import operator\n",
    "import heapq as hq\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get currently working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# load functions from other notebooks : helpers.ipynb contains a set of tools and functions used in this notebook\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb').replace(\"\\\\\", \"/\")\n",
    "%run $helpers_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['../spotlight_ext']:\n",
    "    module_path = os.path.abspath(os.path.join(base_dir, p))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "random_state = np.random.RandomState(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare models/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained models \"lstm\" (entire_model_1m_20interactions.pt) and \"pooling\" (pooling_model_1m_20interactions.pt) presents in the models folder\n",
    "\n",
    "# implicit_model = load_model('implicit_factorization')\n",
    "lstm_model = load_model(model_type='entire') # the code to create this model is in misc.ipynb (see section \"train model\")\n",
    "pooling_model = load_model('pooling') # the code to create this model is in brute_force_rec_expl.ipynb (see section \"train and save pooling model\")\n",
    "\n",
    "pretrained_models = {\n",
    "    'lstm': lstm_model,\n",
    "    'pooling': pooling_model,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset Movielens with the variant 1M. Then divide it into a training set and a testing set. It also limits the length of each sequence of elements in the 2 sets to 20.\n",
    "\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "\n",
    "# get dataset, more information here : https://grouplens.org/datasets/movielens/\n",
    "dataset = get_movielens_dataset(variant='1M')\n",
    "train, test = random_train_test_split(dataset, random_state=random_state)\n",
    "\n",
    "max_sequence_length = 20 # Maximum sequence length. Subsequences shorter than this will be left-padded with zeros.\n",
    "train = train.to_sequence(max_sequence_length=max_sequence_length)\n",
    "test = test.to_sequence(max_sequence_length=max_sequence_length) # test is a SequenceInteractions object, here is the documentation on this object : https://maciejkula.github.io/spotlight/interactions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047a9cd9ea2c4bef87c4d4b14e56a2c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute cosine similarity matrix for item embeddings using GPU\n",
    "pooling_sims_matrix = gpu_embeddings_to_cosine_similarity_matrix(\n",
    "    pooling_model._net.item_embeddings(\n",
    "        torch.arange(0, dataset.num_items, dtype=torch.int64)\n",
    "    )).detach().numpy()\n",
    "\n",
    "# Compute item-item similarity matrix using Jaccard similarity\n",
    "jaccard_sims_matrix = compute_sim_matrix(dataset, 'jaccard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e+00 1.03482099e-01 1.48905109e-01 ... 0.00000000e+00\n",
      " 5.79710145e-04 0.00000000e+00]\n",
      "[0.1034821  1.         0.13600783 ... 0.         0.         0.        ]\n",
      "(3706,)\n",
      "(3706,)\n"
     ]
    }
   ],
   "source": [
    "print(jaccard_sims_matrix[0])\n",
    "print(jaccard_sims_matrix[1])\n",
    "print(jaccard_sims_matrix[0].shape)\n",
    "print(jaccard_sims_matrix[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040\n",
      "1\n",
      "6041\n",
      "3706\n",
      "1\n",
      "3707\n"
     ]
    }
   ],
   "source": [
    "print(max(dataset.user_ids))\n",
    "print(min(dataset.user_ids))\n",
    "print(dataset.num_users)\n",
    "print(max(dataset.item_ids))\n",
    "print(min(dataset.item_ids))\n",
    "print(dataset.num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various implemented Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseStrategy:\n",
    "    class_name = None\n",
    "\n",
    "    def __init__(self, item, interactions, max_length, init_budget,  model=None, random_pick=False):\n",
    "\n",
    "        self.target_item = item\n",
    "        self.original_interactions = interactions\n",
    "        self.max_length = max_length\n",
    "        self.visited_ = set()\n",
    "        self.model = model\n",
    "        self.last_comb_cost = 0\n",
    "        self.random_pick = random_pick\n",
    "        self.top_k = 10\n",
    "        self.budget = init_budget\n",
    "\n",
    "    # Must be implemented by subclasses. Used to select the next item to recommand to the user.\n",
    "    def next_comb(self, reverse=False):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \n",
    "    # This method takes a \"number\" argument and returns a list of 0-bit positions in the binary representation of \"number\".\n",
    "    def _get_pos(self, number):\n",
    "        bits = []\n",
    "        for i, c in enumerate(bin(number)[:1:-1], 1):\n",
    "            if c == '0':\n",
    "                bits.append(i)\n",
    "        return bits\n",
    "\n",
    "    # Method to reset the costs of the last recommended combination\n",
    "    def reset_costs(self):\n",
    "        self.last_comb_cost = 0\n",
    "\n",
    "    # Returns the initial budget\n",
    "    def get_init_budget(self):\n",
    "        return self.budget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSelection\n",
    "#### This class is a subclass of the \"BaseStrategy\" class, representing a random item selection strategy for the sequential recommendation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSelection(BaseStrategy):\n",
    "    class_name = 'Random'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget)\n",
    "\n",
    "    # The _next_item method selects a random integer between 1 and 2 raised to the power of the maximum length of the sequence. \n",
    "    # It checks if the integer is already in the set of visited integers, and if it is, selects another integer until a non-visited integer is found. \n",
    "    # Finally, the selected integer is added to the set of visited integers, and returned.\n",
    "    def _next_item(self):\n",
    "        self.budget -= 1\n",
    "        \n",
    "        number = random.sample(range(1, pow(2, self.max_length)), 1)[0]\n",
    "        while number in self.visited_:\n",
    "            number = random.sample(range(1, pow(2, self.max_length)), 1)[0]\n",
    "        self.visited_.add(number)\n",
    "        \n",
    "        return number\n",
    "    \n",
    "    # The next_comb method generates a new sequence by removing items at positions indicated by the binary digits of the integer returned \n",
    "    # by _next_item from the original sequence of interactions. \n",
    "    # The resulting sequence, along with the current budget, is returned as a tuple.\n",
    "    def next_comb(self, reverse=False):\n",
    "        number = self._next_item()\n",
    "\n",
    "        bits = self._get_pos(number)\n",
    "        seq = np.delete(self.original_interactions, bits)\n",
    "\n",
    "        return (seq, self.budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LossSimilarSelection\n",
    "#### This class inherits from the BaseStrategy class. This class defines a search strategy for selecting items based on their similarity to previously selected items, while also considering their loss (difference between predicted and actual values) in a ranking problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossSimilarSelection(BaseStrategy):\n",
    "    class_name = 'BFS'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, early_term=False):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model)\n",
    "\n",
    "        mask = [False] * len(self.original_interactions)\n",
    "        t_score = StaticVars.INT_MAX\n",
    "        is_solved = 0\n",
    "\n",
    "        self.q = Queue()\n",
    "        self.q.enqueue((mask, t_score, is_solved))\n",
    "\n",
    "        self.thres = len(self.original_interactions) + 1\n",
    "        self.early_termination = early_term\n",
    "\n",
    "    # Helper : This method is called whenever a solution is found for the current \n",
    "    # mask of the items. It computes the loss of the solution and updates the queue \n",
    "    # accordingly.\n",
    "    def _update_queue(self, is_solved):\n",
    "        self.compute_loss(is_solved)\n",
    "\n",
    "    # Helper : \n",
    "    def _next_item(self):\n",
    "        mask, t_score, is_solved = self.q.dequeue()\n",
    "        while self.early_termination and sum(mask) == self.thres:\n",
    "            q_data = self.q.dequeue()\n",
    "            if q_data is None: \n",
    "                break\n",
    "            mask, t_score, is_solved = q_data\n",
    "\n",
    "        if is_solved == 2:\n",
    "            t_score, kth_score = self.get_score(mask)\n",
    "\n",
    "            if (t_score / kth_score) < 1: \n",
    "                self.thres = sum(mask)\n",
    "\n",
    "        return (is_solved, mask, self.budget)\n",
    "\n",
    "    # The next_comb method returns the next combination of items and the remaining budget.\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "\n",
    "        if self.q.size() > 0:\n",
    "            solved_flag, item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy()) # If there is a True in the mask, the value at the corresponding index is masked\n",
    "            self._update_queue(solved_flag)\n",
    "        else: \n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr) #Extract all the valid values in ma_arr\n",
    "        return (seq, budget) if len(seq) else (None, budget)\n",
    "\n",
    "    # This method computes the loss of the solution. If the solution is not yet solved, it searches for the next combination of items \n",
    "    # to evaluate by calling the search method. \n",
    "    # If the solution is solved, it searches for the previous combination of items by calling the search method with forward=False.\n",
    "    def compute_loss(self, is_solved=False):\n",
    "        self.last_comb_cost = 0\n",
    "\n",
    "        if not is_solved: \n",
    "            self.search(forward=True, s=is_solved)#\n",
    "        else: \n",
    "            self.search(forward=False, s=is_solved)\n",
    "\n",
    "    def search(self, forward=True, s=False):\n",
    "        \"\"\"\n",
    "        Searches for the next combination of items based on the search direction.\n",
    "\n",
    "        Args:\n",
    "            forward (bool, optional): If True, the search is performed forward, otherwise backward.\n",
    "            s (bool, optional): Indicates whether a solution is found.\n",
    "        \"\"\"\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        valid_items = np.where(np.logical_not(m_mask) if forward else m_mask)[0] #if forward is True it means we keep index of items where the m_mask is not True\n",
    "        if valid_items.size > 1:\n",
    "            for idx in valid_items:\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "                self.add(m_mask, s)\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "    def get_score(self, d):\n",
    "        \"\"\"\n",
    "        Computes the score of an item based on its predicted value and rank among the top-k items.\n",
    "\n",
    "        Args:\n",
    "            d (array_like): Boolean mask indicating the selected items.\n",
    "\n",
    "        Returns:\n",
    "            Tuple: A tuple containing the score of the target item and its rank among the top-k items.\n",
    "        \"\"\"\n",
    "        perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=d))\n",
    "\n",
    "        self.budget -= 1\n",
    "        # predict next top-k items about to be selected\n",
    "        preds = self.model.predict(perm)\n",
    "        preds[perm] = -StaticVars.FLOAT_MAX\n",
    "        rk_data = st.rankdata(-preds, method='ordinal')\n",
    "\n",
    "        return (preds[self.target_item], preds[(rk_data == self.top_k).nonzero()][0])\n",
    "\n",
    "    def add(self, d, s):\n",
    "        \"\"\"\n",
    "        Adds a new combination to the queue and updates the visited set.\n",
    "\n",
    "        Args:\n",
    "            d (array_like): Boolean mask representing the combination of items.\n",
    "            s (bool): Indicates whether a solution is found.\n",
    "        \"\"\"\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "            perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=d))\n",
    "\n",
    "            if not s:\n",
    "                t_score, kth_score = self.get_score(d)\n",
    "\n",
    "                if self.q.size() == 0: self.q.enqueue((d.copy(), t_score, 1 if (t_score / kth_score) < 1 else 0))\n",
    "\n",
    "                if t_score < self.q.get(0)[1]:  # get only the assigned score\n",
    "                    self.q.setter(0, (d.copy(), t_score, 1 if (t_score / kth_score) < 1 else 0))\n",
    "            else:\n",
    "                self.q.enqueue((d.copy(), StaticVars.INT_MAX, 2))\n",
    "\n",
    "            self.visited_.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiDirectionalSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiDirectionalSelection(BaseStrategy):\n",
    "    class_name = 'BiDirectional'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, weights=(1, 0), alpha=0.9, normalization='default'):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model)\n",
    "\n",
    "        self.tiebraker = itertools.count()\n",
    "        self.q = [(1, StaticVars.INT_MAX, next(self.tiebraker), [False] * len(self.original_interactions), self.budget)]\n",
    "        hq.heapify(self.q)\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.norm = normalization\n",
    "\n",
    "    def _update_queue(self, is_solved):\n",
    "        self.compute_loss(is_solved)\n",
    "\n",
    "    def _next_item(self):\n",
    "        is_solved, _, _, mask, budget = hq.heappop(self.q)\n",
    "        return (is_solved, mask, budget)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "        if self.q:\n",
    "            solved_flag, item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "            self._update_queue(solved_flag)\n",
    "        else: self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)\n",
    "\n",
    "    def compute_loss(self, is_solved=False):\n",
    "        self.search(forward=True, s=is_solved)\n",
    "        self.search(forward=False, s=is_solved)\n",
    "\n",
    "    def search(self, forward=True, s=False):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        valid_items = np.where(np.logical_not(m_mask) if forward else m_mask)[0]\n",
    "        if valid_items.size > 1:\n",
    "            for idx in valid_items:\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "                self.add(m_mask, s)\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "    def get_custom_score(self, c):\n",
    "        return c / self.max_length\n",
    "\n",
    "    def get_score(self, d):\n",
    "        self.budget -= 1\n",
    "\n",
    "        # predict next top-k items about to be selected\n",
    "        perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=d))\n",
    "        preds = self.model.predict(perm)\n",
    "\n",
    "        if self.norm == 'kth_norm':\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "            rk_data = st.rankdata(-preds, method='ordinal')\n",
    "\n",
    "            t_score = preds[self.target_item] / preds[(rk_data == self.top_k).nonzero()][0]\n",
    "        elif self.norm == 'rescale':\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "            rk_data = st.rankdata(-preds, method='ordinal')\n",
    "\n",
    "            max_val = rk_data[0]\n",
    "            min_val = rk_data[-1]\n",
    "            t_score = (max_val - preds[self.target_item]) / (max_val - min_val)\n",
    "        else:  # default case\n",
    "            tensor = F.softmax(torch.from_numpy(preds).float(), dim=0)\n",
    "            preds = tensor.numpy()\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "\n",
    "            t_score = preds[self.target_item]\n",
    "\n",
    "        return self.alpha * t_score + (1 - self.alpha) * self.get_custom_score(np.sum(d))\n",
    "\n",
    "    def add(self, d, s):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "            t_score = self.get_score(d)\n",
    "            hq.heappush(self.q, (int(not s), t_score, next(self.tiebraker), d.copy(), self.budget))\n",
    "\n",
    "            self.visited_.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BruteForceSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BruteForceSelection(BaseStrategy):\n",
    "    class_name = 'BruteForce'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model)\n",
    "\n",
    "        self.q = Queue()\n",
    "        self.q.enqueue(([False] * len(self.original_interactions), self.budget))\n",
    "\n",
    "    def _expand_queue(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        valid_items = np.where(np.logical_not(m_mask))[0]\n",
    "        if valid_items.size > 1:\n",
    "            for idx in valid_items:\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "                self.add(m_mask)\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "    def _next_item(self):\n",
    "        mask, budget = self.q.dequeue()\n",
    "        return (mask, budget)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "\n",
    "        if reverse: self.q.clear()\n",
    "\n",
    "        if self.q.size() > 0:\n",
    "            item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "            self._expand_queue()\n",
    "        else:\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)\n",
    "\n",
    "    def add(self, d):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "            self.budget -= 1\n",
    "            self.q.enqueue((d.copy(), self.budget))\n",
    "            self.visited_.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ComboSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComboSelection(BiDirectionalSelection):\n",
    "    class_name = 'Combo'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, weights=(1, 0), alpha=0.9, normalization='default'):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model, weights, alpha, normalization)\n",
    "\n",
    "        self.alpha = 1\n",
    "\n",
    "        self.q_init = Queue()\n",
    "        self.q_init.enqueue((StaticVars.INT_MAX, [False] * len(self.original_interactions), self.budget))\n",
    "        self.init_queue()\n",
    "\n",
    "        self.tiebraker = itertools.count()\n",
    "        self.q = []\n",
    "        hq.heapify(self.q)\n",
    "\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def init_queue(self):\n",
    "        _, m_mask, budget = self.q_init.dequeue()\n",
    "        m_mask = np.asarray(m_mask)\n",
    "\n",
    "        valid_items = np.where(np.logical_not(m_mask))[0]\n",
    "        for idx in valid_items:\n",
    "            m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "            mask_to_int = int(''.join(map(str, m_mask.astype(int))), 2)\n",
    "            if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "                t_score = self.get_score(m_mask)\n",
    "                self.q_init.enqueue((t_score, m_mask.copy(), self.budget))\n",
    "\n",
    "                self.visited_.add(mask_to_int)\n",
    "\n",
    "            m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "        pair_combs = []\n",
    "        for c in itertools.combinations(range(len(self.original_interactions)), 2):\n",
    "            m = [False] * len(self.original_interactions)\n",
    "            m[c[0]], m[c[1]] = not m[c[0]], not m[c[1]]\n",
    "            pair_combs.append((self.q_init.get(c[0])[0] + self.q_init.get(c[1])[0], m.copy()))\n",
    "\n",
    "        pair_combs.sort(key=operator.itemgetter(0))\n",
    "        for c in pair_combs:\n",
    "            self.budget -= 1\n",
    "            self.q_init.enqueue((0, c[1], self.budget))\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "\n",
    "        if self.q_init.size() > 0:\n",
    "            s, item_mask, budget = self.q_init.dequeue()\n",
    "            item_mask = np.asarray(item_mask)\n",
    "            solved_flag = False\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "\n",
    "            self.add(item_mask, False)\n",
    "        elif self.q:\n",
    "            solved_flag, item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "\n",
    "            self._update_queue(solved_flag)\n",
    "        else: self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporary code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MostSimilarSelection(BaseStrategy):\n",
    "    class_name = 'Sim-Matrix'\n",
    "\n",
    "    supported_sim_matrix = {\n",
    "        'pooling': pooling_sims_matrix,\n",
    "        'jaccard': jaccard_sims_matrix\n",
    "    }\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, model, sim_type='pooling'):\n",
    "        super().__init__(item, interactions, max_sequence_length)\n",
    "\n",
    "        self.visited_.add(0)\n",
    "        self.reverse_checks = []\n",
    "        self.is_materialized = False\n",
    "\n",
    "        self._get_sim_ranking(sim_type)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        if reverse:\n",
    "            self._materialize_list()\n",
    "            selected_item_indices = self.reverse_checks.pop(\n",
    "                random.randrange(len(self.reverse_checks)) if self.random_pick else 0\n",
    "            ) if len(self.reverse_checks) else []\n",
    "        else:\n",
    "            self.visited_.add(max(self.visited_) + 1)\n",
    "            selected_item_indices = np.where(np.isin(\n",
    "                self.rk_items,\n",
    "                list(set(self.rk_items).difference(set(self.visited_)))\n",
    "            ))[0]\n",
    "        seq = self.original_interactions[selected_item_indices] if len(selected_item_indices) else None\n",
    "        return seq\n",
    "\n",
    "    def _get_sim_ranking(self, sim_type):\n",
    "        ranked_items = st.rankdata(self.supported_sim_matrix[sim_type][self.target_item, self.original_interactions])\n",
    "        self.rk_items = self.max_length - ranked_items + 1\n",
    "\n",
    "    def _materialize_list(self):\n",
    "        if not self.is_materialized:\n",
    "            psize = len(self.visited_) - 1  # do not consider initial added zero value\n",
    "            # do not take account none/all excluded interacted items\n",
    "            prods = sorted(list(map(list, itertools.product([0, 1], repeat=psize)))[1:-1], key=sum)\n",
    "#             last_item_indices = np.where(np.isin(\n",
    "#                 self.rk_items,\n",
    "#                 list(set(self.rk_items).difference(set(self.visited_)))\n",
    "#             ))\n",
    "\n",
    "            lvisited_ = np.asarray(list(self.visited_))[1:]\n",
    "            for p in prods:\n",
    "                self.reverse_checks.append(np.where(np.isin(\n",
    "                    self.rk_items,\n",
    "                    list(set(self.rk_items).difference(lvisited_[np.nonzero(np.multiply(p, lvisited_))])))\n",
    "                ))\n",
    "\n",
    "            self.is_materialized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MostSimilarSelectionByJaccard(MostSimilarSelection):\n",
    "    class_name = 'Jaccard-on-Sim-Matrix'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model, 'jaccard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine_on_embeddings_cfs = [\n",
    "#     _find_cfs(test, pretrained_models['lstm'], [3, 5, 7], no_users=500, backend='most_sim', init_budget=1000),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='most_sim', init_budget=1000)\n",
    "# ]\n",
    "# jaccard_on_embeddings_cfs = [\n",
    "#     _find_cfs(test, pretrained_models['lstm'], [3, 5, 7], no_users=500, backend='most_sim_jaccard', init_budget=1000),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='most_sim_jaccard', init_budget=1000),\n",
    "# ]\n",
    "\n",
    "# %store cosine_on_embeddings_cfs\n",
    "# %store jaccard_on_embeddings_cfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get backend strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backend_strategy(backend):\n",
    "    if 'random' == backend:\n",
    "        return RandomSelection\n",
    "    elif 'most_sim' == backend:\n",
    "        return MostSimilarSelection\n",
    "    elif 'most_sim_jaccard' == backend:\n",
    "        return MostSimilarSelectionByJaccard\n",
    "    elif 'bfs' == backend:\n",
    "        return LossSimilarSelection\n",
    "    elif 'random_most_sim' == backend:\n",
    "        return RandomMostSimilarSelection\n",
    "    elif 'random_loss_sim' == backend:\n",
    "        return RandomLossSimilarSelection\n",
    "    elif 'fixed_loss_sim' == backend:\n",
    "        return FixedRankingLossSimilarSelection\n",
    "    elif 'dfs_loss_sim' == backend:\n",
    "        return DFSwithLossSelection\n",
    "    elif 'dfs_fixed_loss_sim' == backend:\n",
    "        return DFSwithFixedRankingLossSelection\n",
    "    elif 'bestFS_loss' == backend:\n",
    "        return BestFSLossSelection\n",
    "    elif 'bestFS_fixed_loss' == backend:\n",
    "        return BestFSFixedLossSelection\n",
    "    elif 'topdown_loss' == backend:\n",
    "        return TopDownBestFSLossSelection\n",
    "    elif 'bidirectional' == backend:\n",
    "        return BiDirectionalSelection\n",
    "    elif 'brute_force' == backend:\n",
    "        return BruteForceSelection\n",
    "    elif 'combo' == backend:\n",
    "        return ComboSelection\n",
    "    else: print('Unknown strategy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run implemented strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: Random\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9670921523534e64ae38aaed96f21078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :  508\n",
      "[-0.         -0.4886701  -1.2704934  ...  1.4422629   0.21140254\n",
      "  0.10461938]\n",
      "-0.0\n",
      "0.104619384\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 2757 3545 3544 3301 3542 3540 3539 3538 3536]\n",
      "target :  890\n",
      "[-0.        -1.7293239  0.7516235 ...  1.2451138  0.8454702  2.057247 ]\n",
      "-0.0\n",
      "2.057247\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3367 3368 3370 3371 3374 3376 3377 3378 3385]\n",
      "target :  1015\n",
      "[-0.         -0.01268113 -0.72315276 ...  1.8612478   1.2578342\n",
      "  0.7910427 ]\n",
      "-0.0\n",
      "0.7910427\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3577 3576 3237 3571 3570 3565 3564 3245 3557]\n",
      "target :  421\n",
      "[-0.         -2.4513376   0.45527014 ...  1.0769624   1.3857057\n",
      "  1.618092  ]\n",
      "-0.0\n",
      "1.618092\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 2757 3071 3590 3589 3545 3547 3455 2228 3582]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [00:09,  2.09it/s]              "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba4cba1d7e5424499640504972f90a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :  28\n",
      "[-0.         -0.4886701  -1.2704934  ...  1.4422629   0.21140254\n",
      "  0.10461938]\n",
      "-0.0\n",
      "0.104619384\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3266 3557 3355 3564 3565 3032 3570 3030 3576]\n",
      "target :  1381\n",
      "[-0.        -1.7293239  0.7516235 ...  1.2451138  0.8454702  2.057247 ]\n",
      "-0.0\n",
      "2.057247\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3438 3440 3442 2228 3443 3444 3447 3448 3428]\n",
      "target :  433\n",
      "[-0.         -0.01268113 -0.72315276 ...  1.8612478   1.2578342\n",
      "  0.7910427 ]\n",
      "-0.0\n",
      "0.7910427\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3605 2983 3517 3516 3515 3609 3514 3513 3266]\n",
      "target :  52\n",
      "[-0.         -2.4513376   0.45527014 ...  1.0769624   1.3857057\n",
      "  1.618092  ]\n",
      "-0.0\n",
      "1.618092\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3476 2228 3498 3630 3632 3634 3582 3447 3581 3579]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [00:19,  1.45it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2379ac08d04156a0264a6487dae5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :  124\n",
      "[-0.         -0.4886701  -1.2704934  ...  1.4422629   0.21140254\n",
      "  0.10461938]\n",
      "-0.0\n",
      "0.104619384\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3633 3428 3582 3245 3415 2228 3581 3579 3266]\n",
      "target :  1408\n",
      "[-0.        -1.7293239  0.7516235 ...  1.2451138  0.8454702  2.057247 ]\n",
      "-0.0\n",
      "2.057247\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3487 3488 3490 2687 3032 3492 3486 3493 3495]\n",
      "target :  466\n",
      "[-0.         -0.01268113 -0.72315276 ...  1.8612478   1.2578342\n",
      "  0.7910427 ]\n",
      "-0.0\n",
      "0.7910427\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3540 3539 3535 3534 3530 3527 3526 3523 3288]\n",
      "target :  45\n",
      "[-0.         -2.4513376   0.45527014 ...  1.0769624   1.3857057\n",
      "  1.618092  ]\n",
      "-0.0\n",
      "1.618092\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [2989 3604 3617 3462 3632 3633 3319 3603 1785 3316]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [00:32,  1.10it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e2d7b878634787a0dbdb3da24a78fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :  488\n",
      "[-0.         -0.4886701  -1.2704934  ...  1.4422629   0.21140254\n",
      "  0.10461938]\n",
      "-0.0\n",
      "0.104619384\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3450 3452 2465 3453 2120 3454 3455 3447 3457]\n",
      "target :  451\n",
      "[-0.        -1.7293239  0.7516235 ...  1.2451138  0.8454702  2.057247 ]\n",
      "-0.0\n",
      "2.057247\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3472 3218 3473 3216 3475 3476 3477 3471 3215]\n",
      "target :  320\n",
      "[-0.         -0.01268113 -0.72315276 ...  1.8612478   1.2578342\n",
      "  0.7910427 ]\n",
      "-0.0\n",
      "0.7910427\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3582 3393 3581 3580 3579 3577 3576 3408 3415]\n",
      "target :  65\n",
      "[-0.         -2.4513376   0.45527014 ...  1.0769624   1.3857057\n",
      "  1.618092  ]\n",
      "-0.0\n",
      "1.618092\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3032 3603 3604 3605 3612 3616 3617 1785 3566 3633]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [00:42,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'random_cfs' (list)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get currently working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# load functions from other notebooks\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb').replace(\"\\\\\", \"/\")\n",
    "%run $helpers_file\n",
    "\n",
    "backend = 'random'\n",
    "random_cfs = [\n",
    "\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users= 500, init_budget=1000)\n",
    "    # _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users= 10, init_budget=1000)\n",
    "]\n",
    "\n",
    "%store random_cfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BFS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9608abfaef42a1a848f26c279aaaf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :  508\n",
      "[-0.         -0.4886701  -1.2704934  ...  1.4422629   0.21140254\n",
      "  0.10461938]\n",
      "-0.0\n",
      "0.104619384\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 2757 3545 3544 3301 3542 3540 3539 3538 3536]\n",
      "target :  890\n",
      "[-0.        -1.7293239  0.7516235 ...  1.2451138  0.8454702  2.057247 ]\n",
      "-0.0\n",
      "2.057247\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3367 3368 3370 3371 3374 3376 3377 3378 3385]\n",
      "target :  1015\n",
      "[-0.         -0.01268113 -0.72315276 ...  1.8612478   1.2578342\n",
      "  0.7910427 ]\n",
      "-0.0\n",
      "0.7910427\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3577 3576 3237 3571 3570 3565 3564 3245 3557]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [00:00, 35.74it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :  421\n",
      "[-0.         -2.4513376   0.45527014 ...  1.0769624   1.3857057\n",
      "  1.618092  ]\n",
      "-0.0\n",
      "1.618092\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 2757 3071 3590 3589 3545 3547 3455 2228 3582]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d8c2c0e0fd49d9839d3cef3a910d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :  28\n",
      "[-0.         -0.4886701  -1.2704934  ...  1.4422629   0.21140254\n",
      "  0.10461938]\n",
      "-0.0\n",
      "0.104619384\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3266 3557 3355 3564 3565 3032 3570 3030 3576]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [00:01, 24.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :  1381\n",
      "[-0.        -1.7293239  0.7516235 ...  1.2451138  0.8454702  2.057247 ]\n",
      "-0.0\n",
      "2.057247\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3438 3440 3442 2228 3443 3444 3447 3448 3428]\n",
      "target :  433\n",
      "[-0.         -0.01268113 -0.72315276 ...  1.8612478   1.2578342\n",
      "  0.7910427 ]\n",
      "-0.0\n",
      "0.7910427\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3605 2983 3517 3516 3515 3609 3514 3513 3266]\n",
      "target :  52\n",
      "[-0.         -2.4513376   0.45527014 ...  1.0769624   1.3857057\n",
      "  1.618092  ]\n",
      "-0.0\n",
      "1.618092\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3476 2228 3498 3630 3632 3634 3582 3447 3581 3579]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c6e388117747388d8e4770e409989c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :  124\n",
      "[-0.         -0.4886701  -1.2704934  ...  1.4422629   0.21140254\n",
      "  0.10461938]\n",
      "-0.0\n",
      "0.104619384\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3633 3428 3582 3245 3415 2228 3581 3579 3266]\n",
      "target :  1408\n",
      "[-0.        -1.7293239  0.7516235 ...  1.2451138  0.8454702  2.057247 ]\n",
      "-0.0\n",
      "2.057247\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3487 3488 3490 2687 3032 3492 3486 3493 3495]\n",
      "target :  466\n",
      "[-0.         -0.01268113 -0.72315276 ...  1.8612478   1.2578342\n",
      "  0.7910427 ]\n",
      "-0.0\n",
      "0.7910427\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3540 3539 3535 3534 3530 3527 3526 3523 3288]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [00:01, 20.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :  45\n",
      "[-0.         -2.4513376   0.45527014 ...  1.0769624   1.3857057\n",
      "  1.618092  ]\n",
      "-0.0\n",
      "1.618092\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [2989 3604 3617 3462 3632 3633 3319 3603 1785 3316]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913eace7f88f4cc2abc4dd28d2ea1582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :  488\n",
      "[-0.         -0.4886701  -1.2704934  ...  1.4422629   0.21140254\n",
      "  0.10461938]\n",
      "-0.0\n",
      "0.104619384\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3450 3452 2465 3453 2120 3454 3455 3447 3457]\n",
      "target :  451\n",
      "[-0.        -1.7293239  0.7516235 ...  1.2451138  0.8454702  2.057247 ]\n",
      "-0.0\n",
      "2.057247\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3472 3218 3473 3216 3475 3476 3477 3471 3215]\n",
      "target :  320\n",
      "[-0.         -0.01268113 -0.72315276 ...  1.8612478   1.2578342\n",
      "  0.7910427 ]\n",
      "-0.0\n",
      "0.7910427\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3582 3393 3581 3580 3579 3577 3576 3408 3415]\n",
      "target :  65\n",
      "[-0.         -2.4513376   0.45527014 ...  1.0769624   1.3857057\n",
      "  1.618092  ]\n",
      "-0.0\n",
      "1.618092\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3032 3603 3604 3605 3612 3616 3617 1785 3566 3633]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [00:02, 17.56it/s]\n",
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BFS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15115bee2a2471583f1db16de695cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :  508\n",
      "[-0.         -0.4886701  -1.2704934  ...  1.4422629   0.21140254\n",
      "  0.10461938]\n",
      "-0.0\n",
      "0.104619384\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 2757 3545 3544 3301 3542 3540 3539 3538 3536]\n",
      "target :  890\n",
      "[-0.        -1.7293239  0.7516235 ...  1.2451138  0.8454702  2.057247 ]\n",
      "-0.0\n",
      "2.057247\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3367 3368 3370 3371 3374 3376 3377 3378 3385]\n",
      "target :  1015\n",
      "[-0.         -0.01268113 -0.72315276 ...  1.8612478   1.2578342\n",
      "  0.7910427 ]\n",
      "-0.0\n",
      "0.7910427\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3577 3576 3237 3571 3570 3565 3564 3245 3557]\n",
      "target :  421\n",
      "[-0.         -2.4513376   0.45527014 ...  1.0769624   1.3857057\n",
      "  1.618092  ]\n",
      "-0.0\n",
      "1.618092\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 2757 3071 3590 3589 3545 3547 3455 2228 3582]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [00:00, 41.66it/s]              "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0566489769d045e6ad209f02949f7e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :  28\n",
      "[-0.         -0.4886701  -1.2704934  ...  1.4422629   0.21140254\n",
      "  0.10461938]\n",
      "-0.0\n",
      "0.104619384\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3266 3557 3355 3564 3565 3032 3570 3030 3576]\n",
      "target :  1381\n",
      "[-0.        -1.7293239  0.7516235 ...  1.2451138  0.8454702  2.057247 ]\n",
      "-0.0\n",
      "2.057247\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3438 3440 3442 2228 3443 3444 3447 3448 3428]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [00:01, 25.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :  433\n",
      "[-0.         -0.01268113 -0.72315276 ...  1.8612478   1.2578342\n",
      "  0.7910427 ]\n",
      "-0.0\n",
      "0.7910427\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3605 2983 3517 3516 3515 3609 3514 3513 3266]\n",
      "target :  52\n",
      "[-0.         -2.4513376   0.45527014 ...  1.0769624   1.3857057\n",
      "  1.618092  ]\n",
      "-0.0\n",
      "1.618092\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3476 2228 3498 3630 3632 3634 3582 3447 3581 3579]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62443f22ceaf4167912c43121395db28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :  124\n",
      "[-0.         -0.4886701  -1.2704934  ...  1.4422629   0.21140254\n",
      "  0.10461938]\n",
      "-0.0\n",
      "0.104619384\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3633 3428 3582 3245 3415 2228 3581 3579 3266]\n",
      "target :  1408\n",
      "[-0.        -1.7293239  0.7516235 ...  1.2451138  0.8454702  2.057247 ]\n",
      "-0.0\n",
      "2.057247\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3487 3488 3490 2687 3032 3492 3486 3493 3495]\n",
      "target :  466\n",
      "[-0.         -0.01268113 -0.72315276 ...  1.8612478   1.2578342\n",
      "  0.7910427 ]\n",
      "-0.0\n",
      "0.7910427\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3540 3539 3535 3534 3530 3527 3526 3523 3288]\n",
      "target :  45\n",
      "[-0.         -2.4513376   0.45527014 ...  1.0769624   1.3857057\n",
      "  1.618092  ]\n",
      "-0.0\n",
      "1.618092\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [2989 3604 3617 3462 3632 3633 3319 3603 1785 3316]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [00:01, 19.49it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "073c1b491f244e0886d7f55bf2a5040c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :  488\n",
      "[-0.         -0.4886701  -1.2704934  ...  1.4422629   0.21140254\n",
      "  0.10461938]\n",
      "-0.0\n",
      "0.104619384\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3450 3452 2465 3453 2120 3454 3455 3447 3457]\n",
      "target :  451\n",
      "[-0.        -1.7293239  0.7516235 ...  1.2451138  0.8454702  2.057247 ]\n",
      "-0.0\n",
      "2.057247\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3472 3218 3473 3216 3475 3476 3477 3471 3215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [00:02, 16.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :  320\n",
      "[-0.         -0.01268113 -0.72315276 ...  1.8612478   1.2578342\n",
      "  0.7910427 ]\n",
      "-0.0\n",
      "0.7910427\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3582 3393 3581 3580 3579 3577 3576 3408 3415]\n",
      "target :  65\n",
      "[-0.         -2.4513376   0.45527014 ...  1.0769624   1.3857057\n",
      "  1.618092  ]\n",
      "-0.0\n",
      "1.618092\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3032 3603 3604 3605 3612 3616 3617 1785 3566 3633]\n",
      "Stored 'bfs_yloss_cfs' (list)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "backend = 'bfs'\n",
    "\n",
    "bfs_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users= 500, init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users= 500, init_budget=1000, early_term=True),\n",
    "]\n",
    "\n",
    "# %store bfs_yloss_cfs_positive\n",
    "%store bfs_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BiDirectional\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ca49c4bc1940be810945f764d673a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target :  508\n",
      "[-0.         -0.4886701  -1.2704934  ...  1.4422629   0.21140254\n",
      "  0.10461938]\n",
      "-0.0\n",
      "0.104619384\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 2757 3545 3544 3301 3542 3540 3539 3538 3536]\n",
      "target :  890\n",
      "[-0.        -1.7293239  0.7516235 ...  1.2451138  0.8454702  2.057247 ]\n",
      "-0.0\n",
      "2.057247\n",
      "3707\n",
      "len ranked_items :  3686\n",
      "top :  [3685 3367 3368 3370 3371 3374 3376 3377 3378 3385]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 10it [00:08,  1.22it/s]              \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbidirectional\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m bidirectional_cfs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m----> 4\u001b[0m     \u001b[43m_find_cfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_models\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlstm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_backend_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m17\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_target_in_topk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjaccard_sims_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_users\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_budget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m      5\u001b[0m     _find_cfs(test, pretrained_models[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm\u001b[39m\u001b[38;5;124m'\u001b[39m], get_backend_strategy(backend), [\u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m17\u001b[39m], missing_target_in_topk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sim_matrix\u001b[38;5;241m=\u001b[39mjaccard_sims_matrix, no_users\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, init_budget\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, normalization\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      6\u001b[0m     _find_cfs(test, pretrained_models[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm\u001b[39m\u001b[38;5;124m'\u001b[39m], get_backend_strategy(backend), [\u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m17\u001b[39m], missing_target_in_topk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sim_matrix\u001b[38;5;241m=\u001b[39mjaccard_sims_matrix, no_users\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, init_budget\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.999\u001b[39m, normalization\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      7\u001b[0m ]\n\u001b[0;32m      9\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbidirectional_cfs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_332\\979468614.py:158\u001b[0m, in \u001b[0;36m_find_cfs\u001b[1;34m(dataset, model, strategy_func, target_item_pos, missing_target_in_topk, sim_matrix, no_users, init_budget, max_allowed_permutations, top_k, total_CFs, num_processes, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m         best_tot_loss_data[pos] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m user_id \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m1\u001b[39m, num_users \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musers loop\u001b[39m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 158\u001b[0m             best_tot_loss_data[pos]\u001b[38;5;241m.\u001b[39mextend(\u001b[43m_retrieve_solutions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m                \u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrategy_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_budget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_target_in_topk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_tot_loss_data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_332\\979468614.py:94\u001b[0m, in \u001b[0;36m_retrieve_solutions\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     91\u001b[0m     perm \u001b[38;5;241m=\u001b[39m items_interacted\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;241m+\u001b[39m items_to_add \u001b[38;5;66;03m# maybe a bug TODO test it\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# update the predictions of each items (and then the rank) based on the \"new\" items interactions of the user\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m preds[perm] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mStaticVars\u001b[38;5;241m.\u001b[39mFLOAT_MAX\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# /!\\ the rankdata function give 1 as the lower number for a rank (and not 0)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\Thesis\\previous_work\\spotlight_ext\\spotlight\\sequence\\implicit.py:328\u001b[0m, in \u001b[0;36mImplicitSequenceModel.predict\u001b[1;34m(self, sequences, item_ids)\u001b[0m\n\u001b[0;32m    326\u001b[0m _, sequence_representations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_net\u001b[38;5;241m.\u001b[39muser_representation(sequence_var)\n\u001b[0;32m    327\u001b[0m size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(item_var),) \u001b[38;5;241m+\u001b[39m sequence_representations\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 328\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence_representations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m                \u001b[49m\u001b[43mitem_var\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cpu(out)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\Thesis\\previous_work\\spotlight_ext\\spotlight\\sequence\\representations.py:254\u001b[0m, in \u001b[0;36mLSTMNet.forward\u001b[1;34m(self, user_representations, targets)\u001b[0m\n\u001b[0;32m    249\u001b[0m target_embedding \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_embeddings(targets)\n\u001b[0;32m    250\u001b[0m                     \u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    251\u001b[0m                     \u001b[38;5;241m.\u001b[39msqueeze())\n\u001b[0;32m    252\u001b[0m target_bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_biases(targets)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m--> 254\u001b[0m dot \u001b[38;5;241m=\u001b[39m (\u001b[43m(\u001b[49m\u001b[43muser_representations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget_embedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m       \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m        \u001b[38;5;241m.\u001b[39msqueeze())\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target_bias \u001b[38;5;241m+\u001b[39m dot\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "backend='bidirectional'\n",
    "\n",
    "bidirectional_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=500, init_budget=1000, alpha=1e-3, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=500, init_budget=1000, alpha=0.5, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=500, init_budget=1000, alpha=0.999, normalization='default'),\n",
    "]\n",
    "\n",
    "%store bidirectional_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend='brute_force'\n",
    "\n",
    "brute_force_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=500, init_budget=100000),\n",
    "]\n",
    "\n",
    "%store brute_force_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend='combo'\n",
    "combo_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=500, init_budget=1000, alpha=1e-3, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=500, init_budget=1000, alpha=0.5, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=500, init_budget=1000, alpha=0.999, normalization='default'),\n",
    "]\n",
    "\n",
    "%store combo_cfs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
