{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats as st\n",
    "import itertools\n",
    "import operator\n",
    "import heapq as hq\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get currently working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# load functions from other notebooks : helpers.ipynb contains a set of tools and functions used in this notebook\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb').replace(\"\\\\\", \"/\")\n",
    "%run $helpers_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['../spotlight_ext']:\n",
    "    module_path = os.path.abspath(os.path.join(base_dir, p))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "random_state = np.random.RandomState(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare models/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained models \"lstm\" (entire_model_1m_20interactions.pt) and \"pooling\" (pooling_model_1m_20interactions.pt) presents in the models folder\n",
    "\n",
    "# implicit_model = load_model('implicit_factorization')\n",
    "lstm_model = load_model(model_type='entire') # the code to create this model is in misc.ipynb (see section \"train model\")\n",
    "pooling_model = load_model('pooling') # the code to create this model is in brute_force_rec_expl.ipynb (see section \"train and save pooling model\")\n",
    "\n",
    "pretrained_models = {\n",
    "    'lstm': lstm_model,\n",
    "    'pooling': pooling_model,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SequenceInteractions' object has no attribute 'users_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m train \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mto_sequence(max_sequence_length\u001b[38;5;241m=\u001b[39mmax_sequence_length)\n\u001b[0;32m     12\u001b[0m test \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mto_sequence(max_sequence_length\u001b[38;5;241m=\u001b[39mmax_sequence_length) \u001b[38;5;66;03m# test is a SequenceInteractions object, here is the documentation on this object : https://maciejkula.github.io/spotlight/interactions.html\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mmin\u001b[39m(\u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43musers_ids\u001b[49m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SequenceInteractions' object has no attribute 'users_ids'"
     ]
    }
   ],
   "source": [
    "# Get the dataset Movielens with the variant 1M. Then divide it into a training set and a testing set. It also limits the length of each sequence of elements in the 2 sets to 20.\n",
    "\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "\n",
    "# get dataset, more information here : https://grouplens.org/datasets/movielens/\n",
    "dataset = get_movielens_dataset(variant='1M')\n",
    "train, test = random_train_test_split(dataset, random_state=random_state)\n",
    "\n",
    "max_sequence_length = 20\n",
    "train = train.to_sequence(max_sequence_length=max_sequence_length)\n",
    "test = test.to_sequence(max_sequence_length=max_sequence_length) # test is a SequenceInteractions object, here is the documentation on this object : https://maciejkula.github.io/spotlight/interactions.html\n",
    "\n",
    "\n",
    "print(min(test.user_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83b129622ae48adaaece056ec87612b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute cosine similarity matrix for item embeddings using GPU\n",
    "pooling_sims_matrix = gpu_embeddings_to_cosine_similarity_matrix(\n",
    "    pooling_model._net.item_embeddings(\n",
    "        torch.arange(0, dataset.num_items, dtype=torch.int64)\n",
    "    )).detach().numpy()\n",
    "\n",
    "# Compute item-item similarity matrix using Jaccard similarity\n",
    "jaccard_sims_matrix = compute_sim_matrix(dataset, 'jaccard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various implemented Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseStrategy:\n",
    "    class_name = None\n",
    "\n",
    "    def __init__(self, item, interactions, max_length, init_budget,  model=None, random_pick=False):\n",
    "\n",
    "        self.target_item = item\n",
    "        self.original_interactions = interactions\n",
    "        self.max_length = max_length\n",
    "        self.visited_ = set()\n",
    "        self.model = model\n",
    "        self.last_comb_cost = 0\n",
    "        self.random_pick = random_pick\n",
    "        self.top_k = 10\n",
    "        self.budget = init_budget\n",
    "\n",
    "    #Must be implemented by subclasses. Used to select the next item to recommand to the user.\n",
    "    def next_comb(self, reverse=False):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \n",
    "    def _get_pos(self, number):\n",
    "        bits = []\n",
    "        for i, c in enumerate(bin(number)[:1:-1], 1):\n",
    "            if c == '0':\n",
    "                bits.append(i)\n",
    "        return bits\n",
    "\n",
    "    #Method to reset the costs of the last recommended combination\n",
    "    def reset_costs(self):\n",
    "        self.last_comb_cost = 0\n",
    "\n",
    "    #Returns the initial budget\n",
    "    def get_init_budget(self):\n",
    "        return self.budget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSelection\n",
    "#### This class is a subclass of the \"BaseStrategy\" class, representing a random item selection strategy for the sequential recommendation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSelection(BaseStrategy):\n",
    "    class_name = 'Random'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget)\n",
    "\n",
    "    # The _next_item method selects a random integer between 1 and the maximum length of the sequence. \n",
    "    # It checks if the integer is already in the set of visited integers, and if it is, selects another integer until a non-visited integer is found. \n",
    "    # Finally, the selected integer is added to the set of visited integers, and returned.\n",
    "    def _next_item(self):\n",
    "        self.budget -= 1\n",
    "        \n",
    "        number = random.sample(range(1, pow(2, self.max_length)), 1)[0]\n",
    "        while number in self.visited_:\n",
    "            number = random.sample(range(1, pow(2, self.max_length)), 1)[0]\n",
    "        self.visited_.add(number)\n",
    "        return number\n",
    "    \n",
    "    #The next_comb method generates a new sequence by removing items at positions indicated by the binary digits of the integer returned \n",
    "    # by _next_item from the original sequence of interactions. \n",
    "    # The resulting sequence, along with the current budget, is returned as a tuple.\n",
    "    def next_comb(self, reverse=False):\n",
    "        number = self._next_item()\n",
    "\n",
    "        bits = self._get_pos(number)\n",
    "        seq = np.delete(self.original_interactions, bits)\n",
    "\n",
    "        return (seq, self.budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LossSimilarSelection\n",
    "#### This class inherits frome the BaseStrategy class. This class defines a search strategy for selecting items based on their similarity to previously selected items, while also considering their loss (difference between predicted and actual values) in a ranking problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossSimilarSelection(BaseStrategy):\n",
    "    class_name = 'BFS'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, early_term=False):\n",
    "        \n",
    "        \n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model)\n",
    "\n",
    "        self.q = Queue()\n",
    "        self.q.enqueue(([False] * len(self.original_interactions), StaticVars.INT_MAX, 0))\n",
    "\n",
    "        self.thres = len(self.original_interactions) + 1\n",
    "        self.early_termination = early_term\n",
    "\n",
    "    # Helper : This method is called whenever a solution is found for the current \n",
    "    # mask of the items. It computes the loss of the solution and updates the queue \n",
    "    # accordingly.\n",
    "    def _update_queue(self, is_solved):\n",
    "        self.compute_loss(is_solved)\n",
    "\n",
    "    # Helper : \n",
    "    def _next_item(self):\n",
    "        mask, t_score, is_solved = self.q.dequeue()\n",
    "        while self.early_termination and sum(mask) == self.thres:\n",
    "            q_data = self.q.dequeue()\n",
    "            if q_data is None: break\n",
    "\n",
    "            mask, t_score, is_solved = q_data\n",
    "\n",
    "        if is_solved == 2:\n",
    "            t_score, kth_score = self.get_score(mask)\n",
    "\n",
    "            if (t_score / kth_score) < 1: self.thres = sum(mask)\n",
    "\n",
    "        return (is_solved, mask, self.budget)\n",
    "\n",
    "    # The next_comb method returns the next combination of items and the remaining budget.\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "\n",
    "        if self.q.size() > 0:\n",
    "            solved_flag, item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "            self._update_queue(solved_flag) #bug here\n",
    "        else: self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)\n",
    "\n",
    "    # This method computes the loss of the solution. If the solution is not yet solved, it searches for the next combination of items \n",
    "    # to evaluate by calling the search method. \n",
    "    # If the solution is solved, it searches for the previous combination of items by calling the search method with forward=False.\n",
    "    def compute_loss(self, is_solved=False):\n",
    "        self.last_comb_cost = 0\n",
    "\n",
    "        if not is_solved: self.search(forward=True, s=is_solved)\n",
    "        else: self.search(forward=False, s=is_solved)\n",
    "\n",
    "    def search(self, forward=True, s=False):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        valid_items = np.where(np.logical_not(m_mask) if forward else m_mask)[0]\n",
    "        if valid_items.size > 1:\n",
    "            for idx in valid_items:\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "                self.add(m_mask, s)\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "    # The get_score method returns the score of an item based on its predicted value and its rank among the top-k items.\n",
    "    def get_score(self, d):\n",
    "        perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=d))\n",
    "\n",
    "        self.budget -= 1\n",
    "        # predict next top-k items about to be selected\n",
    "        preds = self.model.predict(perm)\n",
    "        preds[perm] = -StaticVars.FLOAT_MAX\n",
    "        rk_data = st.rankdata(-preds, method='ordinal')\n",
    "\n",
    "        return (preds[self.target_item], preds[(rk_data == self.top_k).nonzero()][0])\n",
    "\n",
    "    # The add method adds a new combination to the queue and updates the visited set.\n",
    "    def add(self, d, s):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "            perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=d))\n",
    "\n",
    "            if not s:\n",
    "                t_score, kth_score = self.get_score(d)\n",
    "\n",
    "                if self.q.size() == 0: self.q.enqueue((d.copy(), t_score, 1 if (t_score / kth_score) < 1 else 0))\n",
    "\n",
    "                if t_score < self.q.get(0)[1]:  # get only the assigned score\n",
    "                    self.q.setter(0, (d.copy(), t_score, 1 if (t_score / kth_score) < 1 else 0))\n",
    "            else:\n",
    "                self.q.enqueue((d.copy(), StaticVars.INT_MAX, 2))\n",
    "\n",
    "            self.visited_.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiDirectionalSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiDirectionalSelection(BaseStrategy):\n",
    "    class_name = 'BiDirectional'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, weights=(1, 0), alpha=0.9, normalization='default'):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model)\n",
    "\n",
    "        self.tiebraker = itertools.count()\n",
    "        self.q = [(1, StaticVars.INT_MAX, next(self.tiebraker), [False] * len(self.original_interactions), self.budget)]\n",
    "        hq.heapify(self.q)\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.norm = normalization\n",
    "\n",
    "    def _update_queue(self, is_solved):\n",
    "        self.compute_loss(is_solved)\n",
    "\n",
    "    def _next_item(self):\n",
    "        is_solved, _, _, mask, budget = hq.heappop(self.q)\n",
    "        return (is_solved, mask, budget)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "        if self.q:\n",
    "            solved_flag, item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "            self._update_queue(solved_flag)\n",
    "        else: self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)\n",
    "\n",
    "    def compute_loss(self, is_solved=False):\n",
    "        self.search(forward=True, s=is_solved)\n",
    "        self.search(forward=False, s=is_solved)\n",
    "\n",
    "    def search(self, forward=True, s=False):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        valid_items = np.where(np.logical_not(m_mask) if forward else m_mask)[0]\n",
    "        if valid_items.size > 1:\n",
    "            for idx in valid_items:\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "                self.add(m_mask, s)\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "    def get_custom_score(self, c):\n",
    "        return c / self.max_length\n",
    "\n",
    "    def get_score(self, d):\n",
    "        self.budget -= 1\n",
    "\n",
    "        # predict next top-k items about to be selected\n",
    "        perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=d))\n",
    "        preds = self.model.predict(perm)\n",
    "\n",
    "        if self.norm == 'kth_norm':\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "            rk_data = st.rankdata(-preds, method='ordinal')\n",
    "\n",
    "            t_score = preds[self.target_item] / preds[(rk_data == self.top_k).nonzero()][0]\n",
    "        elif self.norm == 'rescale':\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "            rk_data = st.rankdata(-preds, method='ordinal')\n",
    "\n",
    "            max_val = rk_data[0]\n",
    "            min_val = rk_data[-1]\n",
    "            t_score = (max_val - preds[self.target_item]) / (max_val - min_val)\n",
    "        else:  # default case\n",
    "            tensor = F.softmax(torch.from_numpy(preds).float(), dim=0)\n",
    "            preds = tensor.numpy()\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "\n",
    "            t_score = preds[self.target_item]\n",
    "\n",
    "        return self.alpha * t_score + (1 - self.alpha) * self.get_custom_score(np.sum(d))\n",
    "\n",
    "    def add(self, d, s):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "            t_score = self.get_score(d)\n",
    "            hq.heappush(self.q, (int(not s), t_score, next(self.tiebraker), d.copy(), self.budget))\n",
    "\n",
    "            self.visited_.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BruteForceSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BruteForceSelection(BaseStrategy):\n",
    "    class_name = 'BruteForce'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model)\n",
    "\n",
    "        self.q = Queue()\n",
    "        self.q.enqueue(([False] * len(self.original_interactions), self.budget))\n",
    "\n",
    "    def _expand_queue(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        valid_items = np.where(np.logical_not(m_mask))[0]\n",
    "        if valid_items.size > 1:\n",
    "            for idx in valid_items:\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "                self.add(m_mask)\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "    def _next_item(self):\n",
    "        mask, budget = self.q.dequeue()\n",
    "        return (mask, budget)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "\n",
    "        if reverse: self.q.clear()\n",
    "\n",
    "        if self.q.size() > 0:\n",
    "            item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "            self._expand_queue()\n",
    "        else:\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)\n",
    "\n",
    "    def add(self, d):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "            self.budget -= 1\n",
    "            self.q.enqueue((d.copy(), self.budget))\n",
    "            self.visited_.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ComboSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComboSelection(BiDirectionalSelection):\n",
    "    class_name = 'Combo'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, weights=(1, 0), alpha=0.9, normalization='default'):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model, weights, alpha, normalization)\n",
    "\n",
    "        self.alpha = 1\n",
    "\n",
    "        self.q_init = Queue()\n",
    "        self.q_init.enqueue((StaticVars.INT_MAX, [False] * len(self.original_interactions), self.budget))\n",
    "        self.init_queue()\n",
    "\n",
    "        self.tiebraker = itertools.count()\n",
    "        self.q = []\n",
    "        hq.heapify(self.q)\n",
    "\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def init_queue(self):\n",
    "        _, m_mask, budget = self.q_init.dequeue()\n",
    "        m_mask = np.asarray(m_mask)\n",
    "\n",
    "        valid_items = np.where(np.logical_not(m_mask))[0]\n",
    "        for idx in valid_items:\n",
    "            m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "            mask_to_int = int(''.join(map(str, m_mask.astype(int))), 2)\n",
    "            if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "                t_score = self.get_score(m_mask)\n",
    "                self.q_init.enqueue((t_score, m_mask.copy(), self.budget))\n",
    "\n",
    "                self.visited_.add(mask_to_int)\n",
    "\n",
    "            m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "        pair_combs = []\n",
    "        for c in itertools.combinations(range(len(self.original_interactions)), 2):\n",
    "            m = [False] * len(self.original_interactions)\n",
    "            m[c[0]], m[c[1]] = not m[c[0]], not m[c[1]]\n",
    "            pair_combs.append((self.q_init.get(c[0])[0] + self.q_init.get(c[1])[0], m.copy()))\n",
    "\n",
    "        pair_combs.sort(key=operator.itemgetter(0))\n",
    "        for c in pair_combs:\n",
    "            self.budget -= 1\n",
    "            self.q_init.enqueue((0, c[1], self.budget))\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "\n",
    "        if self.q_init.size() > 0:\n",
    "            s, item_mask, budget = self.q_init.dequeue()\n",
    "            item_mask = np.asarray(item_mask)\n",
    "            solved_flag = False\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "\n",
    "            self.add(item_mask, False)\n",
    "        elif self.q:\n",
    "            solved_flag, item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "\n",
    "            self._update_queue(solved_flag)\n",
    "        else: self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get backend strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backend_strategy(backend):\n",
    "    if 'random' == backend:\n",
    "        return RandomSelection\n",
    "    elif 'most_sim' == backend:\n",
    "        return MostSimilarSelection\n",
    "    elif 'most_sim_jaccard' == backend:\n",
    "        return MostSimilarSelectionByJaccard\n",
    "    elif 'bfs' == backend:\n",
    "        return LossSimilarSelection\n",
    "    elif 'random_most_sim' == backend:\n",
    "        return RandomMostSimilarSelection\n",
    "    elif 'random_loss_sim' == backend:\n",
    "        return RandomLossSimilarSelection\n",
    "    elif 'fixed_loss_sim' == backend:\n",
    "        return FixedRankingLossSimilarSelection\n",
    "    elif 'dfs_loss_sim' == backend:\n",
    "        return DFSwithLossSelection\n",
    "    elif 'dfs_fixed_loss_sim' == backend:\n",
    "        return DFSwithFixedRankingLossSelection\n",
    "    elif 'bestFS_loss' == backend:\n",
    "        return BestFSLossSelection\n",
    "    elif 'bestFS_fixed_loss' == backend:\n",
    "        return BestFSFixedLossSelection\n",
    "    elif 'topdown_loss' == backend:\n",
    "        return TopDownBestFSLossSelection\n",
    "    elif 'bidirectional' == backend:\n",
    "        return BiDirectionalSelection\n",
    "    elif 'brute_force' == backend:\n",
    "        return BruteForceSelection\n",
    "    elif 'combo' == backend:\n",
    "        return ComboSelection\n",
    "    else: print('Unknown strategy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run implemented strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: Random\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SequenceInteractions' object has no attribute 'users_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$helpers_file\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m random_cfs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     10\u001b[0m \n\u001b[1;32m---> 11\u001b[0m     \u001b[43m_find_cfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_models\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlstm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_backend_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m17\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjaccard_sims_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_users\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_budget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11], negative_mode=True, sim_matrix=jaccard_sims_matrix, no_users= 10, init_budget=1000)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m ]\n\u001b[0;32m     15\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_cfs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14496\\1017300876.py:119\u001b[0m, in \u001b[0;36m_find_cfs\u001b[1;34m(dataset, model, strategy_func, target_item_pos, negative_mode, sim_matrix, no_users, init_budget, max_allowed_permutations, top_k, total_CFs, num_processes, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_find_cfs\u001b[39m(dataset, model, strategy_func, target_item_pos, negative_mode, sim_matrix, no_users\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_budget\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m    115\u001b[0m               max_allowed_permutations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, total_CFs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, num_processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe backend used is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrategy_func\u001b[38;5;241m.\u001b[39mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 119\u001b[0m     num_users \u001b[38;5;241m=\u001b[39m no_users \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43musers_ids\u001b[49m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    120\u001b[0m     best_tot_loss_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys(target_item_pos)\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(target_item_pos), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget position loop\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SequenceInteractions' object has no attribute 'users_ids'"
     ]
    }
   ],
   "source": [
    "# get currently working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# load functions from other notebooks\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb').replace(\"\\\\\", \"/\")\n",
    "%run $helpers_file\n",
    "\n",
    "backend = 'random'\n",
    "random_cfs = [\n",
    "\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users= 10, init_budget=1000)\n",
    "    # _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users= 10, init_budget=1000)\n",
    "]\n",
    "\n",
    "%store random_cfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BFS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f69f8145ed4fbbbd3562fe2a25f1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [00:14,  1.39it/s]              "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4075983a5be4c5ba70140cba14e5c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [00:29,  1.04s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e092ee0f750848d1bd92ccf6ae2a160e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [00:43,  1.19s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4bfb9e20df4b27815b869a9d21ddf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [00:57,  1.45s/it]\n",
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BFS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8d5d8f44c342fbaa966c48413a5259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [00:14,  1.43it/s]              "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26310d11ceee4fa79c026f6c339778cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [00:28,  1.03s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106c7d35e5974c988c4390227afeca0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [00:43,  1.19s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038e8b34e899424caecdfce83138d530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [00:57,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'bfs_yloss_cfs' (list)\n"
     ]
    }
   ],
   "source": [
    "backend = 'bfs'\n",
    "\n",
    "bfs_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users= 10, init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users= 10, init_budget=1000, early_term=True),\n",
    "]\n",
    "\n",
    "# %store bfs_yloss_cfs_positive\n",
    "%store bfs_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BiDirectional\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32027460aed04900915ab3586f7f2ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [12:48, 38.44s/it]              "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e5ce1b84f64937805e4e7b6a2de451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [27:08, 58.26s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cc8573a31e432a911f4f1609ed1e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [40:17, 65.95s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc60ee25c054f0bb0d0797c5a2e29eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [53:33, 80.34s/it]\n",
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BiDirectional\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e04179c9fa485888d3afd630cb375e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [12:15, 36.79s/it]              "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14dc5355b5144d32a5a8c12d5c844d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [24:49, 52.88s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f330a526ac8e41b6bed76f0be21e4bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [37:22, 61.25s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b911d0cdf9420aa164ab2ea46ad0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [49:31, 74.28s/it]\n",
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BiDirectional\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da186e425a64b358b7828834712b5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [12:01, 36.07s/it]              "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102936b7bc034e709329478aa76ded4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [23:23, 49.45s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef26d2646cf04616ac699d97fa77dcf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [34:28, 55.84s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cf324d2832482380d7558d512de74c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [45:16, 67.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'bidirectional_cfs' (list)\n"
     ]
    }
   ],
   "source": [
    "backend='bidirectional'\n",
    "\n",
    "bidirectional_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=10, init_budget=1000, alpha=1e-3, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=10, init_budget=1000, alpha=0.5, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=10, init_budget=1000, alpha=0.999, normalization='default'),\n",
    "]\n",
    "\n",
    "%store bidirectional_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: BruteForce\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9496ec9a224e17a32622f4d37ae251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [00:04,  4.70it/s]              "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a61e3b918a0407a9a783ba4aa65a4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [00:08,  3.28it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdf5a27d84040c28f8fe7e9f23fe23d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [00:12,  2.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917e09a76da3446292159ea2086956c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [00:17,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'brute_force_cfs' (list)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "backend='brute_force'\n",
    "\n",
    "brute_force_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=10, init_budget=100000),\n",
    "]\n",
    "\n",
    "%store brute_force_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: Combo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6e112516504e0c96690a586e675fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [14:50, 44.52s/it]              "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f90aab99b74bf2a3c6711e9eaffa9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [29:13, 61.93s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc3900827c946be9b705d114c87ac1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [44:22, 72.75s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b24c2bb8834d98aab3e7930227973c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [1:02:39, 94.00s/it]\n",
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: Combo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73b725986ad420e93c14d3e9d05a80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [14:01, 42.10s/it]              "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55dddab322f4241aa488d68821b1780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [34:50, 76.58s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64402f9e7e3e4f5ab5b3813b9ee2ae15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [48:10, 77.87s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15ea2a92d4a414d826f17f79a628fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [1:00:26, 90.66s/it]\n",
      "target position loop:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend used is: Combo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9692c6ccf33045c38a92978b45f497ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 20it [11:05, 33.30s/it]              "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3686ee2f79dd4e829beada165388b3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 30it [22:27, 47.80s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83c7ac1bebb4272988b5663276a6150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [33:50, 55.46s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d39d11172a41f2a8e05cbfc978d947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "users loop:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target position loop: 40it [45:14, 67.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'combo_cfs' (list)\n"
     ]
    }
   ],
   "source": [
    "backend='combo'\n",
    "combo_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=10, init_budget=1000, alpha=1e-3, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=10, init_budget=1000, alpha=0.5, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=10, init_budget=1000, alpha=0.999, normalization='default'),\n",
    "]\n",
    "\n",
    "%store combo_cfs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
