{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats as st\n",
    "import itertools\n",
    "import operator\n",
    "import heapq as hq\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get currently working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# load functions from other notebooks : helpers.ipynb contains a set of tools and functions used in this notebook\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb').replace(\"\\\\\", \"/\")\n",
    "%run $helpers_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['../spotlight_ext']:\n",
    "    module_path = os.path.abspath(os.path.join(base_dir, p))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "random_state = np.random.RandomState(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare models/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained models \"lstm\" (entire_model_1m_20interactions.pt) and \"pooling\" (pooling_model_1m_20interactions.pt) presents in the models folder\n",
    "\n",
    "# implicit_model = load_model('implicit_factorization')\n",
    "lstm_model = load_model(model_type='entire') # the code to create this model is in misc.ipynb (see section \"train model\")\n",
    "pooling_model = load_model('pooling') # the code to create this model is in brute_force_rec_expl.ipynb (see section \"train and save pooling model\")\n",
    "\n",
    "pretrained_models = {\n",
    "    'lstm': lstm_model,\n",
    "    'pooling': pooling_model,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset Movielens with the variant 1M. Then divide it into a training set and a testing set. It also limits the length of each sequence of elements in the 2 sets to 20.\n",
    "\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "\n",
    "# get dataset, more information here : https://grouplens.org/datasets/movielens/\n",
    "dataset = get_movielens_dataset(variant='1M')\n",
    "train, test = random_train_test_split(dataset, random_state=random_state)\n",
    "\n",
    "max_sequence_length = 20 # Maximum sequence length. Subsequences shorter than this will be left-padded with zeros.\n",
    "train = train.to_sequence(max_sequence_length=max_sequence_length)\n",
    "test = test.to_sequence(max_sequence_length=max_sequence_length) # test is a SequenceInteractions object, here is the documentation on this object : https://maciejkula.github.io/spotlight/interactions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2e2bf93c2d4d93a2cc6d95b139b4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute cosine similarity matrix for item embeddings using GPU\n",
    "pooling_sims_matrix = gpu_embeddings_to_cosine_similarity_matrix(\n",
    "    pooling_model._net.item_embeddings(\n",
    "        torch.arange(0, dataset.num_items, dtype=torch.int64)\n",
    "    )).detach().numpy()\n",
    "\n",
    "# Compute item-item similarity matrix using Jaccard similarity\n",
    "jaccard_sims_matrix = compute_sim_matrix(dataset, 'jaccard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e+00 1.03482099e-01 1.48905109e-01 ... 0.00000000e+00\n",
      " 5.79710145e-04 0.00000000e+00]\n",
      "[0.1034821  1.         0.13600783 ... 0.         0.         0.        ]\n",
      "(3706,)\n",
      "(3706,)\n"
     ]
    }
   ],
   "source": [
    "print(jaccard_sims_matrix[0])\n",
    "print(jaccard_sims_matrix[1])\n",
    "print(jaccard_sims_matrix[0].shape)\n",
    "print(jaccard_sims_matrix[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040\n",
      "1\n",
      "6041\n",
      "3706\n",
      "1\n",
      "3707\n"
     ]
    }
   ],
   "source": [
    "print(max(dataset.user_ids))\n",
    "print(min(dataset.user_ids))\n",
    "print(dataset.num_users)\n",
    "print(max(dataset.item_ids))\n",
    "print(min(dataset.item_ids))\n",
    "print(dataset.num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various implemented Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseStrategy:\n",
    "    class_name = None\n",
    "\n",
    "    def __init__(self, item, interactions, max_length, init_budget,  model=None, random_pick=False):\n",
    "\n",
    "        self.target_item = item\n",
    "        self.original_interactions = interactions\n",
    "        self.max_length = max_length\n",
    "        self.visited_ = set()\n",
    "        self.model = model\n",
    "        self.last_comb_cost = 0\n",
    "        self.random_pick = random_pick\n",
    "        self.top_k = 10\n",
    "        self.budget = init_budget\n",
    "\n",
    "    # Must be implemented by subclasses. Used to select the next item to recommand to the user.\n",
    "    def next_comb(self, reverse=False):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \n",
    "    # This method takes a \"number\" argument and returns a list of 0-bit positions in the binary representation of \"number\".\n",
    "    def _get_pos(self, number):\n",
    "        bits = []\n",
    "        for i, c in enumerate(bin(number)[:1:-1], 1):\n",
    "            if c == '0':\n",
    "                bits.append(i)\n",
    "        return bits\n",
    "\n",
    "    # Method to reset the costs of the last recommended combination\n",
    "    def reset_costs(self):\n",
    "        self.last_comb_cost = 0\n",
    "\n",
    "    # Returns the initial budget\n",
    "    def get_init_budget(self):\n",
    "        return self.budget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSelection\n",
    "#### This class is a subclass of the \"BaseStrategy\" class, representing a random item selection strategy for the sequential recommendation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSelection(BaseStrategy):\n",
    "    class_name = 'Random'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget)\n",
    "\n",
    "    # The _next_item method selects a random integer between 1 and 2 raised to the power of the maximum length of the sequence. \n",
    "    # It checks if the integer is already in the set of visited integers, and if it is, selects another integer until a non-visited integer is found. \n",
    "    # Finally, the selected integer is added to the set of visited integers, and returned.\n",
    "    def _next_item(self):\n",
    "        self.budget -= 1\n",
    "        \n",
    "        number = random.sample(range(1, pow(2, self.max_length)), 1)[0]\n",
    "        while number in self.visited_:\n",
    "            number = random.sample(range(1, pow(2, self.max_length)), 1)[0]\n",
    "        self.visited_.add(number)\n",
    "        \n",
    "        return number\n",
    "    \n",
    "    # The next_comb method generates a new sequence by removing items at positions indicated by the binary digits of the integer returned \n",
    "    # by _next_item from the original sequence of interactions. \n",
    "    # The resulting sequence, along with the current budget, is returned as a tuple.\n",
    "    def next_comb(self, reverse=False):\n",
    "        number = self._next_item()\n",
    "\n",
    "        bits = self._get_pos(number)\n",
    "        seq = np.delete(self.original_interactions, bits)\n",
    "\n",
    "        return (seq, self.budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LossSimilarSelection\n",
    "#### This class inherits from the BaseStrategy class. This class defines a search strategy for selecting items based on their similarity to previously selected items, while also considering their loss (difference between predicted and actual values) in a ranking problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossSimilarSelection(BaseStrategy):\n",
    "    class_name = 'BFS'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, early_term=False):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model)\n",
    "\n",
    "        mask = [False] * len(self.original_interactions)\n",
    "        t_score = StaticVars.INT_MAX\n",
    "        is_solved = 0\n",
    "\n",
    "        self.q = Queue()\n",
    "        self.q.enqueue((mask, t_score, is_solved))\n",
    "\n",
    "        self.thres = len(self.original_interactions) + 1\n",
    "        self.early_termination = early_term\n",
    "\n",
    "    # Helper : This method is called whenever a solution is found for the current \n",
    "    # mask of the items. It computes the loss of the solution and updates the queue \n",
    "    # accordingly.\n",
    "    def _update_queue(self, is_solved):\n",
    "        self.compute_loss(is_solved)\n",
    "\n",
    "    # Helper : \n",
    "    def _next_item(self):\n",
    "        mask, t_score, is_solved = self.q.dequeue()\n",
    "        while self.early_termination and sum(mask) == self.thres:\n",
    "            q_data = self.q.dequeue()\n",
    "            if q_data is None: \n",
    "                break\n",
    "            mask, t_score, is_solved = q_data\n",
    "\n",
    "        if is_solved == 2:\n",
    "            t_score, kth_score = self.get_score(mask)\n",
    "\n",
    "            if (t_score / kth_score) < 1: \n",
    "                self.thres = sum(mask)\n",
    "\n",
    "        return (is_solved, mask, self.budget)\n",
    "\n",
    "    # The next_comb method returns the next combination of items and the remaining budget.\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "\n",
    "        if self.q.size() > 0:\n",
    "            solved_flag, item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy()) # If there is a True in the mask, the value at the corresponding index is masked\n",
    "            self._update_queue(solved_flag)\n",
    "        else: \n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr) #Extract all the valid values in ma_arr\n",
    "        return (seq, budget) if len(seq) else (None, budget)\n",
    "\n",
    "    # This method computes the loss of the solution. If the solution is not yet solved, it searches for the next combination of items \n",
    "    # to evaluate by calling the search method. \n",
    "    # If the solution is solved, it searches for the previous combination of items by calling the search method with forward=False.\n",
    "    def compute_loss(self, is_solved=False):\n",
    "        self.last_comb_cost = 0\n",
    "\n",
    "        if not is_solved: \n",
    "            self.search(forward=True, s=is_solved)#\n",
    "        else: \n",
    "            self.search(forward=False, s=is_solved)\n",
    "\n",
    "    def search(self, forward=True, s=False):\n",
    "        \"\"\"\n",
    "        Searches for the next combination of items based on the search direction.\n",
    "\n",
    "        Args:\n",
    "            forward (bool, optional): If True, the search is performed forward, otherwise backward.\n",
    "            s (bool, optional): Indicates whether a solution is found.\n",
    "        \"\"\"\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        valid_items = np.where(np.logical_not(m_mask) if forward else m_mask)[0] #if forward is True it means we keep index of items where the m_mask is not True\n",
    "        if valid_items.size > 1:\n",
    "            for idx in valid_items:\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "                self.add(m_mask, s)\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "    def get_score(self, d):\n",
    "        \"\"\"\n",
    "        Computes the score of an item based on its predicted value and rank among the top-k items.\n",
    "\n",
    "        Args:\n",
    "            d (array_like): Boolean mask indicating the selected items.\n",
    "\n",
    "        Returns:\n",
    "            Tuple: A tuple containing the score of the target item and its rank among the top-k items.\n",
    "        \"\"\"\n",
    "        perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=d))\n",
    "\n",
    "        self.budget -= 1\n",
    "        # predict next top-k items about to be selected\n",
    "        preds = self.model.predict(perm)\n",
    "        preds[perm] = -StaticVars.FLOAT_MAX\n",
    "        rk_data = st.rankdata(-preds, method='ordinal')\n",
    "\n",
    "        return (preds[self.target_item], preds[(rk_data == self.top_k).nonzero()][0])\n",
    "\n",
    "    def add(self, d, s):\n",
    "        \"\"\"\n",
    "        Adds a new combination to the queue and updates the visited set.\n",
    "\n",
    "        Args:\n",
    "            d (array_like): Boolean mask representing the combination of items.\n",
    "            s (bool): Indicates whether a solution is found.\n",
    "        \"\"\"\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "            perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=d))\n",
    "\n",
    "            if not s:\n",
    "                t_score, kth_score = self.get_score(d)\n",
    "\n",
    "                if self.q.size() == 0: self.q.enqueue((d.copy(), t_score, 1 if (t_score / kth_score) < 1 else 0))\n",
    "\n",
    "                if t_score < self.q.get(0)[1]:  # get only the assigned score\n",
    "                    self.q.setter(0, (d.copy(), t_score, 1 if (t_score / kth_score) < 1 else 0))\n",
    "            else:\n",
    "                self.q.enqueue((d.copy(), StaticVars.INT_MAX, 2))\n",
    "\n",
    "            self.visited_.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiDirectionalSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiDirectionalSelection(BaseStrategy):\n",
    "    class_name = 'BiDirectional'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, weights=(1, 0), alpha=0.9, normalization='default'):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model)\n",
    "\n",
    "        self.tiebraker = itertools.count()\n",
    "        self.q = [(1, StaticVars.INT_MAX, next(self.tiebraker), [False] * len(self.original_interactions), self.budget)]\n",
    "        hq.heapify(self.q)\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.norm = normalization\n",
    "\n",
    "    def _update_queue(self, is_solved):\n",
    "        self.compute_loss(is_solved)\n",
    "\n",
    "    def _next_item(self):\n",
    "        is_solved, _, _, mask, budget = hq.heappop(self.q)\n",
    "        return (is_solved, mask, budget)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "        if self.q:\n",
    "            solved_flag, item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "            self._update_queue(solved_flag)\n",
    "        else: self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)\n",
    "\n",
    "    def compute_loss(self, is_solved=False):\n",
    "        self.search(forward=True, s=is_solved)\n",
    "        self.search(forward=False, s=is_solved)\n",
    "\n",
    "    def search(self, forward=True, s=False):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        valid_items = np.where(np.logical_not(m_mask) if forward else m_mask)[0]\n",
    "        if valid_items.size > 1:\n",
    "            for idx in valid_items:\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "                self.add(m_mask, s)\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "    def get_custom_score(self, c):\n",
    "        return c / self.max_length\n",
    "\n",
    "    def get_score(self, d):\n",
    "        self.budget -= 1\n",
    "\n",
    "        # predict next top-k items about to be selected\n",
    "        perm = np.ma.compressed(np.ma.masked_array(self.original_interactions, mask=d))\n",
    "        preds = self.model.predict(perm)\n",
    "\n",
    "        if self.norm == 'kth_norm':\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "            rk_data = st.rankdata(-preds, method='ordinal')\n",
    "\n",
    "            t_score = preds[self.target_item] / preds[(rk_data == self.top_k).nonzero()][0]\n",
    "        elif self.norm == 'rescale':\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "            rk_data = st.rankdata(-preds, method='ordinal')\n",
    "\n",
    "            max_val = rk_data[0]\n",
    "            min_val = rk_data[-1]\n",
    "            t_score = (max_val - preds[self.target_item]) / (max_val - min_val)\n",
    "        else:  # default case\n",
    "            tensor = F.softmax(torch.from_numpy(preds).float(), dim=0)\n",
    "            preds = tensor.numpy()\n",
    "            preds[perm] = -StaticVars.FLOAT_MAX\n",
    "\n",
    "            t_score = preds[self.target_item]\n",
    "\n",
    "        return self.alpha * t_score + (1 - self.alpha) * self.get_custom_score(np.sum(d))\n",
    "\n",
    "    def add(self, d, s):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "            t_score = self.get_score(d)\n",
    "            hq.heappush(self.q, (int(not s), t_score, next(self.tiebraker), d.copy(), self.budget))\n",
    "\n",
    "            self.visited_.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BruteForceSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BruteForceSelection(BaseStrategy):\n",
    "    class_name = 'BruteForce'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model)\n",
    "\n",
    "        self.q = Queue()\n",
    "        self.q.enqueue(([False] * len(self.original_interactions), self.budget))\n",
    "\n",
    "    def _expand_queue(self):\n",
    "        m_mask = np.ma.getmask(self.ma_arr).copy()\n",
    "        valid_items = np.where(np.logical_not(m_mask))[0]\n",
    "        if valid_items.size > 1:\n",
    "            for idx in valid_items:\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "                self.add(m_mask)\n",
    "                m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "    def _next_item(self):\n",
    "        mask, budget = self.q.dequeue()\n",
    "        return (mask, budget)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "\n",
    "        if reverse: self.q.clear()\n",
    "\n",
    "        if self.q.size() > 0:\n",
    "            item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "            self._expand_queue()\n",
    "        else:\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)\n",
    "\n",
    "    def add(self, d):\n",
    "        mask_to_int = int(''.join(map(str, d.astype(int))), 2)\n",
    "        if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "            self.budget -= 1\n",
    "            self.q.enqueue((d.copy(), self.budget))\n",
    "            self.visited_.add(mask_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ComboSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComboSelection(BiDirectionalSelection):\n",
    "    class_name = 'Combo'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, init_budget, model, weights=(1, 0), alpha=0.9, normalization='default'):\n",
    "        super().__init__(item, interactions, max_sequence_length, init_budget, model, weights, alpha, normalization)\n",
    "\n",
    "        self.alpha = 1\n",
    "\n",
    "        self.q_init = Queue()\n",
    "        self.q_init.enqueue((StaticVars.INT_MAX, [False] * len(self.original_interactions), self.budget))\n",
    "        self.init_queue()\n",
    "\n",
    "        self.tiebraker = itertools.count()\n",
    "        self.q = []\n",
    "        hq.heapify(self.q)\n",
    "\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def init_queue(self):\n",
    "        _, m_mask, budget = self.q_init.dequeue()\n",
    "        m_mask = np.asarray(m_mask)\n",
    "\n",
    "        valid_items = np.where(np.logical_not(m_mask))[0]\n",
    "        for idx in valid_items:\n",
    "            m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "            mask_to_int = int(''.join(map(str, m_mask.astype(int))), 2)\n",
    "            if (mask_to_int not in self.visited_) and (self.budget > 0):\n",
    "                t_score = self.get_score(m_mask)\n",
    "                self.q_init.enqueue((t_score, m_mask.copy(), self.budget))\n",
    "\n",
    "                self.visited_.add(mask_to_int)\n",
    "\n",
    "            m_mask[idx] = not m_mask[idx]\n",
    "\n",
    "        pair_combs = []\n",
    "        for c in itertools.combinations(range(len(self.original_interactions)), 2):\n",
    "            m = [False] * len(self.original_interactions)\n",
    "            m[c[0]], m[c[1]] = not m[c[0]], not m[c[1]]\n",
    "            pair_combs.append((self.q_init.get(c[0])[0] + self.q_init.get(c[1])[0], m.copy()))\n",
    "\n",
    "        pair_combs.sort(key=operator.itemgetter(0))\n",
    "        for c in pair_combs:\n",
    "            self.budget -= 1\n",
    "            self.q_init.enqueue((0, c[1], self.budget))\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        budget = self.budget\n",
    "\n",
    "        if self.q_init.size() > 0:\n",
    "            s, item_mask, budget = self.q_init.dequeue()\n",
    "            item_mask = np.asarray(item_mask)\n",
    "            solved_flag = False\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "\n",
    "            self.add(item_mask, False)\n",
    "        elif self.q:\n",
    "            solved_flag, item_mask, budget = self._next_item()\n",
    "            self.ma_arr = np.ma.masked_array(self.original_interactions, mask=item_mask.copy())\n",
    "\n",
    "            self._update_queue(solved_flag)\n",
    "        else: self.ma_arr = np.ma.masked_array(self.original_interactions, mask=True)\n",
    "\n",
    "        seq = np.ma.compressed(self.ma_arr)\n",
    "        return (seq, budget) if len(seq) else (None, budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporary code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MostSimilarSelection(BaseStrategy):\n",
    "    class_name = 'Sim-Matrix'\n",
    "\n",
    "    supported_sim_matrix = {\n",
    "        'pooling': pooling_sims_matrix,\n",
    "        'jaccard': jaccard_sims_matrix\n",
    "    }\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, model, sim_type='pooling'):\n",
    "        super().__init__(item, interactions, max_sequence_length)\n",
    "\n",
    "        self.visited_.add(0)\n",
    "        self.reverse_checks = []\n",
    "        self.is_materialized = False\n",
    "\n",
    "        self._get_sim_ranking(sim_type)\n",
    "\n",
    "    def next_comb(self, reverse=False):\n",
    "        if reverse:\n",
    "            self._materialize_list()\n",
    "            selected_item_indices = self.reverse_checks.pop(\n",
    "                random.randrange(len(self.reverse_checks)) if self.random_pick else 0\n",
    "            ) if len(self.reverse_checks) else []\n",
    "        else:\n",
    "            self.visited_.add(max(self.visited_) + 1)\n",
    "            selected_item_indices = np.where(np.isin(\n",
    "                self.rk_items,\n",
    "                list(set(self.rk_items).difference(set(self.visited_)))\n",
    "            ))[0]\n",
    "        seq = self.original_interactions[selected_item_indices] if len(selected_item_indices) else None\n",
    "        return seq\n",
    "\n",
    "    def _get_sim_ranking(self, sim_type):\n",
    "        ranked_items = st.rankdata(self.supported_sim_matrix[sim_type][self.target_item, self.original_interactions])\n",
    "        self.rk_items = self.max_length - ranked_items + 1\n",
    "\n",
    "    def _materialize_list(self):\n",
    "        if not self.is_materialized:\n",
    "            psize = len(self.visited_) - 1  # do not consider initial added zero value\n",
    "            # do not take account none/all excluded interacted items\n",
    "            prods = sorted(list(map(list, itertools.product([0, 1], repeat=psize)))[1:-1], key=sum)\n",
    "#             last_item_indices = np.where(np.isin(\n",
    "#                 self.rk_items,\n",
    "#                 list(set(self.rk_items).difference(set(self.visited_)))\n",
    "#             ))\n",
    "\n",
    "            lvisited_ = np.asarray(list(self.visited_))[1:]\n",
    "            for p in prods:\n",
    "                self.reverse_checks.append(np.where(np.isin(\n",
    "                    self.rk_items,\n",
    "                    list(set(self.rk_items).difference(lvisited_[np.nonzero(np.multiply(p, lvisited_))])))\n",
    "                ))\n",
    "\n",
    "            self.is_materialized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MostSimilarSelectionByJaccard(MostSimilarSelection):\n",
    "    class_name = 'Jaccard-on-Sim-Matrix'\n",
    "\n",
    "    def __init__(self, item, interactions, max_sequence_length, model):\n",
    "        super().__init__(item, interactions, max_sequence_length, model, 'jaccard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine_on_embeddings_cfs = [\n",
    "#     _find_cfs(test, pretrained_models['lstm'], [3, 5, 7], no_users=500, backend='most_sim', init_budget=1000),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='most_sim', init_budget=1000)\n",
    "# ]\n",
    "# jaccard_on_embeddings_cfs = [\n",
    "#     _find_cfs(test, pretrained_models['lstm'], [3, 5, 7], no_users=500, backend='most_sim_jaccard', init_budget=1000),\n",
    "#     _find_cfs(test, pretrained_models['pooling'], [3, 5, 7], no_users=500, backend='most_sim_jaccard', init_budget=1000),\n",
    "# ]\n",
    "\n",
    "# %store cosine_on_embeddings_cfs\n",
    "# %store jaccard_on_embeddings_cfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get backend strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backend_strategy(backend):\n",
    "    if 'random' == backend:\n",
    "        return RandomSelection\n",
    "    elif 'most_sim' == backend:\n",
    "        return MostSimilarSelection\n",
    "    elif 'most_sim_jaccard' == backend:\n",
    "        return MostSimilarSelectionByJaccard\n",
    "    elif 'bfs' == backend:\n",
    "        return LossSimilarSelection\n",
    "    elif 'random_most_sim' == backend:\n",
    "        return RandomMostSimilarSelection\n",
    "    elif 'random_loss_sim' == backend:\n",
    "        return RandomLossSimilarSelection\n",
    "    elif 'fixed_loss_sim' == backend:\n",
    "        return FixedRankingLossSimilarSelection\n",
    "    elif 'dfs_loss_sim' == backend:\n",
    "        return DFSwithLossSelection\n",
    "    elif 'dfs_fixed_loss_sim' == backend:\n",
    "        return DFSwithFixedRankingLossSelection\n",
    "    elif 'bestFS_loss' == backend:\n",
    "        return BestFSLossSelection\n",
    "    elif 'bestFS_fixed_loss' == backend:\n",
    "        return BestFSFixedLossSelection\n",
    "    elif 'topdown_loss' == backend:\n",
    "        return TopDownBestFSLossSelection\n",
    "    elif 'bidirectional' == backend:\n",
    "        return BiDirectionalSelection\n",
    "    elif 'brute_force' == backend:\n",
    "        return BruteForceSelection\n",
    "    elif 'combo' == backend:\n",
    "        return ComboSelection\n",
    "    else: print('Unknown strategy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run implemented strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258e1800e88b48999d9ca43c64c76e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty 5\n",
      "empty 8\n",
      "empty 58\n",
      "empty 58\n",
      "empty 93\n",
      "empty 132\n",
      "empty 132\n",
      "empty 203\n",
      "empty 232\n",
      "empty 260\n",
      "empty 260\n",
      "empty 300\n",
      "empty 300\n",
      "empty 454\n",
      "empty 563\n",
      "empty 563\n",
      "empty 673\n",
      "empty 689\n",
      "empty 702\n",
      "empty 728\n",
      "empty 731\n",
      "empty 732\n",
      "empty 774\n",
      "empty 869\n",
      "empty 1050\n",
      "empty 1050\n",
      "empty 1100\n",
      "empty 1155\n",
      "empty 1206\n",
      "empty 1219\n",
      "empty 1221\n",
      "empty 1221\n",
      "empty 1263\n",
      "empty 1287\n",
      "empty 1347\n",
      "empty 1395\n",
      "empty 1490\n",
      "empty 1592\n",
      "empty 1600\n",
      "empty 1616\n",
      "empty 1616\n",
      "empty 1616\n",
      "empty 1667\n",
      "empty 1701\n",
      "empty 1722\n",
      "empty 1726\n",
      "empty 1726\n",
      "empty 1741\n",
      "empty 1758\n",
      "empty 1803\n",
      "empty 1803\n",
      "empty 1894\n",
      "empty 2021\n",
      "empty 2021\n",
      "empty 2029\n",
      "empty 2173\n",
      "empty 2221\n",
      "empty 2263\n",
      "empty 2279\n",
      "empty 2352\n",
      "empty 2368\n",
      "empty 2410\n",
      "empty 2445\n",
      "empty 2463\n",
      "empty 2692\n",
      "empty 2731\n",
      "empty 2738\n",
      "empty 2757\n",
      "empty 2761\n",
      "empty 2761\n",
      "empty 3026\n",
      "empty 3075\n",
      "empty 3079\n",
      "empty 3121\n",
      "empty 3148\n",
      "empty 3197\n",
      "empty 3210\n",
      "empty 3227\n",
      "empty 3237\n",
      "empty 3290\n",
      "empty 3301\n",
      "empty 3312\n",
      "empty 3476\n",
      "empty 3477\n",
      "empty 3528\n",
      "empty 3532\n",
      "empty 3538\n",
      "empty 3538\n",
      "empty 3538\n",
      "empty 3726\n",
      "empty 3763\n",
      "empty 3770\n",
      "empty 3770\n",
      "empty 3771\n",
      "empty 3791\n",
      "empty 3806\n",
      "empty 3807\n",
      "empty 3851\n",
      "empty 3874\n",
      "empty 3892\n",
      "empty 3900\n",
      "empty 3902\n",
      "empty 3903\n",
      "empty 3968\n",
      "empty 3968\n",
      "empty 4022\n",
      "empty 4041\n",
      "empty 4093\n",
      "empty 4094\n",
      "empty 4094\n",
      "empty 4094\n",
      "empty 4130\n",
      "empty 4130\n",
      "empty 4161\n",
      "empty 4171\n",
      "empty 4272\n",
      "empty 4292\n",
      "empty 4371\n",
      "empty 4430\n",
      "empty 4485\n",
      "empty 4485\n",
      "empty 4522\n",
      "empty 4569\n",
      "empty 4593\n",
      "empty 4605\n",
      "empty 4619\n",
      "empty 4705\n",
      "empty 5029\n",
      "empty 5077\n",
      "empty 5100\n",
      "empty 5131\n",
      "empty 5178\n",
      "empty 5287\n",
      "empty 5287\n",
      "empty 5319\n",
      "empty 5333\n",
      "empty 5352\n",
      "empty 5561\n",
      "empty 5598\n",
      "empty 5653\n",
      "empty 5679\n",
      "empty 5728\n",
      "empty 5752\n",
      "empty 5759\n",
      "empty 5787\n",
      "empty 5806\n",
      "empty 5824\n",
      "empty 5888\n",
      "empty 5894\n",
      "empty 5998\n",
      "empty 5998\n",
      "empty 6007\n",
      "empty 6036\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "# get currently working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# load functions from other notebooks\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb').replace(\"\\\\\", \"/\")\n",
    "%run $helpers_file\n",
    "\n",
    "def replace_items_if_missing(items_removed, target_list):\n",
    "    items_to_replace = set(items_removed) - set(target_list)\n",
    "    for i, item in enumerate(items_to_replace):\n",
    "        j = i\n",
    "        while target_list[j] in items_removed:\n",
    "            j += 1\n",
    "        target_list[j] = item\n",
    "\n",
    "def create_reverse_mode_evaluation_dataframe(dataset, model, strategy, target_item_pos, top_k, sim_matrix):\n",
    "    evaluation_df = pd.DataFrame(columns=['user_id', 'target_pos', 'cfs', 'len_cfs', 'worst_jacc_cfs', 'len_worst_jacc_cfs'])#, 'jacc_cfs', 'len_jacc_cfs', 'rs_cfs', 'len_rs_cfs'])\n",
    "    len_sample = 20\n",
    "\n",
    "    for user_id in tqdm.notebook.tqdm(range(1, max(dataset.user_ids))):\n",
    "        for target_pos in target_item_pos:\n",
    "            specific_cfs = _find_specific_cfs_(dataset, model, strategy, target_pos, False, sim_matrix, user_id, 1000, top_k, alpha=0.5, normalization='default')\n",
    "            \n",
    "            user_sequences = test.sequences[test.user_ids == user_id]\n",
    "            \n",
    "            for j in range (min(1, len(user_sequences))):\n",
    "                if all(v > 0 for v in user_sequences[j]):\n",
    "                    original_interactions = user_sequences[j].copy()\n",
    "                    best_interactions = specific_cfs[j].interactions['best']\n",
    "                    items_removed = np.setdiff1d(original_interactions, best_interactions)\n",
    "\n",
    "                    predictions = -pretrained_models['lstm'].predict(original_interactions)\n",
    "                    predictions[original_interactions] = StaticVars.FLOAT_MAX\n",
    "                    target_item = predictions.argsort()[min(top_k, target_pos)]\n",
    "                    if len(best_interactions) == 0 : \n",
    "                        print(\"empty\", user_id)\n",
    "                        evaluation_df = evaluation_df.append([user_id, target_pos, items_removed, len(items_removed), None, None])\n",
    "                        break\n",
    "                    predictions_reverse = -pretrained_models['lstm'].predict(best_interactions)\n",
    "                    predictions_reverse[best_interactions] = StaticVars.FLOAT_MAX\n",
    "                    # pos_target_item_reverse = np.where(predictions_reverse.argsort() == target_item)[0][0] #bug maybe?\n",
    "                    worst_jaccard_sample = find_worst_items_with_jaccard(target_item, best_interactions, jaccard_sims_matrix, len_sample)\n",
    "                    # jaccard_sample = find_best_items_with_jaccard(target_item, best_interactions, jaccard_sims_matrix, len_sample)\n",
    "                    # rs_sample = find_best_items_using_recommender(target_item, best_interactions, pretrained_models['lstm'], len_sample)\n",
    "\n",
    "                    if len(items_removed) >= len_sample:\n",
    "                        print(f\"Sequence skipped, too much items removed for user_id {user_id}.\")\n",
    "                        continue\n",
    "                    \n",
    "                    # if not set(items_removed) <= set(jaccard_sample):\n",
    "                        # replace_items_if_missing(items_removed, jaccard_sample)\n",
    "                        # jacc_search_info = retrieve_solutions_specific_sequence(user_id, test, pretrained_models['lstm'], get_backend_strategy('combo'), 1000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, jaccard_sample, alpha=0.5)\n",
    "# \n",
    "                    # if not set(items_removed) <= set(rs_sample):\n",
    "                        # replace_items_if_missing(items_removed, rs_sample)\n",
    "                        # rs_search_info = retrieve_solutions_specific_sequence(user_id, test, pretrained_models['lstm'], get_backend_strategy('combo'), 1000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, rs_sample, alpha=0.5)\n",
    "\n",
    "                    if not set(items_removed) <= set(worst_jaccard_sample):\n",
    "                        replace_items_if_missing(items_removed, worst_jaccard_sample)\n",
    "                        worst_jacc_search_info = retrieve_solutions_specific_sequence(user_id, test, pretrained_models['lstm'], get_backend_strategy('combo'), 1000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, worst_jaccard_sample, alpha=0.5)\n",
    "\n",
    "                    evaluation_df = evaluation_df.append([user_id, target_pos, items_removed, len(items_removed), worst_jacc_search_info[j].interactions['best'], len(worst_jacc_search_info[j].interactions['best'])])#, jacc_search_info[0].interactions['best'], len(jacc_search_info[0].interactions['best']), rs_search_info[0].interactions['best'], len(rs_search_info[0].interactions['best'])])\n",
    "    return evaluation_df\n",
    "df = create_reverse_mode_evaluation_dataframe(test, pretrained_models['lstm'], get_backend_strategy('combo'), [1, 3, 5, 7], 10, jaccard_sims_matrix)\n",
    "%store df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                123\n",
       "target_pos               A\n",
       "cfs                      5\n",
       "len_cfs                 10\n",
       "worst_jacc_cfs        0.75\n",
       "len_worst_jacc_cfs       8\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_df = pd.DataFrame(columns=['user_id', 'target_pos', 'cfs', 'len_cfs', 'worst_jacc_cfs', 'len_worst_jacc_cfs'])\n",
    "nouvelle_ligne = {'user_id': 123, 'target_pos': 'A', 'cfs': 5, 'len_cfs': 10, 'worst_jacc_cfs': 0.75, 'len_worst_jacc_cfs': 8}\n",
    "evaluation_df = evaluation_df.append(nouvelle_ligne, ignore_index=True)\n",
    "evaluation_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826222f361c64e75b4805503e53d6b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o [230 257 359 130 358 329 372 227 324 301 253 239 107 305 266 315  60 331\n",
      " 123 357]\n",
      "b []\n",
      "empty 5\n",
      "o [230 257 359 130 358 329 372 227 324 301 253 239 107 305 266 315  60 331\n",
      " 123 357]\n",
      "b [230 257 359 130 358 329 227 324 253 239 107 305  60 331 123 357]\n",
      "o [230 257 359 130 358 329 372 227 324 301 253 239 107 305 266 315  60 331\n",
      " 123 357]\n",
      "b [230 257 359 130 358 329 372 227 324 253 239 107 305 266 315  60 331 123\n",
      " 357]\n",
      "o [230 257 359 130 358 329 372 227 324 301 253 239 107 305 266 315  60 331\n",
      " 123 357]\n",
      "b [257 359 130 358 329 372 227 324 301 253 239 107 305 266 315  60 331 123\n",
      " 357]\n",
      "o [384 461 236 478  86 457 511  60 323 443 360 473 472 514 456 481 119 450\n",
      " 453 444]\n",
      "b []\n",
      "empty 8\n",
      "o [384 461 236 478  86 457 511  60 323 443 360 473 472 514 456 481 119 450\n",
      " 453 444]\n",
      "b [384 461 236 478  86 457 511  60 323 443 360 473 472 514 481 119 450 453]\n",
      "o [384 461 236 478  86 457 511  60 323 443 360 473 472 514 456 481 119 450\n",
      " 453 444]\n",
      "b [384 461 236 478  86 457 511  60 323 443 360 473 472 514 456 481 119 453]\n",
      "o [384 461 236 478  86 457 511  60 323 443 360 473 472 514 456 481 119 450\n",
      " 453 444]\n",
      "b [384 461 236 478  86 457 511  60 323 443 360 473 472 514 456 481 119 450\n",
      " 453]\n",
      "o [ 24 105 126 523 268  22 337  40 506 318 317  90 539 227 273 114 549 323\n",
      " 529  94]\n",
      "b [ 24 105 126 523 268  22 337  40 506 318 317  90 539 227 273 114 549 323\n",
      " 529]\n",
      "o [ 24 105 126 523 268  22 337  40 506 318 317  90 539 227 273 114 549 323\n",
      " 529  94]\n",
      "b [ 24 105 126 523 268  22 337  40 506 318 317  90 539 227 273 114 549 323\n",
      " 529]\n",
      "o [ 24 105 126 523 268  22 337  40 506 318 317  90 539 227 273 114 549 323\n",
      " 529  94]\n",
      "b [ 24 105 126 523 268  22 337  40 506 318 317  90 539 227 114 549 323 529]\n",
      "o [ 24 105 126 523 268  22 337  40 506 318 317  90 539 227 273 114 549 323\n",
      " 529  94]\n",
      "b [ 24 105 126 523 268  22 337  40 506 318 317  90 539 227 273 114 549 323\n",
      " 529]\n",
      "o [539 734 647 759 742  20 592 569 563  22  42 612 671  15 547 613  11 662\n",
      " 435 660]\n",
      "b [539 734 647 759 742  20 592 569 563  22  42 612 671  15 547 613  11 660]\n",
      "o [539 734 647 759 742  20 592 569 563  22  42 612 671  15 547 613  11 662\n",
      " 435 660]\n",
      "b [539 734 647 759 742  20 592 569 563  22  42 612 671  15 547 613  11 662\n",
      " 435]\n",
      "o [539 734 647 759 742  20 592 569 563  22  42 612 671  15 547 613  11 662\n",
      " 435 660]\n",
      "b [539 734 647 759 742  20 592 569 563  22  42 612 671  15 547 613  11 435\n",
      " 660]\n",
      "o [539 734 647 759 742  20 592 569 563  22  42 612 671  15 547 613  11 662\n",
      " 435 660]\n",
      "b [539 734 647 759 742  20 592 569 563  22  42 612 671  15 547  11 662 435\n",
      " 660]\n",
      "o [746 165 507 292 397 466 531 306 789 185  68  50 829 799 601 807 639 704\n",
      " 823 684]\n",
      "b [746 165 507 292 397 466 531 306 789 185  68 829 799 601 807 639 704 823\n",
      " 684]\n",
      "o [746 165 507 292 397 466 531 306 789 185  68  50 829 799 601 807 639 704\n",
      " 823 684]\n",
      "b [746 165 507 292 397 466 531 306 789 185  68  50 829 799 601 807 639 704\n",
      " 823]\n",
      "o [746 165 507 292 397 466 531 306 789 185  68  50 829 799 601 807 639 704\n",
      " 823 684]\n",
      "b [746 165 507 292 397 466 531 306 789  68  50 829 799 807 639 704 823 684]\n",
      "o [746 165 507 292 397 466 531 306 789 185  68  50 829 799 601 807 639 704\n",
      " 823 684]\n",
      "b [746 165 507 292 397 466 531 306 789 185  68 829 799 601 807 639 704 823\n",
      " 684]\n",
      "o [117 471 377  91 399  21 872 901 926 826 123 515 922  94 894 915 851 188\n",
      " 125 623]\n",
      "b [117 471 377  91 399  21 872 901 926 826 123 515 922  94 894 915 851 188\n",
      " 623]\n",
      "o [117 471 377  91 399  21 872 901 926 826 123 515 922  94 894 915 851 188\n",
      " 125 623]\n",
      "b [117 471 377  91 399  21 872 901 926 826 123 515 922  94 894 851 188 125\n",
      " 623]\n",
      "o [117 471 377  91 399  21 872 901 926 826 123 515 922  94 894 915 851 188\n",
      " 125 623]\n",
      "b [117 471 377  91 399  21 872 901 926 826 123 515 922  94 915 851 188 125\n",
      " 623]\n",
      "o [117 471 377  91 399  21 872 901 926 826 123 515 922  94 894 915 851 188\n",
      " 125 623]\n",
      "b [117 471 377  91 399  21 872 901 926 826 123 515 922 894 915 851 188 125\n",
      " 623]\n",
      "o [ 373   11  960  117  150  118  349   21   91  377  741  749  278  323\n",
      "  990 1009  529  970  978 1010]\n",
      "b [ 373   11  960  117  150  118  349   21  377  741  749  278  323  990\n",
      " 1009  970  978 1010]\n",
      "o [ 373   11  960  117  150  118  349   21   91  377  741  749  278  323\n",
      "  990 1009  529  970  978 1010]\n",
      "b [ 373   11  960  117  150  118  349   21   91  377  741  749  278  323\n",
      "  990 1009  529  978 1010]\n",
      "o [ 373   11  960  117  150  118  349   21   91  377  741  749  278  323\n",
      "  990 1009  529  970  978 1010]\n",
      "b [ 373   11  960  117  150  118  349   21   91  377  741  749  278  323\n",
      "  990 1009  970  978 1010]\n",
      "o [ 373   11  960  117  150  118  349   21   91  377  741  749  278  323\n",
      "  990 1009  529  970  978 1010]\n",
      "b [ 373   11  960  117  150  118  349   21   91  377  741  749  278  323\n",
      "  990 1009  529  970 1010]\n",
      "o [  31 1044 1061 1051  567  402 1109  260  245   58  475  105 1099  795\n",
      "  951 1050  471  354  686  417]\n",
      "b [  31 1044 1061 1051  567  402 1109  260  245   58  475  105 1099  795\n",
      "  951 1050  354  686]\n",
      "o [  31 1044 1061 1051  567  402 1109  260  245   58  475  105 1099  795\n",
      "  951 1050  471  354  686  417]\n",
      "b [  31 1044 1061 1051  567  402 1109  260  245   58  475  105  795 1050\n",
      "  471  354  686  417]\n",
      "o [  31 1044 1061 1051  567  402 1109  260  245   58  475  105 1099  795\n",
      "  951 1050  471  354  686  417]\n",
      "b [  31 1044 1061 1051  567  402 1109  260  245   58  475 1099  795  951\n",
      " 1050  354  686  417]\n",
      "o [  31 1044 1061 1051  567  402 1109  260  245   58  475  105 1099  795\n",
      "  951 1050  471  354  686  417]\n",
      "b [  31 1044 1061 1051  567  402 1109  245   58  475  105 1099  795  951\n",
      " 1050  471  354  686  417]\n",
      "o [1047  506  601  316  689  117  995  539  433  971  874  353  232  520\n",
      "  733  156   14 1161 1128 1058]\n",
      "b [1047  506  601  316  689  117  995  539  433  971  874  353  232  733\n",
      "  156   14 1161 1058]\n",
      "o [1047  506  601  316  689  117  995  539  433  971  874  353  232  520\n",
      "  733  156   14 1161 1128 1058]\n",
      "b [1047  506  601  316  689  117  995  539  433  971  874  353  232  520\n",
      "  733  156   14 1161 1128]\n",
      "o [1047  506  601  316  689  117  995  539  433  971  874  353  232  520\n",
      "  733  156   14 1161 1128 1058]\n",
      "b [1047  506  601  316  689  117  995  539  433  971  874  353  232  733\n",
      "  156   14 1161 1128 1058]\n",
      "o [1047  506  601  316  689  117  995  539  433  971  874  353  232  520\n",
      "  733  156   14 1161 1128 1058]\n",
      "b [1047  506  601  316  689  117  995  539  433  971  353  232  520  733\n",
      "  156   14 1161 1128 1058]\n",
      "Stored 'df2' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "# get currently working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# load functions from other notebooks\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb').replace(\"\\\\\", \"/\")\n",
    "%run $helpers_file\n",
    "\n",
    "def replace_items_if_missing(items_removed, target_list):\n",
    "    items_to_replace = set(items_removed) - set(target_list)\n",
    "    for i, item in enumerate(items_to_replace):\n",
    "        j = i\n",
    "        while target_list[j] in items_removed:\n",
    "            j += 1\n",
    "        target_list[j] = item\n",
    "    # should maybe shuffle?\n",
    "\n",
    "def create_reverse_mode_evaluation_dataframe(dataset, model, strategy, target_item_pos, top_k, sim_matrix):\n",
    "    evaluation_df = pd.DataFrame(columns=['user_id', 'target_pos', 'original_interactions', 'cfs', 'len_cfs', 'worst_jacc_sample', 'worst_jacc_cfs', 'len_worst_jacc_cfs'])#, 'jacc_cfs', 'len_jacc_cfs', 'rs_cfs', 'len_rs_cfs'])\n",
    "    len_sample = 20\n",
    "\n",
    "    for user_id in tqdm.notebook.tqdm(range(1, 20)):\n",
    "        for target_pos in target_item_pos:\n",
    "            specific_cfs = _find_specific_cfs_(dataset, model, strategy, target_pos, False, sim_matrix, user_id, 1000, top_k, alpha=0.5, normalization='default')\n",
    "            \n",
    "            user_sequences = test.sequences[test.user_ids == user_id]\n",
    "            \n",
    "            for j in range (min(1, len(user_sequences))):\n",
    "                if all(v > 0 for v in user_sequences[j]):\n",
    "                    original_interactions = user_sequences[j].copy()\n",
    "                    best_interactions = specific_cfs[j].interactions['best']\n",
    "                    items_removed = np.setdiff1d(original_interactions, best_interactions)\n",
    "\n",
    "                    predictions = -pretrained_models['lstm'].predict(original_interactions)\n",
    "                    predictions[original_interactions] = StaticVars.FLOAT_MAX\n",
    "                    target_item = predictions.argsort()[min(top_k, target_pos)]\n",
    "                    if len(best_interactions) == 0 : \n",
    "                        print(\"empty\", user_id)\n",
    "                        new_lign = {'user_id': user_id, 'target_pos': target_pos, 'cfs': items_removed, 'len_cfs': len(items_removed), 'worst_jacc_cfs': None, 'len_worst_jacc_cfs': None}#, jacc_search_info[0].interactions['best'], len(jacc_search_info[0].interactions['best']), rs_search_info[0].interactions['best'], len(rs_search_info[0].interactions['best'])])\n",
    "                        evaluation_df = evaluation_df.append(new_lign, ignore_index=True)\n",
    "                        break\n",
    "                    predictions_reverse = -pretrained_models['lstm'].predict(best_interactions)\n",
    "                    predictions_reverse[best_interactions] = StaticVars.FLOAT_MAX\n",
    "                    pos_target_item_reverse = np.where(predictions_reverse.argsort() == target_item)[0][0] #bug maybe?\n",
    "                    worst_jaccard_sample = find_worst_items_with_jaccard(target_item, best_interactions, jaccard_sims_matrix, len_sample)\n",
    "                    # jaccard_sample = find_best_items_with_jaccard(target_item, best_interactions, jaccard_sims_matrix, len_sample)\n",
    "                    # rs_sample = find_best_items_using_recommender(target_item, best_interactions, pretrained_models['lstm'], len_sample)\n",
    "\n",
    "                    if len(items_removed) >= len_sample:\n",
    "                        print(f\"Sequence skipped, too much items removed for user_id {user_id}.\")\n",
    "                        continue\n",
    "                    \n",
    "                    # if not set(items_removed) <= set(jaccard_sample):\n",
    "                        # replace_items_if_missing(items_removed, jaccard_sample)\n",
    "                        # jacc_search_info = retrieve_solutions_specific_sequence(user_id, test, pretrained_models['lstm'], get_backend_strategy('combo'), 1000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, jaccard_sample, alpha=0.5)\n",
    "# \n",
    "                    # if not set(items_removed) <= set(rs_sample):\n",
    "                        # replace_items_if_missing(items_removed, rs_sample)\n",
    "                        # rs_search_info = retrieve_solutions_specific_sequence(user_id, test, pretrained_models['lstm'], get_backend_strategy('combo'), 1000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, rs_sample, alpha=0.5)\n",
    "\n",
    "                    if not set(items_removed) <= set(worst_jaccard_sample):\n",
    "                        replace_items_if_missing(items_removed, worst_jaccard_sample)\n",
    "                        worst_jacc_search_info = retrieve_solutions_specific_sequence(user_id, test, pretrained_models['lstm'], get_backend_strategy('combo'), 1000, top_k, True, jaccard_sims_matrix, best_interactions, pos_target_item_reverse, worst_jaccard_sample, alpha=0.5)\n",
    "                    worst_jacc_cfs = np.setdiff1d(worst_jaccard_sample, worst_jacc_search_info[j].interactions['best'])\n",
    "                    new_lign = {'user_id': user_id, 'original_interactions': original_interactions, 'target_pos': target_pos, 'cfs': items_removed, 'len_cfs': len(items_removed), 'worst_jacc_sample': worst_jaccard_sample, 'worst_jacc_cfs': worst_jacc_cfs, 'len_worst_jacc_cfs': len(worst_jacc_cfs)}#, jacc_search_info[0].interactions['best'], len(jacc_search_info[0].interactions['best']), rs_search_info[0].interactions['best'], len(rs_search_info[0].interactions['best'])])\n",
    "                    evaluation_df = evaluation_df.append(new_lign, ignore_index=True)\n",
    "    return evaluation_df\n",
    "df2 = create_reverse_mode_evaluation_dataframe(test, pretrained_models['lstm'], get_backend_strategy('combo'), [1, 3, 5, 7], 10, jaccard_sims_matrix)\n",
    "%store df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>target_pos</th>\n",
       "      <th>original_interactions</th>\n",
       "      <th>cfs</th>\n",
       "      <th>len_cfs</th>\n",
       "      <th>worst_jacc_sample</th>\n",
       "      <th>worst_jacc_cfs</th>\n",
       "      <th>len_worst_jacc_cfs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[60, 107, 123, 130, 227, 230, 239, 253, 257, 2...</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[230, 257, 359, 130, 358, 329, 372, 227, 324, ...</td>\n",
       "      <td>[266, 301, 315, 372]</td>\n",
       "      <td>4</td>\n",
       "      <td>[266, 315, 372, 301, 466, 438, 766, 40, 53, 90...</td>\n",
       "      <td>[19, 40, 53, 90, 266, 301, 313, 315, 372, 438,...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[230, 257, 359, 130, 358, 329, 372, 227, 324, ...</td>\n",
       "      <td>[301]</td>\n",
       "      <td>1</td>\n",
       "      <td>[301, 483, 1369, 485, 243, 1420, 151, 439, 438...</td>\n",
       "      <td>[91, 127, 151, 243, 265, 301, 438, 439, 462, 4...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>[230, 257, 359, 130, 358, 329, 372, 227, 324, ...</td>\n",
       "      <td>[230]</td>\n",
       "      <td>1</td>\n",
       "      <td>[230, 120, 98, 1019, 190, 215, 529, 606, 161, ...</td>\n",
       "      <td>[63, 98, 120, 133, 156, 161, 190, 215, 230, 25...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[60, 86, 119, 236, 323, 360, 384, 443, 444, 45...</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>[384, 461, 236, 478, 86, 457, 511, 60, 323, 44...</td>\n",
       "      <td>[444, 456]</td>\n",
       "      <td>2</td>\n",
       "      <td>[456, 444, 1409, 488, 882, 419, 397, 1593, 133...</td>\n",
       "      <td>[397, 401, 419, 444, 456, 488, 577, 640, 641, ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>[384, 461, 236, 478, 86, 457, 511, 60, 323, 44...</td>\n",
       "      <td>[444, 450]</td>\n",
       "      <td>2</td>\n",
       "      <td>[450, 444, 1912, 1143, 1209, 2672, 2380, 1154,...</td>\n",
       "      <td>[444, 450, 483, 585, 761, 911, 912, 1119, 1143...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>[384, 461, 236, 478, 86, 457, 511, 60, 323, 44...</td>\n",
       "      <td>[444]</td>\n",
       "      <td>1</td>\n",
       "      <td>[444, 84, 376, 1203, 1059, 223, 777, 91, 138, ...</td>\n",
       "      <td>[75, 80, 84, 91, 118, 121, 126, 127, 131, 138,...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[24, 105, 126, 523, 268, 22, 337, 40, 506, 318...</td>\n",
       "      <td>[94]</td>\n",
       "      <td>1</td>\n",
       "      <td>[94, 320, 63, 147, 59, 433, 844, 75, 149, 241,...</td>\n",
       "      <td>[59, 63, 75, 79, 91, 94, 118, 121, 147, 149, 1...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>[24, 105, 126, 523, 268, 22, 337, 40, 506, 318...</td>\n",
       "      <td>[94]</td>\n",
       "      <td>1</td>\n",
       "      <td>[94, 127, 844, 434, 134, 147, 161, 896, 121, 4...</td>\n",
       "      <td>[59, 63, 79, 91, 94, 118, 121, 127, 134, 147, ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>[24, 105, 126, 523, 268, 22, 337, 40, 506, 318...</td>\n",
       "      <td>[94, 273]</td>\n",
       "      <td>2</td>\n",
       "      <td>[273, 94, 434, 59, 91, 117, 165, 433, 118, 712...</td>\n",
       "      <td>[59, 63, 79, 91, 94, 117, 118, 146, 149, 152, ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>[24, 105, 126, 523, 268, 22, 337, 40, 506, 318...</td>\n",
       "      <td>[94]</td>\n",
       "      <td>1</td>\n",
       "      <td>[844, 80, 152, 149, 79, 320, 138, 256, 434, 26...</td>\n",
       "      <td>[79, 80, 91, 94, 118, 121, 138, 147, 149, 151,...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[539, 734, 647, 759, 742, 20, 592, 569, 563, 2...</td>\n",
       "      <td>[435, 662]</td>\n",
       "      <td>2</td>\n",
       "      <td>[662, 98, 65, 168, 24, 68, 129, 247, 245, 211,...</td>\n",
       "      <td>[24, 45, 52, 65, 68, 98, 129, 168, 210, 211, 2...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[539, 734, 647, 759, 742, 20, 592, 569, 563, 2...</td>\n",
       "      <td>[660]</td>\n",
       "      <td>1</td>\n",
       "      <td>[660, 744, 49, 63, 61, 187, 190, 114, 6, 210, ...</td>\n",
       "      <td>[6, 23, 27, 45, 49, 61, 63, 65, 98, 114, 125, ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>[539, 734, 647, 759, 742, 20, 592, 569, 563, 2...</td>\n",
       "      <td>[662]</td>\n",
       "      <td>1</td>\n",
       "      <td>[662, 128, 45, 281, 117, 125, 98, 133, 152, 68...</td>\n",
       "      <td>[39, 45, 49, 68, 98, 105, 117, 128, 129, 133, ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>[539, 734, 647, 759, 742, 20, 592, 569, 563, 2...</td>\n",
       "      <td>[613]</td>\n",
       "      <td>1</td>\n",
       "      <td>[613, 1043, 1299, 199, 386, 1302, 1211, 6, 23,...</td>\n",
       "      <td>[6, 14, 16, 23, 85, 169, 178, 184, 199, 274, 3...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>[746, 165, 507, 292, 397, 466, 531, 306, 789, ...</td>\n",
       "      <td>[50]</td>\n",
       "      <td>1</td>\n",
       "      <td>[50, 1092, 1322, 557, 1857, 1197, 688, 1226, 1...</td>\n",
       "      <td>[50, 275, 557, 567, 658, 669, 688, 700, 747, 7...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>[746, 165, 507, 292, 397, 466, 531, 306, 789, ...</td>\n",
       "      <td>[684]</td>\n",
       "      <td>1</td>\n",
       "      <td>[684, 98, 118, 776, 87, 274, 739, 556, 606, 10...</td>\n",
       "      <td>[63, 87, 98, 118, 134, 156, 161, 190, 274, 278...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>[746, 165, 507, 292, 397, 466, 531, 306, 789, ...</td>\n",
       "      <td>[185, 601]</td>\n",
       "      <td>2</td>\n",
       "      <td>[601, 185, 98, 65, 168, 24, 129, 247, 245, 211...</td>\n",
       "      <td>[24, 45, 49, 52, 65, 98, 125, 128, 129, 168, 1...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>[746, 165, 507, 292, 397, 466, 531, 306, 789, ...</td>\n",
       "      <td>[50]</td>\n",
       "      <td>1</td>\n",
       "      <td>[50, 755, 1231, 636, 587, 1076, 1177, 215, 647...</td>\n",
       "      <td>[201, 559, 587, 636, 645, 647, 677, 716, 738, ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id target_pos                              original_interactions  \\\n",
       "0        5          1                                                NaN   \n",
       "1        5          3  [230, 257, 359, 130, 358, 329, 372, 227, 324, ...   \n",
       "2        5          5  [230, 257, 359, 130, 358, 329, 372, 227, 324, ...   \n",
       "3        5          7  [230, 257, 359, 130, 358, 329, 372, 227, 324, ...   \n",
       "4        8          1                                                NaN   \n",
       "5        8          3  [384, 461, 236, 478, 86, 457, 511, 60, 323, 44...   \n",
       "6        8          5  [384, 461, 236, 478, 86, 457, 511, 60, 323, 44...   \n",
       "7        8          7  [384, 461, 236, 478, 86, 457, 511, 60, 323, 44...   \n",
       "8        9          1  [24, 105, 126, 523, 268, 22, 337, 40, 506, 318...   \n",
       "9        9          3  [24, 105, 126, 523, 268, 22, 337, 40, 506, 318...   \n",
       "10       9          5  [24, 105, 126, 523, 268, 22, 337, 40, 506, 318...   \n",
       "11       9          7  [24, 105, 126, 523, 268, 22, 337, 40, 506, 318...   \n",
       "12      10          1  [539, 734, 647, 759, 742, 20, 592, 569, 563, 2...   \n",
       "13      10          3  [539, 734, 647, 759, 742, 20, 592, 569, 563, 2...   \n",
       "14      10          5  [539, 734, 647, 759, 742, 20, 592, 569, 563, 2...   \n",
       "15      10          7  [539, 734, 647, 759, 742, 20, 592, 569, 563, 2...   \n",
       "16      11          1  [746, 165, 507, 292, 397, 466, 531, 306, 789, ...   \n",
       "17      11          3  [746, 165, 507, 292, 397, 466, 531, 306, 789, ...   \n",
       "18      11          5  [746, 165, 507, 292, 397, 466, 531, 306, 789, ...   \n",
       "19      11          7  [746, 165, 507, 292, 397, 466, 531, 306, 789, ...   \n",
       "\n",
       "                                                  cfs len_cfs  \\\n",
       "0   [60, 107, 123, 130, 227, 230, 239, 253, 257, 2...      20   \n",
       "1                                [266, 301, 315, 372]       4   \n",
       "2                                               [301]       1   \n",
       "3                                               [230]       1   \n",
       "4   [60, 86, 119, 236, 323, 360, 384, 443, 444, 45...      20   \n",
       "5                                          [444, 456]       2   \n",
       "6                                          [444, 450]       2   \n",
       "7                                               [444]       1   \n",
       "8                                                [94]       1   \n",
       "9                                                [94]       1   \n",
       "10                                          [94, 273]       2   \n",
       "11                                               [94]       1   \n",
       "12                                         [435, 662]       2   \n",
       "13                                              [660]       1   \n",
       "14                                              [662]       1   \n",
       "15                                              [613]       1   \n",
       "16                                               [50]       1   \n",
       "17                                              [684]       1   \n",
       "18                                         [185, 601]       2   \n",
       "19                                               [50]       1   \n",
       "\n",
       "                                    worst_jacc_sample  \\\n",
       "0                                                 NaN   \n",
       "1   [266, 315, 372, 301, 466, 438, 766, 40, 53, 90...   \n",
       "2   [301, 483, 1369, 485, 243, 1420, 151, 439, 438...   \n",
       "3   [230, 120, 98, 1019, 190, 215, 529, 606, 161, ...   \n",
       "4                                                 NaN   \n",
       "5   [456, 444, 1409, 488, 882, 419, 397, 1593, 133...   \n",
       "6   [450, 444, 1912, 1143, 1209, 2672, 2380, 1154,...   \n",
       "7   [444, 84, 376, 1203, 1059, 223, 777, 91, 138, ...   \n",
       "8   [94, 320, 63, 147, 59, 433, 844, 75, 149, 241,...   \n",
       "9   [94, 127, 844, 434, 134, 147, 161, 896, 121, 4...   \n",
       "10  [273, 94, 434, 59, 91, 117, 165, 433, 118, 712...   \n",
       "11  [844, 80, 152, 149, 79, 320, 138, 256, 434, 26...   \n",
       "12  [662, 98, 65, 168, 24, 68, 129, 247, 245, 211,...   \n",
       "13  [660, 744, 49, 63, 61, 187, 190, 114, 6, 210, ...   \n",
       "14  [662, 128, 45, 281, 117, 125, 98, 133, 152, 68...   \n",
       "15  [613, 1043, 1299, 199, 386, 1302, 1211, 6, 23,...   \n",
       "16  [50, 1092, 1322, 557, 1857, 1197, 688, 1226, 1...   \n",
       "17  [684, 98, 118, 776, 87, 274, 739, 556, 606, 10...   \n",
       "18  [601, 185, 98, 65, 168, 24, 129, 247, 245, 211...   \n",
       "19  [50, 755, 1231, 636, 587, 1076, 1177, 215, 647...   \n",
       "\n",
       "                                       worst_jacc_cfs len_worst_jacc_cfs  \n",
       "0                                                 NaN               None  \n",
       "1   [19, 40, 53, 90, 266, 301, 313, 315, 372, 438,...                 20  \n",
       "2   [91, 127, 151, 243, 265, 301, 438, 439, 462, 4...                 20  \n",
       "3   [63, 98, 120, 133, 156, 161, 190, 215, 230, 25...                 20  \n",
       "4                                                None               None  \n",
       "5   [397, 401, 419, 444, 456, 488, 577, 640, 641, ...                 20  \n",
       "6   [444, 450, 483, 585, 761, 911, 912, 1119, 1143...                 20  \n",
       "7   [75, 80, 84, 91, 118, 121, 126, 127, 131, 138,...                 20  \n",
       "8   [59, 63, 75, 79, 91, 94, 118, 121, 147, 149, 1...                 20  \n",
       "9   [59, 63, 79, 91, 94, 118, 121, 127, 134, 147, ...                 20  \n",
       "10  [59, 63, 79, 91, 94, 117, 118, 146, 149, 152, ...                 20  \n",
       "11  [79, 80, 91, 94, 118, 121, 138, 147, 149, 151,...                 20  \n",
       "12  [24, 45, 52, 65, 68, 98, 129, 168, 210, 211, 2...                 16  \n",
       "13  [6, 23, 27, 45, 49, 61, 63, 65, 98, 114, 125, ...                 20  \n",
       "14  [39, 45, 49, 68, 98, 105, 117, 128, 129, 133, ...                 16  \n",
       "15  [6, 14, 16, 23, 85, 169, 178, 184, 199, 274, 3...                 20  \n",
       "16  [50, 275, 557, 567, 658, 669, 688, 700, 747, 7...                 20  \n",
       "17  [63, 87, 98, 118, 134, 156, 161, 190, 274, 278...                 20  \n",
       "18  [24, 45, 49, 52, 65, 98, 125, 128, 129, 168, 1...                 20  \n",
       "19  [201, 559, 587, 636, 645, 647, 677, 716, 738, ...                 18  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[266,\n",
       " 315,\n",
       " 372,\n",
       " 301,\n",
       " 466,\n",
       " 438,\n",
       " 766,\n",
       " 40,\n",
       " 53,\n",
       " 90,\n",
       " 521,\n",
       " 492,\n",
       " 511,\n",
       " 19,\n",
       " 705,\n",
       " 440,\n",
       " 313,\n",
       " 485,\n",
       " 439,\n",
       " 594]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df2.iloc[1][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 19,  40,  53,  90, 266, 301, 313, 315, 372, 438, 439, 440, 466,\n",
       "       485, 492, 511, 521, 594, 705, 766])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df2.iloc[1][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "original_interactions [230 257 359 130 358 329 372 227 324 301 253 239 107 305 266 315  60 331\n",
      " 123 357]\n",
      "best_interactions [230 257 359 130 358 329 227 324 253 239 107 305  60 331 123 357]\n",
      "items_removed [266 301 315 372]\n",
      "target_item 594\n",
      "position target item in reverse mode 10\n",
      "worst_jacc [165, 157, 508, 281, 466, 438, 766, 40, 53, 90, 521, 492, 511, 19, 705, 440, 313, 485, 439, 594]\n",
      "jacc [1494, 3509, 3242, 24, 2683, 3231, 2848, 3239, 3240, 3247, 3228, 3244, 1930, 3706, 1707, 386, 2650, 1868, 3226, 3222]\n",
      "modified_sample [266, 301, 315, 372, 466, 438, 766, 40, 53, 90, 521, 492, 511, 19, 705, 440, 313, 485, 439, 594]\n",
      "search_info [230, 257, 359, 130, 358, 329, 227, 324, 253, 239, 107, 305, 60, 331, 123, 357, 266]\n",
      "defaultdict(<class 'dict'>, {10: {'random_0': [[1], [1], [1], [1], [2], [2], [5], [16], [1], [0], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]]}})\n",
      "defaultdict(<class 'list'>, {})\n",
      "defaultdict(<class 'dict'>, {3: {'random_0': [[4], [4], [5346], [5346], [5347], [5347], [5], [20], [4], [0], [0], [0], [5346], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]]}})\n",
      "defaultdict(<class 'list'>, {})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "# get currently working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# load functions from other notebooks\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb').replace(\"\\\\\", \"/\")\n",
    "%run $helpers_file\n",
    "\n",
    "\n",
    "FLOAT_MAX = np.finfo(np.float32).max\n",
    "\n",
    "target_pos = 3\n",
    "user_id = 5\n",
    "top_k = 10\n",
    "combo_specific_cfs = None\n",
    "i = 0\n",
    "\n",
    "while combo_specific_cfs == [] or combo_specific_cfs is None:\n",
    "    i += 1\n",
    "    combo_specific_cfs = _find_specific_cfs_(test, pretrained_models['lstm'], get_backend_strategy('brute_force'), target_pos, False, jaccard_sims_matrix, i, 10000, 10)#, alpha=0.5, normalization='default')\n",
    "\n",
    "# combo_specific_cfs = _find_specific_cfs_(test, pretrained_models['lstm'], get_backend_strategy('combo'), target_pos, False, jaccard_sims_matrix, user_id, 1000, top_k)\n",
    "print(i)\n",
    "user_sequences = test.sequences[test.user_ids == i]\n",
    "user_sequences = [sequence for sequence in user_sequences if all(value > 0 for value in sequence)]\n",
    "\n",
    "original_interactions = user_sequences[0]\n",
    "print(\"original_interactions\", original_interactions)\n",
    "\n",
    "best_interactions = combo_specific_cfs[0].interactions['best']\n",
    "print(\"best_interactions\", best_interactions)\n",
    "\n",
    "items_removed = np.setdiff1d(original_interactions, best_interactions)\n",
    "print(\"items_removed\", items_removed)\n",
    "\n",
    "predictions = -pretrained_models['lstm'].predict(original_interactions)\n",
    "predictions[original_interactions] = FLOAT_MAX\n",
    "target_item = predictions.argsort()[min(top_k, target_pos)]\n",
    "print(\"target_item\", target_item)\n",
    "\n",
    "predictions_reverse = -pretrained_models['lstm'].predict(best_interactions)\n",
    "predictions_reverse[best_interactions] = FLOAT_MAX\n",
    "pos_target_item_reverse = np.where(predictions_reverse.argsort() == target_item)[0][0]\n",
    "print(\"position target item in reverse mode\", pos_target_item_reverse)\n",
    "\n",
    "worst_jaccard_sample = find_worst_items_with_jaccard(target_item, best_interactions, jaccard_sims_matrix, 20)\n",
    "print(\"worst_jacc\", worst_jaccard_sample)\n",
    "\n",
    "jaccard_sample = find_best_items_with_jaccard(target_item, best_interactions, jaccard_sims_matrix, 20)\n",
    "print(\"jacc\", jaccard_sample)\n",
    "rs_sample = find_best_items_using_recommender(target_item, best_interactions, pretrained_models['lstm'], 20)\n",
    "if set(items_removed) <= set(jaccard_sample):\n",
    "    print(\"jaccard_sample\", jaccard_sample)\n",
    "    search_info = retrieve_solutions_specific_sequence(i, test, pretrained_models['lstm'], get_backend_strategy('brute_force'), 10000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, jaccard_sample)\n",
    "\n",
    "elif set(items_removed) <= set(rs_sample):\n",
    "    print(\"rs_sample\", rs_sample)\n",
    "    search_info = retrieve_solutions_specific_sequence(i, test, pretrained_models['lstm'], get_backend_strategy('brute_force'), 10000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, rs_sample)\n",
    "else:\n",
    "    worst_jaccard_sample[:len(items_removed)] = items_removed[:len(items_removed)]\n",
    "    print(\"modified_sample\", worst_jaccard_sample)\n",
    "    search_info = retrieve_solutions_specific_sequence(i, test, pretrained_models['lstm'], get_backend_strategy('brute_force'), 10000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, worst_jaccard_sample)\n",
    "\n",
    "print(\"search_info\", search_info[0].interactions['best'])\n",
    "\n",
    "result2 = dict.fromkeys([pos_target_item_reverse])\n",
    "result2[pos_target_item_reverse] = []\n",
    "result2[pos_target_item_reverse].extend(search_info)\n",
    "\n",
    "cnt2 = defaultdict(dict)\n",
    "no_target_achieved_cases2 = defaultdict(list)\n",
    "\n",
    "\n",
    "cnt2, no_target_achieved_cases2 = convert_res_to_lists(result2, cnt2, no_target_achieved_cases2, \"random_0\", True)\n",
    "print(cnt2)\n",
    "print(no_target_achieved_cases2)\n",
    "\n",
    "result = dict.fromkeys([target_pos])\n",
    "result[target_pos] = []\n",
    "result[target_pos].extend(combo_specific_cfs)\n",
    "\n",
    "cnt = defaultdict(dict)\n",
    "no_target_achieved_cases = defaultdict(list)\n",
    "\n",
    "target_item = 0\n",
    "\n",
    "cnt, no_target_achieved_cases = convert_res_to_lists(result, cnt, no_target_achieved_cases, \"random_0\", False)\n",
    "print(cnt)\n",
    "print(no_target_achieved_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_supported = ['Brute_Force', 'Random', 'BFS'] + \\\n",
    "    [f'BiDirectional_{m}' for m in ['001', '5', '999']] + \\\n",
    "    [f'Combo_{m}' for m in ['001', '5', '999']]\n",
    "\n",
    "strategies = [('init', 2), ('best', 3)]\n",
    "custom_range = [9, 29] # Range to access to the \"stats per cardinality\" part (please check the convert_res_to_lists method in the helpers notebook for more info)\n",
    "target_pos = list(cnt.keys())\n",
    "cnames = ['user_id', 'method', 'pos', 'budget', 'init_budget', 'best_budget', 'cardinality', 'cfs_orig', 'cfs']\n",
    "\n",
    "rows, cols = 5, 1\n",
    "\n",
    "tmp_dfs = []\n",
    "for col in range(cols):\n",
    "    for pos, row in zip(target_pos, range(rows)):\n",
    "\n",
    "        tmp_dfs.append(pd.DataFrame.from_records(list(\n",
    "            itertools.chain(*(\n",
    "                zip(v[6], itertools.repeat(k), itertools.repeat(pos), v[i], v[2], v[3],\n",
    "                    itertools.repeat(i - custom_range[0] + 1), v[7], v[8])\n",
    "                for k, v in cnt[pos].items() if f'_{col}' in k and k.rsplit('_', 1)[0] in map(lambda x: x.lower(), methods_supported)\n",
    "                for i in range(custom_range[0], custom_range[1])\n",
    "            ))), columns=cnames\n",
    "        ))\n",
    "\n",
    "df = pd.concat(tmp_dfs, ignore_index=True)\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_supported = ['Brute_Force', 'Random', 'BFS'] + \\\n",
    "    [f'BiDirectional_{m}' for m in ['001', '5', '999']] + \\\n",
    "    [f'Combo_{m}' for m in ['001', '5', '999']]\n",
    "\n",
    "strategies = [('init', 2), ('best', 3)]\n",
    "custom_range = [9, 28] # Range to access to the \"stats per cardinality\" part (please check the convert_res_to_lists method in the helpers notebook for more info)\n",
    "target_pos = list(cnt2.keys())\n",
    "cnames = ['user_id', 'method', 'pos', 'budget', 'init_budget', 'best_budget', 'cardinality', 'cfs_orig', 'cfs']\n",
    "\n",
    "rows, cols = 5, 1\n",
    "\n",
    "tmp_dfs = []\n",
    "for col in range(cols):\n",
    "    for pos, row in zip(target_pos, range(rows)):\n",
    "\n",
    "        tmp_dfs.append(pd.DataFrame.from_records(list(\n",
    "            itertools.chain(*(\n",
    "                zip(v[6], itertools.repeat(k), itertools.repeat(pos), v[i], v[2], v[3],\n",
    "                    itertools.repeat(i - custom_range[0] + 1), v[7], v[8])\n",
    "                for k, v in cnt2[pos].items() if f'_{col}' in k and k.rsplit('_', 1)[0] in map(lambda x: x.lower(), methods_supported)\n",
    "                for i in range(custom_range[0], custom_range[1])\n",
    "            ))), columns=cnames\n",
    "        ))\n",
    "\n",
    "df = pd.concat(tmp_dfs, ignore_index=True)\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get currently working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# load functions from other notebooks\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb').replace(\"\\\\\", \"/\")\n",
    "%run $helpers_file\n",
    "\n",
    "backend = 'random'\n",
    "random_cfs = [\n",
    "\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users= 500, init_budget=1000)\n",
    "    # _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users= 10, init_budget=1000)\n",
    "]\n",
    "\n",
    "%store random_cfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = 'bfs'\n",
    "\n",
    "bfs_yloss_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users= 500, init_budget=1000),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users= 500, init_budget=1000, early_term=True),\n",
    "]\n",
    "\n",
    "# %store bfs_yloss_cfs_positive\n",
    "%store bfs_yloss_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend='bidirectional'\n",
    "\n",
    "bidirectional_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=500, init_budget=1000, alpha=1e-3, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=500, init_budget=1000, alpha=0.5, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=500, init_budget=1000, alpha=0.999, normalization='default'),\n",
    "]\n",
    "\n",
    "%store bidirectional_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend='brute_force'\n",
    "\n",
    "brute_force_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=500, init_budget=100000),\n",
    "]\n",
    "\n",
    "%store brute_force_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend='combo'\n",
    "combo_cfs = [\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=500, init_budget=1000, alpha=1e-3, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=500, init_budget=1000, alpha=0.5, normalization='default'),\n",
    "    _find_cfs(test, pretrained_models['lstm'], get_backend_strategy(backend), [11, 13, 15, 17], missing_target_in_topk=True, sim_matrix=jaccard_sims_matrix, no_users=500, init_budget=1000, alpha=0.999, normalization='default'),\n",
    "]\n",
    "\n",
    "%store combo_cfs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
