{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats as st\n",
    "import itertools\n",
    "import operator\n",
    "import heapq as hq\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get currently working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# load functions from other notebooks\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb').replace(\"\\\\\", \"/\")\n",
    "%run $helpers_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['../spotlight_ext']:\n",
    "    module_path = os.path.abspath(os.path.join(base_dir, p))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "random_state = np.random.RandomState(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare models/datasets\n",
    "#### Load the pretrained models \"lstm\" (entire_model_1m_20interactions.pt) and \"pooling\" (pooling_model_1m_20interactions.pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implicit_model = load_model('implicit_factorization')\n",
    "lstm_model = load_model(model_type='entire')\n",
    "pooling_model = load_model('pooling')\n",
    "\n",
    "pretrained_models = {\n",
    "    'lstm': lstm_model,\n",
    "    'pooling': pooling_model,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the dataset Movielens with the variant 1M. Then divide it into a training set and a testing set. And finally this code limits the length of each sequence of elements in the 2 sets to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "\n",
    "# get dataset \n",
    "dataset = get_movielens_dataset(variant='1M')\n",
    "train, test = random_train_test_split(dataset, random_state=random_state)\n",
    "\n",
    "max_sequence_length = 20\n",
    "train = train.to_sequence(max_sequence_length=max_sequence_length)\n",
    "test = test.to_sequence(max_sequence_length=max_sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Compute the similarity matrix based on cosine similarity\n",
    "#### 2. Compute the similarity matrix based on Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_sims_matrix = gpu_embeddings_to_cosine_similarity_matrix(\n",
    "    pooling_model._net.item_embeddings(\n",
    "        torch.arange(0, dataset.num_items, dtype=torch.int64)\n",
    "    )).detach().numpy()\n",
    "\n",
    "jaccard_sims_matrix = compute_sim_matrix(dataset, 'jaccard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various implemented Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseStrategy:\n",
    "    class_name = None\n",
    "\n",
    "    def __init__(self, item, interactions, max_length, init_budget,  model=None, random_pick=False):\n",
    "\n",
    "        self.target_item = item\n",
    "        self.original_interactions = interactions\n",
    "        self.max_length = max_length\n",
    "        self.visited_ = set()\n",
    "        self.model = model\n",
    "        self.last_comb_cost = 0\n",
    "        self.random_pick = random_pick\n",
    "        self.top_k = 10\n",
    "        self.budget = init_budget\n",
    "\n",
    "    #Must be implemented by subclasses. Used to select the next item to recommand to the user.\n",
    "    def next_comb(self, reverse=False):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \n",
    "    def _get_pos(self, number):\n",
    "        bits = []\n",
    "        for i, c in enumerate(bin(number)[:1:-1], 1):\n",
    "            if c == '0':\n",
    "                bits.append(i)\n",
    "        return bits\n",
    "\n",
    "    #Method to reset the costs of the last recommended combination\n",
    "    def reset_costs(self):\n",
    "        self.last_comb_cost = 0\n",
    "\n",
    "    #Returns the initial budget\n",
    "    def get_init_budget(self):\n",
    "        return self.budget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSelection\n",
    "#### This class is a subclass of the \"BaseStrategy\" class, representing a random item selection strategy for the sequential recommendation task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
