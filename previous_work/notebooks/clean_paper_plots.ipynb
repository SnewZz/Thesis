{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unnecessary-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-spider",
   "metadata": {},
   "source": [
    "# Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "innovative-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "base_dir = os.getcwd()\n",
    "plots_folder = 'plots'\n",
    "\n",
    "# Load functions from other notebooks\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb')\n",
    "%run $helpers_file\n",
    "\n",
    "current_module = sys.modules[__name__]\n",
    "\n",
    "class Strategies:\n",
    "    \"\"\"\n",
    "    A class representing different strategies for counterfactual explanation generation.\n",
    "\n",
    "    Attributes:\n",
    "    - stypes (list): List of strategy types, including 'random', 'brute_force', 'bfs_yloss', 'bidirectional', and 'combo'.\n",
    "    \"\"\"\n",
    "    stypes = [\n",
    "        'random',\n",
    "        'brute_force',\n",
    "        'bfs_yloss',\n",
    "        'bidirectional',\n",
    "        'combo',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-democracy",
   "metadata": {},
   "source": [
    "# Movielens 10M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-economics",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "painted-montgomery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007005929946899414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 6040,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c93324cdff477fbf5133ecb92dbf65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## uncomment the following lines if you want to run the various strategies in budget_strategies\n",
    "implemented_strategies = os.path.join(base_dir, 'clean_budget_strategies.ipynb')\n",
    "%run $implemented_strategies\n",
    "\n",
    "# Restore relevant variables from other notebooks\n",
    "\n",
    "%store -r random_cfs\n",
    "%store -r brute_force_cfs\n",
    "%store -r bfs_yloss_cfs\n",
    "# %store -r dfs_yloss_cfs\n",
    "# %store -r bestfs_yloss_cfs\n",
    "%store -r bidirectional_cfs\n",
    "%store -r combo_cfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f25340",
   "metadata": {},
   "source": [
    "## Save/retrieve data experiment if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a2a5c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "pkl_dir = os.path.join(base_dir, 'pkl/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a83751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these lines to save the object from the budget strategies notebook in the pkl folder\n",
    "# with open(os.path.join(pkl_dir,'random_cfs.pkl'), 'wb') as f:\n",
    "#     pickle.dump(random_cfs, f)\n",
    "    \n",
    "# with open(os.path.join(pkl_dir,'brute_force_cfs.pkl'), 'wb') as f:\n",
    "#     pickle.dump(brute_force_cfs, f)\n",
    "\n",
    "# with open(os.path.join(pkl_dir,'bfs_yloss_cfs.pkl'), 'wb') as f:\n",
    "#     pickle.dump(bfs_yloss_cfs, f)\n",
    "\n",
    "# with open(os.path.join(pkl_dir,'bidirectional_cfs.pkl'), 'wb') as f:\n",
    "#     pickle.dump(bidirectional_cfs, f)\n",
    "\n",
    "# with open(os.path.join(pkl_dir,'combo_cfs.pkl'), 'wb') as f:\n",
    "#     pickle.dump(combo_cfs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "189ca2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these lines to load the object stored as pkl in the pkl folder\n",
    "with open(os.path.join(pkl_dir,'random_cfs.pkl'), 'rb') as f:\n",
    "    random_cfs = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(pkl_dir,'brute_force_cfs.pkl'), 'rb') as f:\n",
    "    brute_force_cfs = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(pkl_dir,'bfs_yloss_cfs.pkl'), 'rb') as f:\n",
    "    bfs_yloss_cfs = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(pkl_dir,'bidirectional_cfs.pkl'), 'rb') as f:\n",
    "    bidirectional_cfs = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(pkl_dir,'combo_cfs.pkl'), 'rb') as f:\n",
    "    combo_cfs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582f1a5f",
   "metadata": {},
   "source": [
    "# Evaluation of the strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6da60cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id :  5\n",
      "target_pos :  1\n",
      "original : [230, 257, 359, 130, 358, 329, 372, 227, 324, 301, 253, 239, 107, 305, 266, 315, 60, 331, 123, 357]\n",
      "best: [230, 359, 130, 358, 329, 372, 227, 324, 301, 253, 239, 107, 305, 60]\n",
      "target 461\n",
      "new pos 11\n",
      "worst_jac [285, 505, 594, 19, 1578, 507, 492, 508, 480, 440, 293, 510, 485, 439, 325, 447, 266, 543, 521, 461]\n",
      "new worst [257, 357, 331, 315, 123, 507, 492, 508, 480, 440, 293, 510, 485, 439, 325, 447, 266, 543, 521, 461]\n",
      "\n",
      "\n",
      "\n",
      "[230, 359, 130, 358, 329, 372, 227, 324, 301, 253, 239, 107, 305, 60, 357]\n",
      "[230, 359, 130, 358, 329, 372, 227, 324, 301, 253, 239, 107, 305, 60]\n",
      "last pos 11\n",
      "================================\n",
      "user_id :  5\n",
      "target_pos :  3\n",
      "original : [230, 257, 359, 130, 358, 329, 372, 227, 324, 301, 253, 239, 107, 305, 266, 315, 60, 331, 123, 357]\n",
      "best: [230, 257, 359, 130, 358, 329, 227, 324, 253, 239, 107, 305, 60, 331, 123, 357]\n",
      "target 594\n",
      "new pos 10\n",
      "worst_jac [165, 157, 508, 281, 466, 438, 766, 40, 53, 90, 521, 492, 511, 19, 705, 440, 313, 485, 439, 594]\n",
      "new worst [266, 315, 372, 301, 466, 438, 766, 40, 53, 90, 521, 492, 511, 19, 705, 440, 313, 485, 439, 594]\n",
      "\n",
      "\n",
      "[230, 257, 359, 130, 358, 329, 227, 324, 253, 239, 107, 305, 60, 331, 123, 357, 266]\n",
      "[230, 257, 359, 130, 358, 329, 227, 324, 253, 239, 107, 305, 60, 331, 123, 357]\n",
      "last pos 10\n",
      "================================\n",
      "user_id :  5\n",
      "target_pos :  5\n",
      "original : [230, 257, 359, 130, 358, 329, 372, 227, 324, 301, 253, 239, 107, 305, 266, 315, 60, 331, 123, 357]\n",
      "best: [230, 257, 359, 130, 358, 329, 372, 227, 324, 253, 239, 107, 305, 266, 315, 60, 331, 123, 357]\n",
      "target 466\n",
      "new pos 10\n",
      "worst_jac [121, 483, 1369, 485, 243, 1420, 151, 439, 438, 462, 127, 265, 2145, 91, 926, 906, 568, 524, 888, 466]\n",
      "new worst [301, 483, 1369, 485, 243, 1420, 151, 439, 438, 462, 127, 265, 2145, 91, 926, 906, 568, 524, 888, 466]\n",
      "\n",
      "\n",
      "[230, 257, 359, 130, 358, 329, 372, 227, 324, 253, 239, 107, 305, 266, 315, 60, 331, 123, 357, 301]\n",
      "[230, 257, 359, 130, 358, 329, 372, 227, 324, 253, 239, 107, 305, 266, 315, 60, 331, 123, 357]\n",
      "last pos 10\n",
      "================================\n",
      "user_id :  5\n",
      "target_pos :  7\n",
      "original : [230, 257, 359, 130, 358, 329, 372, 227, 324, 301, 253, 239, 107, 305, 266, 315, 60, 331, 123, 357]\n",
      "best: [257, 359, 130, 358, 329, 372, 227, 324, 301, 253, 239, 107, 305, 266, 315, 60, 331, 123, 357]\n",
      "target 323\n",
      "new pos 10\n",
      "worst_jac [218, 120, 98, 1019, 190, 215, 529, 606, 161, 776, 133, 897, 433, 1015, 252, 63, 377, 156, 539, 323]\n",
      "new worst [230, 120, 98, 1019, 190, 215, 529, 606, 161, 776, 133, 897, 433, 1015, 252, 63, 377, 156, 539, 323]\n",
      "\n",
      "\n",
      "[257, 359, 130, 358, 329, 372, 227, 324, 301, 253, 239, 107, 305, 266, 315, 60, 331, 123, 357, 230]\n",
      "[257, 359, 130, 358, 329, 372, 227, 324, 301, 253, 239, 107, 305, 266, 315, 60, 331, 123, 357]\n",
      "last pos 10\n",
      "================================\n",
      "user_id :  8\n",
      "target_pos :  1\n",
      "original : [384, 461, 236, 478, 86, 457, 511, 60, 323, 443, 360, 473, 472, 514, 456, 481, 119, 450, 453, 444]\n",
      "best: [236, 457, 323, 443, 360, 473, 472, 514, 456, 481, 119, 450, 453, 444]\n",
      "target 1439\n",
      "new pos 13\n",
      "worst_jac [859, 845, 594, 1861, 266, 485, 464, 1443, 927, 2145, 1381, 582, 1688, 1385, 705, 488, 888, 519, 512, 1439]\n",
      "new worst [384, 461, 86, 60, 478, 511, 464, 1443, 927, 2145, 1381, 582, 1688, 1385, 705, 488, 888, 519, 512, 1439]\n",
      "\n",
      "\n",
      "[236, 457, 323, 443, 360, 473, 472, 514, 456, 481, 119, 450, 453, 444, 384]\n",
      "[236, 457, 323, 443, 360, 473, 472, 514, 456, 481, 119, 450, 453, 444]\n",
      "last pos 13\n",
      "================================\n",
      "user_id :  8\n",
      "target_pos :  3\n",
      "original : [384, 461, 236, 478, 86, 457, 511, 60, 323, 443, 360, 473, 472, 514, 456, 481, 119, 450, 453, 444]\n",
      "best: [384, 461, 478, 86, 457, 511, 60, 323, 443, 360, 473, 472, 514, 456, 481, 119, 450, 453]\n",
      "target 1360\n",
      "new pos 10\n",
      "worst_jac [1387, 1365, 1409, 488, 882, 419, 397, 1593, 1339, 829, 641, 1195, 730, 1443, 1325, 401, 640, 577, 691, 1360]\n",
      "new worst [444, 236, 1409, 488, 882, 419, 397, 1593, 1339, 829, 641, 1195, 730, 1443, 1325, 401, 640, 577, 691, 1360]\n",
      "\n",
      "\n",
      "[384, 461, 478, 86, 457, 511, 60, 323, 443, 360, 473, 472, 514, 456, 481, 119, 450, 453, 444]\n",
      "[384, 461, 478, 86, 457, 511, 60, 323, 443, 360, 473, 472, 514, 456, 481, 119, 450, 453]\n",
      "last pos 10\n",
      "================================\n",
      "user_id :  8\n",
      "target_pos :  5\n",
      "original : [384, 461, 236, 478, 86, 457, 511, 60, 323, 443, 360, 473, 472, 514, 456, 481, 119, 450, 453, 444]\n",
      "best: [384, 461, 236, 478, 86, 457, 511, 60, 323, 443, 473, 472, 514, 456, 481, 119, 453, 444]\n",
      "target 1329\n",
      "new pos 10\n",
      "worst_jac [1142, 1895, 1912, 1143, 1209, 2672, 2380, 1154, 912, 2260, 1260, 1985, 1119, 911, 761, 585, 1900, 483, 1156, 1329]\n",
      "new worst [360, 450, 1912, 1143, 1209, 2672, 2380, 1154, 912, 2260, 1260, 1985, 1119, 911, 761, 585, 1900, 483, 1156, 1329]\n",
      "\n",
      "\n",
      "[384, 461, 236, 478, 86, 457, 511, 60, 323, 443, 473, 472, 514, 456, 481, 119, 453, 444, 360]\n",
      "[384, 461, 236, 478, 86, 457, 511, 60, 323, 443, 473, 472, 514, 456, 481, 119, 453, 444]\n",
      "last pos 10\n",
      "================================\n",
      "user_id :  8\n",
      "target_pos :  7\n",
      "original : [384, 461, 236, 478, 86, 457, 511, 60, 323, 443, 360, 473, 472, 514, 456, 481, 119, 450, 453, 444]\n",
      "best: [384, 461, 236, 478, 86, 457, 511, 60, 323, 443, 360, 473, 472, 514, 456, 481, 119, 450, 453]\n",
      "target 80\n",
      "new pos 12\n",
      "worst_jac [320, 84, 376, 1203, 1059, 223, 777, 91, 138, 196, 151, 121, 127, 75, 131, 118, 126, 896, 147, 80]\n",
      "new worst [444, 84, 376, 1203, 1059, 223, 777, 91, 138, 196, 151, 121, 127, 75, 131, 118, 126, 896, 147, 80]\n",
      "\n",
      "\n",
      "[384, 461, 236, 478, 86, 457, 511, 60, 323, 443, 360, 473, 472, 514, 456, 481, 119, 450, 453, 444]\n",
      "[384, 461, 236, 478, 86, 457, 511, 60, 323, 443, 360, 473, 472, 514, 456, 481, 119, 450, 453]\n",
      "last pos 12\n",
      "================================\n",
      "user_id :  9\n",
      "target_pos :  1\n",
      "original : [24, 105, 126, 523, 268, 22, 337, 40, 506, 318, 317, 90, 539, 227, 273, 114, 549, 323, 529, 94]\n",
      "best: [24, 105, 126, 523, 268, 22, 337, 40, 506, 318, 317, 90, 539, 227, 273, 114, 549, 323, 529]\n",
      "target 91\n",
      "new pos 25\n",
      "worst_jac [256, 320, 63, 147, 59, 433, 844, 75, 149, 241, 152, 896, 434, 121, 265, 196, 79, 118, 151, 91]\n",
      "new worst [94, 320, 63, 147, 59, 433, 844, 75, 149, 241, 152, 896, 434, 121, 265, 196, 79, 118, 151, 91]\n",
      "\n",
      "\n",
      "[24, 105, 126, 523, 268, 22, 337, 40, 506, 318, 317, 90, 539, 227, 273, 114, 549, 323, 529, 94]\n",
      "[24, 105, 126, 523, 268, 22, 337, 40, 506, 318, 317, 90, 539, 227, 273, 114, 549, 323, 529]\n",
      "last pos 25\n",
      "================================\n",
      "user_id :  9\n",
      "target_pos :  3\n",
      "original : [24, 105, 126, 523, 268, 22, 337, 40, 506, 318, 317, 90, 539, 227, 273, 114, 549, 323, 529, 94]\n",
      "best: [24, 105, 126, 523, 268, 22, 337, 40, 506, 318, 317, 90, 539, 227, 273, 114, 549, 323, 529]\n",
      "target 196\n",
      "new pos 10\n",
      "worst_jac [190, 127, 844, 434, 134, 147, 161, 896, 121, 433, 63, 91, 59, 152, 79, 118, 149, 265, 151, 196]\n",
      "new worst [94, 127, 844, 434, 134, 147, 161, 896, 121, 433, 63, 91, 59, 152, 79, 118, 149, 265, 151, 196]\n",
      "\n",
      "\n",
      "[24, 105, 126, 523, 268, 22, 337, 40, 506, 318, 317, 90, 539, 227, 273, 114, 549, 323, 529, 94]\n",
      "[24, 105, 126, 523, 268, 22, 337, 40, 506, 318, 317, 90, 539, 227, 273, 114, 549, 323, 529]\n",
      "last pos 10\n",
      "================================\n",
      "user_id :  9\n",
      "target_pos :  5\n",
      "original : [24, 105, 126, 523, 268, 22, 337, 40, 506, 318, 317, 90, 539, 227, 273, 114, 549, 323, 529, 94]\n",
      "best: [24, 105, 126, 523, 268, 22, 337, 40, 506, 318, 317, 90, 539, 227, 114, 549, 323, 529]\n",
      "target 146\n",
      "new pos 13\n",
      "worst_jac [386, 256, 434, 59, 91, 117, 165, 433, 118, 712, 63, 291, 157, 190, 196, 79, 265, 152, 149, 146]\n",
      "new worst [273, 94, 434, 59, 91, 117, 165, 433, 118, 712, 63, 291, 157, 190, 196, 79, 265, 152, 149, 146]\n",
      "\n",
      "\n",
      "[24, 105, 126, 523, 268, 22, 337, 40, 506, 318, 317, 90, 539, 227, 114, 549, 323, 529, 273]\n",
      "[24, 105, 126, 523, 268, 22, 337, 40, 506, 318, 317, 90, 539, 227, 114, 549, 323, 529]\n",
      "last pos 13\n",
      "================================\n",
      "user_id :  9\n",
      "target_pos :  7\n",
      "original : [24, 105, 126, 523, 268, 22, 337, 40, 506, 318, 317, 90, 539, 227, 273, 114, 549, 323, 529, 94]\n",
      "best: [24, 105, 126, 523, 268, 22, 337, 40, 506, 318, 317, 90, 539, 227, 273, 114, 549, 323, 529]\n",
      "target 241\n",
      "new pos 38\n",
      "worst_jac [844, 80, 152, 149, 79, 320, 138, 256, 434, 265, 433, 147, 896, 151, 196, 94, 118, 91, 121, 241]\n",
      "[24, 105, 126, 523, 268, 22, 337, 40, 506, 318, 317, 90, 539, 227, 114, 549, 323, 529, 273]\n",
      "[24, 105, 126, 523, 268, 22, 337, 40, 506, 318, 317, 90, 539, 227, 273, 114, 549, 323, 529]\n",
      "last pos 38\n",
      "================================\n",
      "5\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# Load functions from other notebooks\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb')\n",
    "%run $helpers_file\n",
    "\n",
    "counter, shape = evaluate_reverse_mode(\"new_brute_force_evaluation_cfs.csv\", pretrained_models['lstm'], test,  get_backend_strategy(\"brute_force\"), 20, jaccard_sims_matrix, 10)\n",
    "\n",
    "print(counter)\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd81fdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original : [384 461 236 478  86 457 511  60 323 443 360 473 472 514 456 481 119 450\n",
      " 453 444]\n",
      "best: [384 461 236 478  86 457 511  60 323 443 473 472 514 456 481 119 450 453\n",
      " 444]\n",
      "items_removed [360]\n",
      "target 704\n",
      "new pos 10\n",
      "19\n",
      "sim_matrix 3706\n",
      "sim_matrix 3706\n",
      "19\n",
      "test :  3687\n",
      "top_items_indices :  [ 727  710  806   87  649  515  671  537  712  680 1072  619  638 1412\n",
      "  881  270  774  791  547  684]\n",
      "[ 746  729  825   89  668  534  690  556  731  699 1091  638  657 1431\n",
      "  900  274  793  810  566  703  358]\n",
      "tmp [ 2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19.\n",
      " 20. 21.  1.]\n",
      "worst_jac [747, 730, 826, 90, 669, 535, 691, 557, 732, 700, 1092, 639, 658, 1432, 901, 275, 794, 811, 567, 704]\n",
      "new worst [360, 730, 826, 90, 669, 535, 691, 557, 732, 700, 1092, 639, 658, 1432, 901, 275, 794, 811, 567, 704]\n",
      "neg_original_interactions [384 461 236 478  86 457 511  60 323 443 473 472 514 456 481 119 450 453\n",
      " 444]\n",
      "last pos 10\n",
      "item :  704\n"
     ]
    }
   ],
   "source": [
    "# Load functions from other notebooks\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb')\n",
    "%run $helpers_file\n",
    "\n",
    "test_evaluate_reverse_mode(8, \"new_brute_force_evaluation_cfs.csv\", pretrained_models['lstm'], test,  get_backend_strategy(\"brute_force\"), 20, jaccard_sims_matrix, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398a5c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluate_reverse_mode(user_id, csv_file_name, model, dataset, strategy, len_sample, sim_matrix, top_k, alpha = None, normalization = None):\n",
    "    \n",
    "    target_pos = 9\n",
    "\n",
    "    user_sequences = dataset.sequences[dataset.user_ids == user_id]\n",
    "    user_sequences = [sequence for sequence in user_sequences if all(value > 0 for value in sequence)]\n",
    "    original_interactions = user_sequences[0]\n",
    "    print(\"original :\", original_interactions)\n",
    "\n",
    "    brute_force_specific_cfs = _find_specific_cfs_(dataset, model, strategy, target_pos, False, sim_matrix, user_id, 1048576, top_k)\n",
    "    best_interactions = brute_force_specific_cfs[0].interactions['best']\n",
    "    print(\"best:\", best_interactions)\n",
    "\n",
    "    items_removed = np.setdiff1d(original_interactions, best_interactions)\n",
    "    print(\"items_removed\", items_removed)\n",
    "    \n",
    "    predictions = -model.predict(original_interactions)\n",
    "    predictions[original_interactions] = StaticVars.FLOAT_MAX\n",
    "    target_item = predictions.argsort()[min(top_k, target_pos)] # TODO retrieve it from the csv\n",
    "    print(\"target\", target_item)\n",
    "\n",
    "    if len(best_interactions) == 0 : \n",
    "        print(\"empty\", user_id)\n",
    "        \n",
    "    predictions_reverse = -model.predict(best_interactions)\n",
    "    predictions_reverse[best_interactions] = StaticVars.FLOAT_MAX\n",
    "    pos_target_item_reverse = np.where(predictions_reverse.argsort() == target_item)[0][0] #bug maybe?\n",
    "    print(\"new pos\",  pos_target_item_reverse)\n",
    "\n",
    "    worst_jaccard_sample = find_worst_items_with_jaccard(target_item, best_interactions, sim_matrix, len_sample)\n",
    "    print(\"worst_jac\", worst_jaccard_sample )\n",
    "    \n",
    "    if len(items_removed) >= len_sample:\n",
    "        print(f\"Sequence skipped, too much items removed for user_id {user_id}.\")\n",
    "    \n",
    "    if not set(items_removed) <= set(worst_jaccard_sample):\n",
    "        replace_items_if_missing(items_removed, worst_jaccard_sample)\n",
    "        print(\"new worst\", worst_jaccard_sample)\n",
    "        #bug ??\n",
    "        if alpha is None or normalization is None : \n",
    "            worst_jacc_search_info = _find_specific_cfs_(dataset, model, strategy, pos_target_item_reverse, True, sim_matrix, user_id, 1048576, top_k)\n",
    "            worst_jacc_search_info = retrieve_solutions_specific_sequence(user_id, dataset, model, strategy, 1048576, top_k, True, sim_matrix, best_interactions, target_item, worst_jaccard_sample)\n",
    "        else:\n",
    "            worst_jacc_search_info = retrieve_solutions_specific_sequence(user_id, dataset, model, strategy, 1048576, top_k, True, sim_matrix, best_interactions, target_item, worst_jaccard_sample, alpha=0.5, normalization='default')\n",
    "    \n",
    "    print(\"neg_original_interactions\", worst_jacc_search_info[0].interactions['best'])\n",
    "\n",
    "    last_predictions_reverse = -model.predict(worst_jacc_search_info[0].interactions['best'])\n",
    "    last_predictions_reverse[worst_jacc_search_info[0].interactions['best']] = StaticVars.FLOAT_MAX\n",
    "    \n",
    "    last_pos_target_item_reverse = np.where(last_predictions_reverse.argsort() == target_item)[0][0] #bug maybe?\n",
    "    print(\"last pos\",  last_pos_target_item_reverse)\n",
    "    print(\"item : \", last_predictions_reverse.argsort()[last_pos_target_item_reverse])\n",
    "\n",
    "    # worst_jacc_cfs = np.setdiff1d( worst_jacc_search_info[0].interactions['best'], best_interactions)\n",
    "    \n",
    "    if are_the_same(worst_jacc_search_info[0].interactions['best'], original_interactions):\n",
    "        # counter = counter + 1\n",
    "        print(\"Hopefully they are the same!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b587dd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_interactions [384 461 236 478  86 457 511  60 323 443 360 473 472 514 456 481 119 450\n",
      " 453 444]\n",
      "best_interactions [384 461 236 478  86 457 511  60 323 443 360 473 472 514 456 481 119 450\n",
      " 453]\n",
      "items_removed [444]\n",
      "target_item 80\n",
      "position target item in reverse mode 12\n",
      "worst_jacc [320, 84, 376, 1203, 1059, 223, 777, 91, 138, 196, 151, 121, 127, 75, 131, 118, 126, 896, 147, 80]\n",
      "jacc [2840, 2562, 3681, 3468, 1977, 3598, 3706, 139, 3471, 3603, 1688, 3595, 1988, 3602, 3600, 3601, 3597, 2044, 271, 665]\n",
      "modified_sample [444, 84, 376, 1203, 1059, 223, 777, 91, 138, 196, 151, 121, 127, 75, 131, 118, 126, 896, 147, 80]\n",
      "search_info [384, 461, 236, 478, 86, 457, 511, 60, 323, 443, 360, 473, 472, 514, 456, 481, 119, 450, 453, 444]\n",
      "defaultdict(<class 'dict'>, {12: {'random_0': [[1], [1], [1], [1], [2], [2], [8], [19], [1], [0], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]]}})\n",
      "defaultdict(<class 'list'>, {})\n",
      "defaultdict(<class 'dict'>, {7: {'random_0': [[1], [1], [20], [20], [21], [21], [8], [20], [1], [20], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]]}})\n",
      "defaultdict(<class 'list'>, {})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "# get currently working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# load functions from other notebooks\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb').replace(\"\\\\\", \"/\")\n",
    "%run $helpers_file\n",
    "\n",
    "\n",
    "FLOAT_MAX = np.finfo(np.float32).max\n",
    "\n",
    "\n",
    "target_pos = 7\n",
    "user_id = 8\n",
    "top_k = 10\n",
    "brute_force_specific_cfs = None\n",
    "i = 0\n",
    "\n",
    "# while brute_force_specific_cfs == [] or brute_force_specific_cfs is None:\n",
    "#     i += 1\n",
    "#     brute_force_specific_cfs = _find_specific_cfs_(test, pretrained_models['lstm'], get_backend_strategy('brute_force'), 7, False, jaccard_sims_matrix, i, 100000, 10)\n",
    "\n",
    "brute_force_specific_cfs = _find_specific_cfs_(test, pretrained_models['lstm'], get_backend_strategy('brute_force'), target_pos, False, jaccard_sims_matrix, user_id, 100000, top_k)\n",
    "\n",
    "user_sequences = test.sequences[test.user_ids == user_id]\n",
    "user_sequences = [sequence for sequence in user_sequences if all(value > 0 for value in sequence)]\n",
    "\n",
    "original_interactions = user_sequences[0]\n",
    "print(\"original_interactions\", original_interactions)\n",
    "\n",
    "best_interactions = brute_force_specific_cfs[0].interactions['best']\n",
    "print(\"best_interactions\", best_interactions)\n",
    "\n",
    "items_removed = np.setdiff1d(original_interactions, best_interactions)\n",
    "print(\"items_removed\", items_removed)\n",
    "\n",
    "predictions = -pretrained_models['lstm'].predict(original_interactions)\n",
    "predictions[original_interactions] = FLOAT_MAX\n",
    "target_item = predictions.argsort()[min(top_k, target_pos)]\n",
    "print(\"target_item\", target_item)\n",
    "\n",
    "predictions_reverse = -pretrained_models['lstm'].predict(best_interactions)\n",
    "predictions_reverse[best_interactions] = FLOAT_MAX\n",
    "pos_target_item_reverse = np.where(predictions_reverse.argsort() == target_item)[0][0]\n",
    "print(\"position target item in reverse mode\", pos_target_item_reverse)\n",
    "\n",
    "worst_jaccard_sample = find_worst_items_with_jaccard(target_item, best_interactions, jaccard_sims_matrix, 20)\n",
    "print(\"worst_jacc\", worst_jaccard_sample)\n",
    "\n",
    "jaccard_sample = find_best_items_with_jaccard(target_item, best_interactions, jaccard_sims_matrix, 20)\n",
    "print(\"jacc\", jaccard_sample)\n",
    "rs_sample = find_best_items_using_recommender(target_item, best_interactions, pretrained_models['lstm'], 20)\n",
    "if set(items_removed) <= set(jaccard_sample):\n",
    "    print(\"jaccard_sample\", jaccard_sample)\n",
    "    search_info = retrieve_solutions_specific_sequence(user_id, test, pretrained_models['lstm'], get_backend_strategy('brute_force'), 100000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, jaccard_sample)\n",
    "\n",
    "elif set(items_removed) <= set(rs_sample):\n",
    "    print(\"rs_sample\", rs_sample)\n",
    "    search_info = retrieve_solutions_specific_sequence(user_id, test, pretrained_models['lstm'], get_backend_strategy('brute_force'), 100000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, rs_sample)\n",
    "else:\n",
    "    worst_jaccard_sample[:len(items_removed)] = items_removed[:len(items_removed)]\n",
    "    print(\"modified_sample\", worst_jaccard_sample)\n",
    "    search_info = retrieve_solutions_specific_sequence(user_id, test, pretrained_models['lstm'], get_backend_strategy('brute_force'), 100000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, worst_jaccard_sample)\n",
    "\n",
    "print(\"search_info\", search_info[0].interactions['best'])\n",
    "\n",
    "result2 = dict.fromkeys([pos_target_item_reverse])\n",
    "result2[pos_target_item_reverse] = []\n",
    "result2[pos_target_item_reverse].extend(search_info)\n",
    "\n",
    "cnt2 = defaultdict(dict)\n",
    "no_target_achieved_cases2 = defaultdict(list)\n",
    "\n",
    "\n",
    "cnt2, no_target_achieved_cases2 = convert_res_to_lists(result2, cnt2, no_target_achieved_cases2, \"random_0\", True)\n",
    "print(cnt2)\n",
    "print(no_target_achieved_cases2)\n",
    "\n",
    "result = dict.fromkeys([target_pos])\n",
    "result[target_pos] = []\n",
    "result[target_pos].extend(brute_force_specific_cfs)\n",
    "\n",
    "cnt = defaultdict(dict)\n",
    "no_target_achieved_cases = defaultdict(list)\n",
    "\n",
    "target_item = 0\n",
    "\n",
    "cnt, no_target_achieved_cases = convert_res_to_lists(result, cnt, no_target_achieved_cases, \"random_0\", False)\n",
    "print(cnt)\n",
    "print(no_target_achieved_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "df3711c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id =  5\n",
      "original_interactions [384 461 236 478  86 457 511  60 323 443 360 473 472 514 456 481 119 450\n",
      " 453 444]\n",
      "best_interactions []\n",
      "items_removed [ 60  86 119 236 323 360 384 443 444 450 453 456 457 461 472 473 478 481\n",
      " 511 514]\n",
      "target_item 1439\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [103]\u001b[0m, in \u001b[0;36m<cell line: 43>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m target_item \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39margsort()[\u001b[38;5;28mmin\u001b[39m(top_k, target_pos)]\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_item\u001b[39m\u001b[38;5;124m\"\u001b[39m, target_item)\n\u001b[1;32m---> 43\u001b[0m predictions_reverse \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mpretrained_models\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlstm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_interactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m predictions_reverse[best_interactions] \u001b[38;5;241m=\u001b[39m FLOAT_MAX\n\u001b[0;32m     45\u001b[0m pos_target_item_reverse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(predictions_reverse\u001b[38;5;241m.\u001b[39margsort() \u001b[38;5;241m==\u001b[39m target_item)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\Thesis\\previous_work\\spotlight_ext\\spotlight\\sequence\\implicit.py:318\u001b[0m, in \u001b[0;36mImplicitSequenceModel.predict\u001b[1;34m(self, sequences, item_ids)\u001b[0m\n\u001b[0;32m    315\u001b[0m     item_ids \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_items)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input(item_ids)\n\u001b[1;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m sequences \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(sequences\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    321\u001b[0m item_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(item_ids\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64))\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\Thesis\\previous_work\\spotlight_ext\\spotlight\\sequence\\implicit.py:187\u001b[0m, in \u001b[0;36mImplicitSequenceModel._check_input\u001b[1;34m(self, item_ids)\u001b[0m\n\u001b[0;32m    185\u001b[0m     item_id_max \u001b[38;5;241m=\u001b[39m item_ids\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m     item_id_max \u001b[38;5;241m=\u001b[39m \u001b[43mitem_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m item_id_max \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_items:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaximum item id greater \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    191\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthan number of items in model.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_methods.py:41\u001b[0m, in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     40\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_maximum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# get currently working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# load functions from other notebooks\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb').replace(\"\\\\\", \"/\")\n",
    "%run $helpers_file\n",
    "\n",
    "\n",
    "FLOAT_MAX = np.finfo(np.float32).max\n",
    "\n",
    "target_pos = 1\n",
    "user_id = 8\n",
    "top_k = 10\n",
    "combo_specific_cfs = None\n",
    "i = 0\n",
    "\n",
    "while combo_specific_cfs == [] or combo_specific_cfs is None:\n",
    "    i += 1\n",
    "    combo_specific_cfs = _find_specific_cfs_(test, pretrained_models['lstm'], get_backend_strategy('combo'), target_pos, False, jaccard_sims_matrix, i, 1000, 10, alpha=0.5, normalization='default')\n",
    "\n",
    "# combo_specific_cfs = _find_specific_cfs_(test, pretrained_models['lstm'], get_backend_strategy('combo'), target_pos, False, jaccard_sims_matrix, user_id, 1000, top_k)\n",
    "print(\"user_id = \", i)\n",
    "user_sequences = test.sequences[test.user_ids == user_id]\n",
    "user_sequences = [sequence for sequence in user_sequences if all(value > 0 for value in sequence)]\n",
    "\n",
    "original_interactions = user_sequences[0]\n",
    "print(\"original_interactions\", original_interactions)\n",
    "\n",
    "best_interactions = combo_specific_cfs[0].interactions['best']\n",
    "print(\"best_interactions\", best_interactions)\n",
    "\n",
    "items_removed = np.setdiff1d(original_interactions, best_interactions)\n",
    "print(\"items_removed\", items_removed)\n",
    "\n",
    "predictions = -pretrained_models['lstm'].predict(original_interactions)\n",
    "predictions[original_interactions] = FLOAT_MAX\n",
    "target_item = predictions.argsort()[min(top_k, target_pos)]\n",
    "print(\"target_item\", target_item)\n",
    "\n",
    "predictions_reverse = -pretrained_models['lstm'].predict(best_interactions)\n",
    "predictions_reverse[best_interactions] = FLOAT_MAX\n",
    "pos_target_item_reverse = np.where(predictions_reverse.argsort() == target_item)[0][0]\n",
    "print(\"position target item in reverse mode\", pos_target_item_reverse)\n",
    "\n",
    "worst_jaccard_sample = find_worst_items_with_jaccard(target_item, best_interactions, jaccard_sims_matrix, 20)\n",
    "print(\"worst_jacc\", worst_jaccard_sample)\n",
    "\n",
    "jaccard_sample = find_best_items_with_jaccard(target_item, best_interactions, jaccard_sims_matrix, 20)\n",
    "print(\"jacc\", jaccard_sample)\n",
    "rs_sample = find_best_items_using_recommender(target_item, best_interactions, pretrained_models['lstm'], 20)\n",
    "if set(items_removed) <= set(jaccard_sample):\n",
    "    print(\"jaccard_sample\", jaccard_sample)\n",
    "    search_info = retrieve_solutions_specific_sequence(i, test, pretrained_models['lstm'], get_backend_strategy('combo'), 1000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, jaccard_sample)\n",
    "\n",
    "elif set(items_removed) <= set(rs_sample):\n",
    "    print(\"rs_sample\", rs_sample)\n",
    "    search_info = retrieve_solutions_specific_sequence(i, test, pretrained_models['lstm'], get_backend_strategy('combo'), 1000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, rs_sample)\n",
    "else:\n",
    "    worst_jaccard_sample[:len(items_removed)] = items_removed[:len(items_removed)]\n",
    "    print(\"modified_sample\", worst_jaccard_sample)\n",
    "    search_info = retrieve_solutions_specific_sequence(i, test, pretrained_models['lstm'], get_backend_strategy('combo'), 1000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, worst_jaccard_sample)\n",
    "\n",
    "print(\"search_info\", search_info[0].interactions['best'])\n",
    "\n",
    "result2 = dict.fromkeys([pos_target_item_reverse])\n",
    "result2[pos_target_item_reverse] = []\n",
    "result2[pos_target_item_reverse].extend(search_info)\n",
    "\n",
    "cnt2 = defaultdict(dict)\n",
    "no_target_achieved_cases2 = defaultdict(list)\n",
    "\n",
    "\n",
    "cnt2, no_target_achieved_cases2 = convert_res_to_lists(result2, cnt2, no_target_achieved_cases2, \"random_0\", True)\n",
    "print(cnt2)\n",
    "print(no_target_achieved_cases2)\n",
    "\n",
    "result = dict.fromkeys([target_pos])\n",
    "result[target_pos] = []\n",
    "result[target_pos].extend(combo_specific_cfs)\n",
    "\n",
    "cnt = defaultdict(dict)\n",
    "no_target_achieved_cases = defaultdict(list)\n",
    "\n",
    "target_item = 0\n",
    "\n",
    "cnt, no_target_achieved_cases = convert_res_to_lists(result, cnt, no_target_achieved_cases, \"random_0\", False)\n",
    "print(cnt)\n",
    "print(no_target_achieved_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e668070d",
   "metadata": {},
   "source": [
    "# Evaluation of the sampling strategies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349dbfed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "regular-hollywood",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = defaultdict(dict)\n",
    "no_target_achieved_cases = defaultdict(list)\n",
    "strs_prefix = ''\n",
    "missing_target_in_topk = True\n",
    "\n",
    "for i in range(1):\n",
    "    # Convert results to lists for each strategy\n",
    "    cnt, no_target_achieved_cases = convert_res_to_lists(\n",
    "        getattr(current_module, f'{strs_prefix}{Strategies.stypes[0]}_cfs')[i],\n",
    "        cnt, no_target_achieved_cases, f'random_{i}', missing_target_in_topk)\n",
    "    \n",
    "    cnt, no_target_achieved_cases = convert_res_to_lists(\n",
    "        getattr(current_module, f'{strs_prefix}{Strategies.stypes[1]}_cfs')[i],\n",
    "        cnt, no_target_achieved_cases, f'brute_force_{i}', missing_target_in_topk)\n",
    "\n",
    "    cnt, no_target_achieved_cases = convert_res_to_lists(\n",
    "        getattr(current_module, f'{strs_prefix}{Strategies.stypes[2]}_cfs')[i+1],\n",
    "        cnt, no_target_achieved_cases, f'bfs_{i}', missing_target_in_topk)\n",
    "\n",
    "    cnt, no_target_achieved_cases = convert_res_to_lists(\n",
    "        getattr(current_module, f'{strs_prefix}{Strategies.stypes[3]}_cfs')[i],\n",
    "        cnt, no_target_achieved_cases, f'bidirectional_001_{i}', missing_target_in_topk)\n",
    "    cnt, no_target_achieved_cases = convert_res_to_lists(\n",
    "        getattr(current_module, f'{strs_prefix}{Strategies.stypes[3]}_cfs')[i + 1],\n",
    "        cnt, no_target_achieved_cases, f'bidirectional_5_{i}', missing_target_in_topk)\n",
    "    cnt, no_target_achieved_cases = convert_res_to_lists(\n",
    "        getattr(current_module, f'{strs_prefix}{Strategies.stypes[3]}_cfs')[i + 2],\n",
    "        cnt, no_target_achieved_cases, f'bidirectional_999_{i}', missing_target_in_topk)\n",
    "    cnt, no_target_achieved_cases = convert_res_to_lists(\n",
    "        getattr(current_module, f'{strs_prefix}{Strategies.stypes[4]}_cfs')[i],\n",
    "        cnt, no_target_achieved_cases, f'combo_001_{i}', missing_target_in_topk)\n",
    "    cnt, no_target_achieved_cases = convert_res_to_lists(\n",
    "        getattr(current_module, f'{strs_prefix}{Strategies.stypes[4]}_cfs')[i + 1],\n",
    "        cnt, no_target_achieved_cases, f'combo_5_{i}', missing_target_in_topk)\n",
    "    cnt, no_target_achieved_cases = convert_res_to_lists(\n",
    "        getattr(current_module, f'{strs_prefix}{Strategies.stypes[4]}_cfs')[i + 2],\n",
    "        cnt, no_target_achieved_cases, f'combo_999_{i}', missing_target_in_topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f670c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of counterfactual methods supported\n",
    "methods_supported = ['Brute_Force', 'Random', 'BFS'] + \\\n",
    "    [f'BiDirectional_{m}' for m in ['001', '5', '999']] + \\\n",
    "    [f'Combo_{m}' for m in ['001', '5', '999']]\n",
    "\n",
    "#it is at this index that starts and ends the stats_per_cardinality storing\n",
    "custom_range = [9, 29] \n",
    "\n",
    "# Get the target positions from the keys of the 'cnt' dictionary\n",
    "target_pos = list(cnt.keys())\n",
    "\n",
    "# Define column names for the resulting DataFrame\n",
    "cnames = ['user_id', 'method', 'pos', 'budget', 'init_budget', 'best_budget', 'cardinality', 'cfs_orig', 'cfs']\n",
    "\n",
    "rows, cols = 5, 1\n",
    "\n",
    "# Initialize an empty list to store several DataFrames\n",
    "tmp_dfs = []\n",
    "\n",
    "for col in range(cols):\n",
    "    for pos, row in zip(target_pos, range(rows)):\n",
    "        tmp_dfs.append( \n",
    "            # Constructs a DataFrame from a list of records.\n",
    "            pd.DataFrame.from_records(\n",
    "                list(\n",
    "                    itertools.chain(\n",
    "                        *(\n",
    "                            zip(\n",
    "                                v[6], itertools.repeat(k), itertools.repeat(pos), v[i], v[2], v[3], \n",
    "                                itertools.repeat(i - custom_range[0] + 1), v[7], v[8]\n",
    "                            )\n",
    "                            for k, v in cnt[pos].items() if f'_{col}' in k and k.rsplit('_', 1)[0] in map(lambda x: x.lower(), methods_supported)\n",
    "                            for i in range(custom_range[0], custom_range[1])\n",
    "                        )\n",
    "                    )\n",
    "                ), columns=cnames\n",
    "            )\n",
    "        )\n",
    "\n",
    "df = pd.concat(tmp_dfs, ignore_index=True)\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a boolean Series (idx) indicating which rows are duplicates based on the conditions specified\n",
    "idx = df.loc[(df['cfs_orig'] == df['cfs'])].duplicated(subset=['user_id', 'method', 'pos'], keep='last')\n",
    "\n",
    "# This line updates the 'budget' column for rows where 'cfs_orig' is equal to 'cfs' and are not duplicate with the values from the 'best_budget' column\n",
    "df.loc[(df['cfs_orig'] == df['cfs']) & ~idx, ['budget']] = df.loc[(df['cfs_orig'] == df['cfs']) & ~idx]['best_budget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create dataframes for the plots'''\n",
    "\n",
    "# 1st plot: %users per card\n",
    "\n",
    "# Calculates the total number of unique users\n",
    "all_users = df['user_id'].nunique()\n",
    "\n",
    "res = []\n",
    "\n",
    "# Loop for the cardinality\n",
    "for i in range(1, 21):\n",
    "    res.append(df[(df['budget'] > 0) & (df['cardinality'] <= i) & (df['best_budget'] <= 1000)]\n",
    "               .groupby(['method', 'pos'], sort=False)[['user_id', 'cfs']]\n",
    "               .nunique()\n",
    "               .reset_index())\n",
    "\n",
    "ddf = pd.concat(res, ignore_index=True)\n",
    "ddf['%users'] = (ddf['user_id'] / all_users) * 100\n",
    "\n",
    "# 2nd plot: average budget\n",
    "\n",
    "\n",
    "init_budget = 100\n",
    "end_budget = 1001\n",
    "step_budget = 100\n",
    "\n",
    "# Initialize an empty list to store aggregated results\n",
    "res = []\n",
    "\n",
    "# Iterate over a range of budget thresholds\n",
    "for b in range(init_budget, end_budget, step_budget):\n",
    "    # Filter DataFrame based on budget and best_budget conditions\n",
    "    filtered_df = df[(df['budget'] > 0) & (df['best_budget'] < b)]\n",
    "    \n",
    "    # Group by 'method' and 'pos', calculate mean of 'cfs' and number of unique users\n",
    "    aggregated = filtered_df.groupby(['method', 'pos'], sort=False)\\\n",
    "        .agg(card_mean=('cfs', 'mean'), no_users=('user_id', 'nunique'))\\\n",
    "        .reset_index()\n",
    "    \n",
    "    # Add a new column 'budget_thres' with the current budget threshold\n",
    "    aggregated['budget_thres'] = b\n",
    "    \n",
    "    # Add a new column 'max_users' with the maximum number of users for each 'pos'\n",
    "    aggregated['max_users'] = aggregated.groupby(['pos'])['no_users'].transform(max)\n",
    "    \n",
    "    # Append the aggregated DataFrame to the list\n",
    "    res.append(aggregated)\n",
    "\n",
    "hard_case_filtered_df = df[(df['budget'] > 0) & (df['best_budget'] > 1000)]\n",
    "print(\"size hard_cases\", len(hard_case_filtered_df))\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "ddf2 = pd.concat(res, ignore_index=True)\n",
    "\n",
    "# Calculate the percentage of users based on the total number of users\n",
    "ddf2['%users'] = (ddf2['no_users'] / all_users) * 100\n",
    "\n",
    "\n",
    "# 3rd plot :\n",
    "\n",
    "def aggf(data):\n",
    "    # For each user, select the data rows where the user's budget is at its maximum.\n",
    "    # By doing so, the resulting DataFrame will contain, for each user, only those records \n",
    "    # where he spent his highest budget.\n",
    "    users_grouping = data.groupby(['user_id']).apply(\n",
    "        lambda d: d.loc[d['budget'] == d['budget'].max()]\n",
    "    )\n",
    "\n",
    "    # Calculate the mean budget and count of users for the group\n",
    "    return pd.Series(\n",
    "        [users_grouping['budget'].mean(),\n",
    "         users_grouping['user_id'].count()],\n",
    "        ['avg_budget', 'no_users']\n",
    "    )\n",
    "\n",
    "# Initialize an empty list to store aggregated results\n",
    "res = []\n",
    "\n",
    "# Iterate over a range of cardinalities in descending order\n",
    "for i in range(5, 0, -1):\n",
    "    # Filter DataFrame based on budget, cardinality, and best_budget conditions\n",
    "    filtered_df = df[(df['budget'] > 0) & (df['cardinality'] <= i) & (df['best_budget'] <= 1000)]\n",
    "    \n",
    "    # Group by 'method' and 'pos', apply custom aggregation function\n",
    "    aggregated = filtered_df.groupby(['method', 'pos'], sort=False)\\\n",
    "        .apply(aggf)\\\n",
    "        .reset_index()\n",
    "    \n",
    "    # Add a new column 'cardinality' with the current cardinality\n",
    "    aggregated['cardinality'] = i\n",
    "    \n",
    "    # Append the aggregated DataFrame to the list\n",
    "    res.append(aggregated)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "ddf3 = pd.concat(res, ignore_index=True)\n",
    "\n",
    "# Calculate the percentage of users based on the total number of users\n",
    "ddf3['%users'] = (ddf3['no_users'] / all_users) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-wheat",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "\n",
    "\n",
    "sns.set_theme(style=\"ticks\", font_scale=1.5, )\n",
    "\n",
    "# Create an array with the colors you want to use\n",
    "colors = ['black', 'darkred', 'green', 'darkblue', 'dodgerblue', 'darkturquoise', 'darkgoldenrod', 'orange', 'chocolate']\n",
    "\n",
    "# Set your custom color palette\n",
    "custom_palette = sns.set_palette(sns.color_palette(colors))\n",
    "\n",
    "custom_markers = ['o', 'v', '^', 's', 'P', 'X', '<', '>', 'D', ]\n",
    "# custom_markers = ['o', 'v', '^', 'P', 'P', 'P', 'X', 'X', 'X']\n",
    "custom_dashes = [(1, 0), (4, 0), (4, 0), (4, 0), (6, 2), (1, 2), (1, 0), (6, 2), (1, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-painting",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "a4_dims = (11.7, 8.27)\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=ddf[(ddf['pos'] == 13)],  # Filter data for a specific position\n",
    "    kind=\"bar\",  # Type of plot\n",
    "    x=\"cfs\",  # X-axis variable\n",
    "    y=\"%users\",  # Y-axis variable\n",
    "    hue=\"method\",  # Variable for color differentiation\n",
    "    ci=\"sd\",  # Confidence interval for error bars\n",
    "    capsize=0.1,  # Size of the caps on error bars\n",
    "    palette=\"dark\",  # Color palette to use\n",
    "    alpha=.8,  # Transparency of bars\n",
    "    height=6,  # Height of the plot\n",
    "    aspect=4,  # Aspect ratio of the plot\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-belle",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Loop through each position and create individual line plots\n",
    "for i, p in enumerate(df.groupby('pos').groups.keys()):\n",
    "    a4_dims = (11.7, 8.27)\n",
    "    fig, ax = plt.subplots(figsize=a4_dims)\n",
    "\n",
    "    g = sns.lineplot(\n",
    "        ax=ax, data=ddf2[(ddf2['pos'] == p)],\n",
    "        x=\"budget_thres\", y=\"card_mean\", hue=\"method\", style='method',\n",
    "        palette=custom_palette,\n",
    "        markers=custom_markers[:len(ddf2['method'].unique())], markersize=12, lw=2, ls='solid', dashes=custom_dashes[:len(ddf2['method'].unique())]\n",
    "    )\n",
    "\n",
    "    # Set the y-axis to logarithmic scale\n",
    "    # g.set(yscale='log')\n",
    "\n",
    "    # Set formatting for y-axis labels\n",
    "    ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%.0f'))\n",
    "    ax.yaxis.set_minor_formatter(mticker.FormatStrFormatter('%.0f'))\n",
    "\n",
    "    # Customize the legend\n",
    "    lgnd = ax.legend(fancybox=True, frameon=True, labelspacing=0, borderpad=1, loc='upper left', bbox_to_anchor=(0, 0.9), ncol=3)\n",
    "\n",
    "    # Replace legend labels with new labels\n",
    "    new_labels = ['Rnd', 'Exh', 'BFS', 'Pri_0.001', 'Pri_0.5', 'Pri_0.999', 'Hyb_0.001', 'Hyb_0.5', 'Hyb_0.999']\n",
    "    for t, l in zip(lgnd.texts, new_labels):\n",
    "        t.set_text(l)\n",
    "\n",
    "    # Set labels for x-axis and y-axis, and title for the plot\n",
    "    ax.set(xlabel=\"Budget\", ylabel=\"Avg. Explanation Length\")\n",
    "    ax.set_title(f'Target position {p}')\n",
    "\n",
    "    # Adjust layout and save the plot as a PDF file\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_folder, f\"avg_card_to_thres_pos_{p}.pdf\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-commissioner",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Loop through target positions and create line plots for the percentage of users against budget thresholds\n",
    "\n",
    "# Iterate over target positions and their corresponding groups in the DataFrame\n",
    "for i, p in enumerate(df.groupby('pos').groups.keys()):\n",
    "    a4_dims = (11.7, 8.27)\n",
    "    fig, ax = plt.subplots(figsize=a4_dims)\n",
    "\n",
    "    g = sns.lineplot(\n",
    "        ax=ax, data=ddf2[(ddf2['pos'] == p)],\n",
    "        x=\"budget_thres\", y=\"%users\", hue=\"method\", style='method',\n",
    "        palette=custom_palette, markers=custom_markers, markersize=12, dashes=custom_dashes, lw=2,\n",
    "    )\n",
    "\n",
    "    # Customize the legend\n",
    "    lgnd = ax.legend(fancybox=True, frameon=True, labelspacing=0, borderpad=1, loc='lower right', ncol=3)\n",
    "\n",
    "    # Replace legend labels with new labels\n",
    "    new_labels = ['Rnd', 'Exh', 'BFS', 'Pri_0.001', 'Pri_0.5', 'Pri_0.999', 'Hyb_0.001', 'Hyb_0.5', 'Hyb_0.999']\n",
    "    for t, l in zip(lgnd.texts, new_labels):\n",
    "        t.set_text(l)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    ax.set(xlabel=\"Budget\", ylabel=\"Explained Recommendations (%)\")\n",
    "    ax.set_title(f'Target position {p}')\n",
    "\n",
    "    # Adjust layout for better visualization\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save the plot as a PDF file in the specified plots folder\n",
    "    plt.savefig(os.path.join(plots_folder, f\"users_percent_to_thres_pos_{p}.pdf\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dab63bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through target positions and create line plots for the percentage of users against budget thresholds\n",
    "\n",
    "# Iterate over target positions and their corresponding groups in the DataFrame\n",
    "for i, p in enumerate(df.groupby('pos').groups.keys()):\n",
    "    a4_dims = (11.7, 8.27)\n",
    "    fig, ax = plt.subplots(figsize=a4_dims)\n",
    "\n",
    "    g = sns.lineplot(\n",
    "        ax=ax, data=ddf2[(ddf2['pos'] == p)],\n",
    "        x=\"card_mean\", y=\"%users\", hue=\"method\", style='method',\n",
    "        palette=custom_palette, markers=custom_markers, markersize=12, dashes=custom_dashes, lw=2,\n",
    "    )\n",
    "\n",
    "    # Customize the legend\n",
    "    lgnd = ax.legend(fancybox=True, frameon=True, labelspacing=0, borderpad=1, loc='lower right', ncol=3)\n",
    "\n",
    "    # Replace legend labels with new labels\n",
    "    new_labels = ['Rnd', 'Exh', 'BFS', 'Pri_0.001', 'Pri_0.5', 'Pri_0.999', 'Hyb_0.001', 'Hyb_0.5', 'Hyb_0.999']\n",
    "    for t, l in zip(lgnd.texts, new_labels):\n",
    "        t.set_text(l)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    ax.set(xlabel=\"Avg. Explanation Length\", ylabel=\"Explained Recommendations (%)\")\n",
    "    ax.set_title(f'Target position {p}')\n",
    "\n",
    "    # Adjust layout for better visualization\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save the plot as a PDF file in the specified plots folder\n",
    "    plt.savefig(os.path.join(plots_folder, f\"users_percent_to_thres_pos_{p}.pdf\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3756c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(df.groupby('pos').groups.keys()):\n",
    "    a4_dims = (11.7, 8.27)\n",
    "    fig, ax = plt.subplots(figsize=a4_dims)\n",
    "\n",
    "    g = sns.lineplot(\n",
    "        ax=ax, data=ddf2[(ddf2['pos'] == p)],\n",
    "        x=\"%users\", y=\"card_mean\", hue=\"method\", style='method',  # Inverser x et y\n",
    "        palette=custom_palette, markers=custom_markers, markersize=12, dashes=custom_dashes, lw=2,\n",
    "    )\n",
    "\n",
    "    # Customize the legend\n",
    "    lgnd = ax.legend(fancybox=True, frameon=True, labelspacing=0, borderpad=1, loc='lower right', ncol=3)\n",
    "\n",
    "    # Replace legend labels with new labels\n",
    "    new_labels = ['Rnd', 'Exh', 'BFS', 'Pri_0.001', 'Pri_0.5', 'Pri_0.999', 'Hyb_0.001', 'Hyb_0.5', 'Hyb_0.999']\n",
    "    for t, l in zip(lgnd.texts, new_labels):\n",
    "        t.set_text(l)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    ax.set(xlabel=\"Explained Recommendations (%)\", ylabel=\"Avg. Explanation Length\")  # Inverser les étiquettes\n",
    "    ax.set_title(f'Target position {p}')\n",
    "\n",
    "    # Adjust layout for better visualization\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save the plot as a PDF file in the specified plots folder\n",
    "    plt.savefig(os.path.join(plots_folder, f\"users_percent_to_thres_pos_{p}.pdf\"), dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fd0828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Print unique methods and custom markers side by side\n",
    "unique_methods = ddf3['method'].unique()\n",
    "print(\"Methods:\", unique_methods)\n",
    "print(\"Custom Markers:\", custom_markers)\n",
    "\n",
    "# Step 2: Create a mapping of methods to markers\n",
    "method_marker_mapping = list(zip(unique_methods, custom_markers))\n",
    "print(\"Method to Marker Mapping:\", method_marker_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e1ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_markers = ['o', 'v', '^', 'P', 'P', 'P', 'X', 'X', 'X']\n",
    "custom_dashes = [(1, 0), (4, 0), (4, 0), (4, 0), (6, 2), (1, 2), (1, 0), (6, 2), (1, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-single",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Loop through target positions and create line plots for average budget spent against acceptable explanation length\n",
    "\n",
    "# Iterate over target positions and their corresponding groups in the DataFrame\n",
    "for i, p in enumerate(df.groupby('pos').groups.keys()):\n",
    "    a4_dims = (11.7, 8.27)\n",
    "    fig, ax = plt.subplots(figsize=a4_dims)\n",
    "\n",
    "    g = sns.lineplot(\n",
    "        ax=ax, data=ddf3[(ddf3['pos']==p)],\n",
    "        x=\"cardinality\", y=\"avg_budget\", hue=\"method\", style='method',\n",
    "        palette=custom_palette, markers=custom_markers, markersize=12, dashes=custom_dashes, lw=2\n",
    "    )\n",
    "\n",
    "    # Set minor locator and formatter for y-axis\n",
    "    locmin = mticker.LogLocator(base=10, subs=[10, 20, 50, 100, 200, 500, 700], numticks=12)\n",
    "    ax.yaxis.set_minor_locator(locmin)\n",
    "    ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%.0f'))\n",
    "    ax.yaxis.set_minor_formatter(mticker.FormatStrFormatter('%.0f'))\n",
    "\n",
    "    # Set x-axis ticks\n",
    "    ax.set_xticks(np.arange(1, 6, 1))\n",
    "\n",
    "    # Uncomment the following line to add grid lines\n",
    "    # plt.grid(True, which=\"both\", ls=\"--\", c='gray')\n",
    "\n",
    "    # Customize the legend\n",
    "    lgnd = ax.legend(fancybox=True, frameon=True, labelspacing=0, borderpad=1, loc='center left', bbox_to_anchor=(0, 0.65), ncol=3)\n",
    "\n",
    "    # Replace legend labels with new labels\n",
    "    new_labels = ['Rnd', 'Exh', 'BFS', 'Pri_0.001', 'Pri_0.5', 'Pri_0.999', 'Hyb_0.001', 'Hyb_0.5', 'Hyb_0.999']\n",
    "    for t, l in zip(lgnd.texts, new_labels):\n",
    "        t.set_text(l)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    ax.set(xlabel=\"Acceptable Explanation Length\", ylabel=\"Avg. Budget Spent\")\n",
    "    ax.set_title(f'Target Position {p}')\n",
    "\n",
    "    # Adjust layout for better visualization\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save the plot as a PDF file in the specified plots folder\n",
    "    plt.savefig(os.path.join(plots_folder, f\"avg_budget_to_card_pos_{p}.pdf\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c981f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ddf3['pos'].unique():\n",
    "    fig, ax = plt.subplots(figsize=(11.7, 8.27))\n",
    "    sns.lineplot(ax=ax, data=ddf3[ddf3['pos']==p], x=\"cardinality\", y=\"avg_budget\", hue=\"method\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-weight",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over target positions and create line plots for percentage of users against acceptable explanation length\n",
    "\n",
    "# Iterate over target positions and their corresponding groups in the DataFrame\n",
    "for i, p in enumerate(df.groupby('pos').groups.keys()):\n",
    "    a4_dims = (11.7, 8.27)\n",
    "    fig, ax = plt.subplots(figsize=a4_dims)\n",
    "\n",
    "    g = sns.lineplot(ax=ax,\n",
    "        data=ddf3[(ddf3['pos']==p) ],\n",
    "        x=\"cardinality\", y=\"%users\", hue=\"method\", style='method',\n",
    "        palette=custom_palette, markers=custom_markers, markersize=12, dashes=custom_dashes, lw=2\n",
    "    )\n",
    "\n",
    "    ax.set_xticks(np.arange(1, 6, 1))\n",
    "\n",
    "\n",
    "    # Customize the legend\n",
    "    lgnd = ax.legend(fancybox=True, frameon=True, labelspacing=0, borderpad=1, loc='lower right', ncol=3)\n",
    "\n",
    "    # Replace legend labels with new labels\n",
    "    new_labels = ['Rnd', 'Exh', 'BFS', 'Pri_0.001', 'Pri_0.5', 'Pri_0.999', 'Hyb_0.001', 'Hyb_0.5', 'Hyb_0.999']\n",
    "    for t, l in zip(lgnd.texts, new_labels):\n",
    "        t.set_text(l)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    ax.set(xlabel=\"Acceptable Explanation Length\", ylabel=\"Explained Recommendations (%)\")\n",
    "    ax.set_title(f'Target position {p}')\n",
    "\n",
    "    # Adjust layout for better visualization\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save the plot as a PDF file in the specified plots folder\n",
    "    plt.savefig(os.path.join(plots_folder, f\"users_percent_to_card_pos_{p}.pdf\"), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-islam",
   "metadata": {},
   "source": [
    "# Amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-street",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment the following lines if you want to run the various strategies in budget_strategies\n",
    "# implemented_strategies = os.path.join(base_dir, 'budget_strategies.ipynb')\n",
    "# %run $implemented_strategies\n",
    "\n",
    "%store -r amazon_random_cfs\n",
    "%store -r amazon_brute_force_cfs\n",
    "\n",
    "%store -r amazon_bfs_yloss_cfs\n",
    "# %store -r dfs_yloss_cfs\n",
    "# %store -r bestfs_yloss_cfs\n",
    "\n",
    "%store -r amazon_bidirectional_cfs\n",
    "%store -r amazon_combo_cfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-blond",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "# cnt = dict.fromkeys(most_sim_cfs.keys())\n",
    "# no_target_achieved_cases = dict.fromkeys(most_sim_cfs.keys())\n",
    "cnt = defaultdict(dict)\n",
    "no_target_achieved_cases = defaultdict(list)\n",
    "strs_prefix = 'amazon_'\n",
    "\n",
    "for i in range(1):\n",
    "    cnt, no_target_achieved_cases = convert_res_to_lists(\n",
    "        getattr(current_module, f'{strs_prefix}{Strategies.stypes[0]}_cfs')[i],\n",
    "        cnt, no_target_achieved_cases, f'random_{i}')\n",
    "    cnt, no_target_achieved_cases = convert_res_to_lists(\n",
    "        getattr(current_module, f'{strs_prefix}{Strategies.stypes[1]}_cfs')[i],\n",
    "        cnt, no_target_achieved_cases, f'brute_force_{i}')\n",
    "\n",
    "    cnt, no_target_achieved_cases = convert_res_to_lists(\n",
    "        getattr(current_module, f'{strs_prefix}{Strategies.stypes[2]}_cfs')[i],\n",
    "        cnt, no_target_achieved_cases, f'bfs_{i}')\n",
    "\n",
    "    cnt, no_target_achieved_cases = convert_res_to_lists(\n",
    "        getattr(current_module, f'{strs_prefix}{Strategies.stypes[3]}_cfs')[i],\n",
    "        cnt, no_target_achieved_cases, f'bidirectional_001_{i}')\n",
    "    cnt, no_target_achieved_cases = convert_res_to_lists(\n",
    "        getattr(current_module, f'{strs_prefix}{Strategies.stypes[3]}_cfs')[i + 1],\n",
    "        cnt, no_target_achieved_cases, f'bidirectional_5_{i}')\n",
    "    cnt, no_target_achieved_cases = convert_res_to_lists(\n",
    "        getattr(current_module, f'{strs_prefix}{Strategies.stypes[3]}_cfs')[i + 2],\n",
    "        cnt, no_target_achieved_cases, f'bidirectional_999_{i}')\n",
    "\n",
    "    cnt, no_target_achieved_cases = convert_res_to_lists(\n",
    "        getattr(current_module, f'{strs_prefix}{Strategies.stypes[4]}_cfs')[i],\n",
    "        cnt, no_target_achieved_cases, f'combo_001_{i}')\n",
    "    cnt, no_target_achieved_cases = convert_res_to_lists(\n",
    "        getattr(current_module, f'{strs_prefix}{Strategies.stypes[4]}_cfs')[i + 1],\n",
    "        cnt, no_target_achieved_cases, f'combo_5_{i}')\n",
    "    cnt, no_target_achieved_cases = convert_res_to_lists(\n",
    "        getattr(current_module, f'{strs_prefix}{Strategies.stypes[4]}_cfs')[i + 2],\n",
    "        cnt, no_target_achieved_cases, f'combo_999_{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_supported = ['Brute_Force', 'Random', 'BFS'] + \\\n",
    "    [f'BiDirectional_{m}' for m in ['001', '5', '999']] + \\\n",
    "    [f'Combo_{m}' for m in ['001', '5', '999']]\n",
    "\n",
    "strategies = [('init', 2), ('best', 3)]\n",
    "custom_range = [9, 29]\n",
    "target_pos = list(cnt.keys())\n",
    "cnames = ['user_id', 'method', 'pos', 'budget', 'init_budget', 'best_budget', 'cardinality', 'cfs_orig', 'cfs']\n",
    "\n",
    "rows, cols = 5, 1\n",
    "\n",
    "tmp_dfs = []\n",
    "for col in range(cols):\n",
    "    for pos, row in zip(target_pos, range(rows)):\n",
    "\n",
    "        tmp_dfs.append(pd.DataFrame.from_records(list(\n",
    "            itertools.chain(*(\n",
    "                zip(v[6], itertools.repeat(k), itertools.repeat(pos), v[i], v[2], v[3],\n",
    "                    itertools.repeat(i - custom_range[0] + 1), v[7], v[8])\n",
    "                for k, v in cnt[pos].items() if f'_{col}' in k and k.rsplit('_', 1)[0] in map(lambda x: x.lower(), methods_supported)\n",
    "                for i in range(custom_range[0], custom_range[1])\n",
    "            ))), columns=cnames\n",
    "        ))\n",
    "\n",
    "df = pd.concat(tmp_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df.loc[(df['cfs_orig'] == df['cfs'])].duplicated(subset=['user_id', 'method', 'pos'], keep='last')\n",
    "df.loc[(df['cfs_orig'] == df['cfs']) & ~idx, ['budget']] = df.loc[(df['cfs_orig'] == df['cfs']) & ~idx]['best_budget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1st plot: %users per card\n",
    "all_users = df['user_id'].nunique()\n",
    "\n",
    "res = []\n",
    "for i in range(1, 21):\n",
    "    res.append(df[(df['budget'] > 0) & (df['cardinality'] <= i) & (df['best_budget'] <= 1000)]\n",
    "               .groupby(['method', 'pos'], sort=False)[['user_id', 'cfs']]\n",
    "               .nunique()\n",
    "               .reset_index())\n",
    "\n",
    "ddf = pd.concat(res, ignore_index=True)\n",
    "ddf['%users'] = (ddf['user_id'] / all_users) * 100\n",
    "\n",
    "# 2nd plot: average budget\n",
    "max_card = 5\n",
    "init = 100\n",
    "end = 1001\n",
    "step = 100\n",
    "\n",
    "\n",
    "res = []\n",
    "for b in range(init, end, step):\n",
    "    aggregated = df[(df['budget'] > 0) & (df['best_budget'] <= b)]\\\n",
    "        .groupby(['method', 'pos'], sort=False)\\\n",
    "        .agg(card_mean=('cfs', 'mean'), no_users=('user_id', 'nunique'))\\\n",
    "        .reset_index()\n",
    "    aggregated['budget_thres'] = b\n",
    "    aggregated['max_users'] = aggregated.groupby(['pos'])['no_users'].transform(max)\n",
    "    res.append(aggregated)\n",
    "\n",
    "ddf2 = pd.concat(res, ignore_index=True)\n",
    "ddf2['%users'] = (ddf2['no_users'] / all_users) * 100\n",
    "# ddf2['combined_means'] = ((ddf2['card_mean'] * ddf2['no_users']) + (20 * (ddf2['max_users'] - ddf2['no_users']))) / (ddf2['max_users'])\n",
    "ddf2['combined_means'] = ddf2['card_mean']\n",
    "\n",
    "\n",
    "# 3rd plot:\n",
    "def aggf(data):\n",
    "    users_grouping = data.groupby(['user_id']).apply(\n",
    "        lambda d: d.loc[d['budget'] == d['budget'].max()]\n",
    "    )\n",
    "\n",
    "    return pd.Series(\n",
    "        [users_grouping['budget'].mean(),\n",
    "         users_grouping['user_id'].count()],\n",
    "        ['avg_budget', 'no_users']\n",
    "    )\n",
    "\n",
    "res = []\n",
    "for i in range(5, 0, -1):\n",
    "    aggregated = df[(df['budget'] > 0) & (df['cardinality'] <= i) & (df['best_budget'] <= 1000)]\\\n",
    "        .groupby(['method', 'pos'], sort=False)\\\n",
    "        .apply(aggf)\\\n",
    "        .reset_index()\n",
    "    aggregated['cardinality'] = i\n",
    "    res.append(aggregated)\n",
    "\n",
    "ddf3 = pd.concat(res, ignore_index=True)\n",
    "ddf3['%users'] = (ddf3['no_users'] / all_users) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-attribute",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "\n",
    "\n",
    "sns.set_theme(style=\"ticks\", font_scale=1.5, )\n",
    "\n",
    "# Create an array with the colors you want to use\n",
    "# colors = [\"#FF0B04\", \"#4374B3\", \"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\n",
    "colors = ['black', 'darkred', 'green', 'darkblue', 'dodgerblue', 'darkturquoise', 'darkgoldenrod', 'orange', 'chocolate']\n",
    "\n",
    "# Set your custom color palette\n",
    "custom_palette = sns.set_palette(sns.color_palette(colors))\n",
    "\n",
    "# custom_markers = ['o', 'v', '^', 's', 'P', 'X', '<', '>', 'D', ]\n",
    "custom_markers = ['o', 'v', '^', 'P', 'P', 'P', 'X', 'X', 'X']\n",
    "custom_dashes = [(1, 0), (4, 0), (4, 0), (4, 0), (6, 2), (1, 2), (1, 0), (6, 2), (1, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-advertiser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a nested barplot by species and sex\n",
    "# g = sns.catplot(\n",
    "#     data=ddf2[ddf2['pos']==3], kind=\"bar\",\n",
    "#     x=\"budget_thres\", y='combined_means', hue=\"method\",\n",
    "#     ci=None, palette=\"dark\", alpha=.8, height=6, aspect=4,\n",
    "# )\n",
    "\n",
    "# num_locations = len(ddf2.groupby('budget_thres').groups.keys())\n",
    "# hatches = itertools.cycle(['//', '+', '-', 'x', '\\\\', '*', 'o', '.'])\n",
    "# for i, bar in enumerate(g.ax.patches):\n",
    "#     if i % num_locations == 0:\n",
    "#         hatch = next(hatches)\n",
    "#     bar.set_hatch(hatch)\n",
    "\n",
    "# g.ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=3, fancybox=True, shadow=False)\n",
    "\n",
    "# g.despine(left=True)\n",
    "# g.set_axis_labels(\"threshold\", \"cardinality average\")\n",
    "# g.legend.set_title(\"\")\n",
    "\n",
    "rows, cols = len(df.groupby('pos').groups.keys()), 1\n",
    "\n",
    "for i, p in enumerate(df.groupby('pos').groups.keys()):\n",
    "    a4_dims = (11.7, 8.27)\n",
    "    fig, ax = plt.subplots(figsize=a4_dims)\n",
    "\n",
    "    g = sns.lineplot(\n",
    "        ax=ax, data=ddf2[(ddf2['pos'] == p)],\n",
    "        x=\"budget_thres\", y=\"card_mean\", hue=\"method\", style='method',\n",
    "        palette=custom_palette,\n",
    "        markers=custom_markers, markersize=12, lw=2, ls='solid', dashes=custom_dashes\n",
    "    )\n",
    "\n",
    "    g.set(yscale='log')\n",
    "#     locmin = mticker.LogLocator(base=10, subs=np.arange(0, 1, 0.1), numticks=12)\n",
    "#     ax.yaxis.set_minor_locator(locmin)\n",
    "#     ax.yaxis.set_minor_formatter(mticker.NullFormatter())\n",
    "#     ax.yaxis.set_major_formatter(mticker.ScalarFormatter())\n",
    "#     ax.yaxis.get_major_formatter().set_scientific(False)\n",
    "#     ax.yaxis.get_major_formatter().set_useOffset(False)\n",
    "\n",
    "    # Turns on grid on the Axis.\n",
    "#     plt.grid(True, which=\"both\", ls=\"--\", c='gray')\n",
    "#     scientific_formatter = mticker.FuncFormatter()\n",
    "#     ax.yaxis.set_major_formatter(mticker.ScalarFormatter(useMathText=True))\n",
    "    ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%.0f'))\n",
    "    ax.yaxis.set_minor_formatter(mticker.FormatStrFormatter('%.0f'))\n",
    "\n",
    "    lgnd = ax.legend(fancybox=True, frameon=True, labelspacing=0, borderpad=1, loc='upper left', bbox_to_anchor=(0, 0.9), ncol=3,)\n",
    "\n",
    "    # replace labels\n",
    "    new_labels = ['Rnd', 'Exh', 'BFS', 'Pri_0.001', 'Pri_0.5', 'Pri_0.999', 'Hyb_0.001', 'Hyb_0.5', 'Hyb_0.999']\n",
    "    for t, l in zip(lgnd.texts, new_labels): t.set_text(l)\n",
    "\n",
    "    ax.set(xlabel=\"Budget\", ylabel=\"Avg. Explanation Length\")\n",
    "    ax.set_title(f'Target position {p}')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_folder, f\"{strs_prefix}avg_card_to_thres_pos_{p}.pdf\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = len(df.groupby('pos').groups.keys()), 1\n",
    "\n",
    "for i, p in enumerate(df.groupby('pos').groups.keys()):\n",
    "    a4_dims = (11.7, 8.27)\n",
    "    fig, ax = plt.subplots(figsize=a4_dims)\n",
    "\n",
    "    g = sns.lineplot(\n",
    "        ax=ax, data=ddf2[(ddf2['pos'] == p)],\n",
    "        x=\"budget_thres\", y=\"%users\", hue=\"method\", style='method',\n",
    "        palette=custom_palette, markers=custom_markers, markersize=12, dashes=custom_dashes, lw=2,\n",
    "    )\n",
    "\n",
    "#     g.set(yscale='log')\n",
    "#     locmin = mticker.LogLocator(base=10, subs=np.arange(0, 1, 0.1), numticks=12)\n",
    "#     ax.yaxis.set_minor_locator(locmin)\n",
    "#     ax.yaxis.set_minor_formatter(mticker.NullFormatter())\n",
    "\n",
    "#     plt.grid(True, which=\"both\", ls=\"--\", c='gray')\n",
    "\n",
    "    lgnd = ax.legend(fancybox=True, frameon=True, labelspacing=0, borderpad=1, loc='lower right', ncol=3,)\n",
    "\n",
    "    # replace labels\n",
    "    new_labels = ['Rnd', 'Exh', 'BFS', 'Pri_0.001', 'Pri_0.5', 'Pri_0.999', 'Hyb_0.001', 'Hyb_0.5', 'Hyb_0.999']\n",
    "    for t, l in zip(lgnd.texts, new_labels): t.set_text(l)\n",
    "\n",
    "    ax.set(xlabel=\"Budget\", ylabel=\"Explained Recommendations (%)\")\n",
    "    ax.set_title(f'Target position {p}')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_folder, f\"{strs_prefix}users_percent_to_thres_pos_{p}.pdf\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = len(df.groupby('pos').groups.keys()), 1\n",
    "\n",
    "for i, p in enumerate(df.groupby('pos').groups.keys()):\n",
    "    a4_dims = (11.7, 8.27)\n",
    "    fig, ax = plt.subplots(figsize=a4_dims)\n",
    "\n",
    "    g = sns.lineplot(\n",
    "        ax=ax, data=ddf3[(ddf3['pos']==p)],\n",
    "        x=\"cardinality\", y=\"avg_budget\", hue=\"method\", style='method',\n",
    "        palette=custom_palette, markers=custom_markers, markersize=12, dashes=custom_dashes, lw=2\n",
    "    )\n",
    "    g.set(yscale='log')\n",
    "    locmin = mticker.LogLocator(base=10, subs=[10, 20, 50, 100, 200, 500, 700], numticks=12)\n",
    "    ax.yaxis.set_minor_locator(locmin)\n",
    "    ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%.0f'))\n",
    "    ax.yaxis.set_minor_formatter(mticker.FormatStrFormatter('%.0f'))\n",
    "#     ax.yaxis.set_minor_formatter(mticker.NullFormatter())\n",
    "\n",
    "    ax.set_xticks(np.arange(1, 6, 1))\n",
    "\n",
    "#     plt.grid(True, which=\"both\", ls=\"--\", c='gray')\n",
    "\n",
    "    lgnd = ax.legend(fancybox=True, frameon=True, labelspacing=0, borderpad=1, loc='center left', bbox_to_anchor=(0, 0.65), ncol=3,)\n",
    "    # replace labels\n",
    "    new_labels = ['Rnd', 'Exh', 'BFS', 'Pri_0.001', 'Pri_0.5', 'Pri_0.999', 'Hyb_0.001', 'Hyb_0.5', 'Hyb_0.999']\n",
    "    for t, l in zip(lgnd.texts, new_labels): t.set_text(l)\n",
    "\n",
    "    ax.set(xlabel=\"Acceptable Explanation Length\", ylabel=\"Avg. Budget Spent\")\n",
    "    ax.set_title(f'Target Position {p}')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_folder, f\"{strs_prefix}avg_budget_to_card_pos_{p}.pdf\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = len(df.groupby('pos').groups.keys()), 1\n",
    "\n",
    "for i, p in enumerate(df.groupby('pos').groups.keys()):\n",
    "    a4_dims = (11.7, 8.27)\n",
    "    fig, ax = plt.subplots(figsize=a4_dims)\n",
    "\n",
    "    g = sns.lineplot(ax=ax,\n",
    "        data=ddf3[(ddf3['pos']==p) ],\n",
    "        x=\"cardinality\", y=\"%users\", hue=\"method\", style='method',\n",
    "        palette=custom_palette, markers=custom_markers, markersize=12, dashes=custom_dashes, lw=2\n",
    "    )\n",
    "\n",
    "#     g.set(yscale='log')\n",
    "#     locmin = mticker.LogLocator(base=10, subs=np.arange(0, 1, 0.1), numticks=12)\n",
    "#     ax.yaxis.set_minor_locator(locmin)\n",
    "#     ax.yaxis.set_minor_formatter(mticker.NullFormatter())\n",
    "#     ax.yaxis.set_minor_formatter(mticker.NullFormatter())\n",
    "\n",
    "    ax.set_xticks(np.arange(1, 6, 1))\n",
    "\n",
    "#     plt.grid(True, which=\"both\", ls=\"--\", c='gray')\n",
    "\n",
    "    lgnd = ax.legend(fancybox=True, frameon=True, labelspacing=0, borderpad=1, loc='lower right', ncol=3,)\n",
    "    # replace labels\n",
    "    new_labels = ['Rnd', 'Exh', 'BFS', 'Pri_0.001', 'Pri_0.5', 'Pri_0.999', 'Hyb_0.001', 'Hyb_0.5', 'Hyb_0.999']\n",
    "    for t, l in zip(lgnd.texts, new_labels): t.set_text(l)\n",
    "\n",
    "    ax.set(xlabel=\"Acceptable Explanation Length\", ylabel=\"Explained Recommendations (%)\")\n",
    "    ax.set_title(f'Target position {p}')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_folder, f\"{strs_prefix}users_percent_to_card_pos_{p}.pdf\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-fifty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
