{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file contains miscellaneous code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import local packages, e.g., dice, spotlight, and contant variables setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "for p in ['../spotlight_ext', '../dice_ext']:\n",
    "    module_path = os.path.abspath(os.path.join(p))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = '../models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage example for spotlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "# from spotlight.evaluation import mrr_score\n",
    "# from spotlight.factorization.implicit import ImplicitFactorizationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = get_movielens_dataset(variant='100K')\n",
    "\n",
    "# train, test = random_train_test_split(dataset)\n",
    "\n",
    "# model = ImplicitFactorizationModel(n_iter=3, loss='bpr')\n",
    "# model.fit(train)\n",
    "\n",
    "# mrr = mrr_score(model, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sequential models** (candidate for our problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spotlight.cross_validation import user_based_train_test_split\n",
    "# from spotlight.datasets.synthetic import generate_sequential\n",
    "\n",
    "\n",
    "# dataset = generate_sequential(num_users=100,\n",
    "#                               num_items=1000,\n",
    "#                               num_interactions=10000,\n",
    "#                               concentration_parameter=0.01,\n",
    "#                               order=3)\n",
    "\n",
    "# train, test = user_based_train_test_split(dataset)\n",
    "\n",
    "dataset = get_movielens_dataset(variant='1M')\n",
    "train, test = random_train_test_split(dataset, random_state=np.random.RandomState(2020))\n",
    "\n",
    "max_sequence_length = 20\n",
    "train = train.to_sequence(max_sequence_length=max_sequence_length)\n",
    "test = test.to_sequence(max_sequence_length=max_sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\Thesis\\previous_work\\notebooks\\misc.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/Thesis/previous_work/notebooks/misc.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m ImplicitSequenceModel(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/Thesis/previous_work/notebooks/misc.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/Thesis/previous_work/notebooks/misc.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     embedding_dim\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/Thesis/previous_work/notebooks/misc.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     random_state\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mRandomState(\u001b[39m2020\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/Thesis/previous_work/notebooks/misc.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/Thesis/previous_work/notebooks/misc.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model\u001b[39m.\u001b[39mfit(train)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Vincent/OneDrive/Bureau/ULB/MA2/MEMO-F524/Thesis/previous_work/notebooks/misc.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m mrr \u001b[39m=\u001b[39m sequence_mrr_score(model, test)\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\Thesis\\previous_work\\spotlight_ext\\spotlight\\evaluation.py:93\u001b[0m, in \u001b[0;36msequence_mrr_score\u001b[1;34m(model, test, exclude_preceding)\u001b[0m\n\u001b[0;32m     89\u001b[0m mrrs \u001b[39m=\u001b[39m []\n\u001b[0;32m     91\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(sequences)):\n\u001b[1;32m---> 93\u001b[0m     predictions \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mmodel\u001b[39m.\u001b[39;49mpredict(sequences[i])\n\u001b[0;32m     95\u001b[0m     \u001b[39mif\u001b[39;00m exclude_preceding:\n\u001b[0;32m     96\u001b[0m         predictions[sequences[i]] \u001b[39m=\u001b[39m FLOAT_MAX\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\Thesis\\previous_work\\spotlight_ext\\spotlight\\sequence\\implicit.py:326\u001b[0m, in \u001b[0;36mImplicitSequenceModel.predict\u001b[1;34m(self, sequences, item_ids)\u001b[0m\n\u001b[0;32m    323\u001b[0m sequence_var \u001b[39m=\u001b[39m gpu(sequences, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_cuda)\n\u001b[0;32m    324\u001b[0m item_var \u001b[39m=\u001b[39m gpu(item_ids, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_cuda)\n\u001b[1;32m--> 326\u001b[0m _, sequence_representations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_net\u001b[39m.\u001b[39;49muser_representation(sequence_var)\n\u001b[0;32m    327\u001b[0m size \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(item_var),) \u001b[39m+\u001b[39m sequence_representations\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m:]\n\u001b[0;32m    328\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_net(sequence_representations\u001b[39m.\u001b[39mexpand(\u001b[39m*\u001b[39msize),\n\u001b[0;32m    329\u001b[0m                 item_var)\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\OneDrive\\Bureau\\ULB\\MA2\\MEMO-F524\\Thesis\\previous_work\\spotlight_ext\\spotlight\\sequence\\representations.py:224\u001b[0m, in \u001b[0;36mLSTMNet.user_representation\u001b[1;34m(self, item_sequences)\u001b[0m\n\u001b[0;32m    219\u001b[0m sequence_embeddings \u001b[39m=\u001b[39m (F\u001b[39m.\u001b[39mpad(sequence_embeddings,\n\u001b[0;32m    220\u001b[0m                              (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m))\n\u001b[0;32m    221\u001b[0m                        \u001b[39m.\u001b[39msqueeze(\u001b[39m3\u001b[39m))\n\u001b[0;32m    222\u001b[0m sequence_embeddings \u001b[39m=\u001b[39m sequence_embeddings\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m--> 224\u001b[0m user_representations, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(sequence_embeddings)\n\u001b[0;32m    225\u001b[0m user_representations \u001b[39m=\u001b[39m user_representations\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m    227\u001b[0m \u001b[39mreturn\u001b[39;00m user_representations[:, :, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], user_representations[:, :, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    811\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    813\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    815\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    816\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.evaluation import sequence_mrr_score\n",
    "\n",
    "model = ImplicitSequenceModel(\n",
    "    batch_size=256,\n",
    "    embedding_dim=32,\n",
    "    l2=0.0,\n",
    "    learning_rate=0.05,\n",
    "    n_iter=11,\n",
    "    representation='lstm',\n",
    "    loss='adaptive_hinge',\n",
    "#     use_cuda=torch.cuda.is_available(),\n",
    "    random_state=np.random.RandomState(2020)\n",
    ")\n",
    "model.fit(train)\n",
    "\n",
    "mrr = sequence_mrr_score(model, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofile = 'entire_model_1m_20interactions.pt'\n",
    "torch.save(model, os.path.join(models_path, ofile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## or load a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofile = 'entire_model_1m.pt'\n",
    "\n",
    "model = torch.load(os.path.join(models_path, ofile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_interacted = test.sequences[test.user_ids==2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item to predict: 127\n"
     ]
    }
   ],
   "source": [
    "predictions = -model.predict(items_interacted[:-1])\n",
    "print(f'Item to predict: {items_interacted[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "769"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "next_item_pos = st.rankdata(predictions, method='ordinal')[items_interacted[-1]]\n",
    "next_item_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, -0.9794686)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(enumerate(predictions), key=lambda x: x[1])[int(next_item_pos) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal convolutions for sequence-based recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'embedding_dim': 128,\n",
    "    'kernel_width': 5,\n",
    "    'dilation': [1, 2, 4],\n",
    "    'num_layers': 5,\n",
    "    'nonlinearity': 'relu',\n",
    "    'residual': True,\n",
    "    'loss': 'adaptive_hinge',\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 0.01,\n",
    "    'l2': 0,\n",
    "    'n_iter': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.sequence.representations import CNNNet\n",
    "from spotlight.evaluation import sequence_mrr_score\n",
    "\n",
    "\n",
    "net = CNNNet(train.num_items,\n",
    "             embedding_dim=hyperparameters['embedding_dim'],\n",
    "             kernel_width=hyperparameters['kernel_width'],\n",
    "             dilation=hyperparameters['dilation'],\n",
    "             num_layers=hyperparameters['num_layers'],\n",
    "             nonlinearity=hyperparameters['nonlinearity'],\n",
    "             residual_connections=hyperparameters['residual'])\n",
    "\n",
    "model = ImplicitSequenceModel(loss=hyperparameters['loss'],\n",
    "                              representation=net,\n",
    "                              batch_size=hyperparameters['batch_size'],\n",
    "                              learning_rate=hyperparameters['learning_rate'],\n",
    "                              l2=hyperparameters['l2'],\n",
    "                              n_iter=hyperparameters['n_iter'],\n",
    "                              use_cuda=torch.cuda.is_available(),\n",
    "#                               random_state=random_state\n",
    "                             )\n",
    "\n",
    "model.fit(train)\n",
    "\n",
    "test_mrr = sequence_mrr_score(model, test)\n",
    "# val_mrr = sequence_mrr_score(model, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MRR [0.01612903 0.0060241  0.00290698 0.00218818 0.05263158 0.00220751\n",
      " 0.01052632 0.0052356  0.03333333 0.00108696 0.05       0.33333333\n",
      " 0.00411523 0.00108696 0.00116009 0.01754386 0.00115875 0.00174216\n",
      " 1.         0.00273224 0.00103199 0.01149425 0.01470588 0.00150376\n",
      " 0.00115741 0.00134771 0.00526316 0.00189036 0.00181488 0.00409836\n",
      " 0.00537634 0.00101833 0.01075269 0.00168067 1.         0.00232019\n",
      " 0.00315457 0.01020408 0.00111235 0.00290698 0.125      0.00584795\n",
      " 0.01149425 0.00970874 0.0013624  0.00161812 0.00175439 0.00308642\n",
      " 0.00275482 1.         0.00137931 0.00423729 0.16666667 0.00187266\n",
      " 0.00138122 0.00154799 0.00485437 0.00121951 0.00127877 0.125\n",
      " 0.00117647 0.00507614 0.00564972 1.         0.01960784 0.00169205\n",
      " 0.00172414 0.00198807 0.01282051 0.0010989  0.00555556 0.00116686\n",
      " 0.00247525 0.00689655 0.01492537 0.0037037  0.01315789 0.001321\n",
      " 0.00143472 0.001287   0.00662252 0.00168919 0.00280899 0.00298507\n",
      " 0.004      0.03333333 0.00204499 0.0013245  0.00181818 0.00111982\n",
      " 0.01470588 0.00813008 0.00106724 0.00294118 0.02439024 0.00229358\n",
      " 0.00122549 0.00116144 0.00104384 0.00151976 0.01923077 0.00168634\n",
      " 0.00122699 0.00358423 0.05       0.00327869 0.00159236 0.00160514\n",
      " 0.00108342 0.0020202  0.01234568 0.00487805 0.03846154 0.00584795\n",
      " 0.00106045 0.00245098 0.00230415 0.00645161 0.00296736 0.00108578\n",
      " 0.00348432 0.0011919  0.00595238 0.5        0.05882353 0.00198807\n",
      " 0.00383142 0.04       0.02       0.00290698 0.0022779  0.04166667\n",
      " 0.00294118 0.01315789 0.01123596 0.00357143 0.00296736 0.00139665\n",
      " 0.00163399 0.00139276 0.02222222 0.00107875 0.00344828 0.00176367\n",
      " 0.00854701 0.00310559 0.00146628 0.00222222 0.0014556  0.00196078\n",
      " 0.00309598 0.00460829 0.00341297 0.0013089  0.00191205 0.00675676\n",
      " 0.00234192 0.01010101 0.00201207 0.00234742 0.00144928 0.00371747\n",
      " 0.00392157 0.00657895 0.0022779  0.00332226 0.0014881  0.00324675\n",
      " 0.0044843  0.00140056 0.00121507 0.00411523 0.00438596 0.0015083\n",
      " 0.00233645 0.003663   0.00149701 0.00138504 0.01075269 0.00132275\n",
      " 0.005      0.03703704 0.00105597 0.003003   0.00132979 0.00211864\n",
      " 0.00531915 0.0041841  0.00361011 0.00114679 0.00179856 0.00423729\n",
      " 0.00124069 0.00132626 0.00558659 0.00578035 0.00209205 0.00132802\n",
      " 0.09090909 0.00137174 0.0010929  0.00406504 0.00218341 0.03571429\n",
      " 0.00100908 0.00146628 0.00138696 0.0034965  0.00225734 0.01234568\n",
      " 0.00105932 0.003663   0.00173913 0.00215054 0.00209205 0.00201613\n",
      " 0.00478469 0.0014556  0.00170358 0.00114025 0.00306748 0.00104712\n",
      " 0.00299401 0.00235849 0.00294118 0.0012837 ]\n"
     ]
    }
   ],
   "source": [
    "print(f'Test MRR {test_mrr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute-force example on Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model\n",
    "ofile = 'entire_model_1m.pt'\n",
    "model = torch.load(os.path.join(models_path, ofile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize input parameters\n",
    "k = 10 #nb of recommended items\n",
    "no_interactions = 5 #the number of interactions to consider\n",
    "user_id = 8 #the user for whom recommendations are generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The SelectedInteractions class is defined in the code to represent and manage information related to a set of selected interactions\n",
    "class SelectedInteractions:\n",
    "    def __init__(self, p=-1, i=None):\n",
    "        pos = p\n",
    "        interactions = i\n",
    "        \n",
    "    def __str__(self): \n",
    "        items_order = [(n[0], n[1].detach().numpy().flatten()[0]) if isinstance(n[1], torch.Tensor) else (n[0], n[1]) for n in self.items_order]\n",
    "            \n",
    "        return (f'Found in iter {self.counter_found_best} with score/in pos {self.score} with interactions {self.interactions}\\n'\n",
    "                f'10-best proposed items {items_order}')\n",
    "    \n",
    "    score = 0 #The score associated with the selected interactions.\n",
    "    pos = -1 #The position of the selected item.\n",
    "    interactions = [] #The interactions selected.\n",
    "    items_order = [] #A list of items along with their scores, sorted in descending order.\n",
    "    counter_found_best = -1 #The iteration number when the best interactions were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the following interactions [227 501 492 454 463] for user 8 the next most 10 possible itemsto interact with are [510, 438, 284, 40, 281, 60, 539, 313, 325, 439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose one of the above next interacted items that should become less candidate:  325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pos of selected item 325 is 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items_interacted = test.sequences[test.user_ids==user_id][0]\n",
    "predictions = -model.predict(items_interacted[:no_interactions])\n",
    "\n",
    "print(f'Given the following interactions {items_interacted[:no_interactions]} for user {user_id} the next most {k} possible items'\n",
    "      f' to interact with are {list(predictions.argsort()[:k])}')\n",
    "cand = input('Choose one of the above next interacted items that should become less candidate: ')\n",
    "try:\n",
    "    cand = int(cand)\n",
    "except ValueError:\n",
    "    print(\"That's not an int!\")\n",
    "\n",
    "print(f'Current pos of selected item {cand} is {st.rankdata(predictions, method=\"ordinal\")[cand]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found in iter 2 with score/in pos 180 with interactions (501,)\n",
      "10-best proposed items [(568, 0.0023526023), (306, 0.002310076), (39, 0.002220974), (892, 0.0020520852), (326, 0.0019568491), (1119, 0.0018849755), (466, 0.0017736341), (86, 0.0017688118), (147, 0.0015101795), (918, 0.0014980054)] \n",
      "Total iterations: 326\n"
     ]
    }
   ],
   "source": [
    "#A loop iterates over the permutations of the user's past interactions. \n",
    "# For each permutation, it calculates predictions using the model, applies softmax, and ranks the items based on predictions. It tracks the best interactions and their rankings.\n",
    "from itertools import permutations\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "counter = 1\n",
    "best_inter = SelectedInteractions()\n",
    "\n",
    "for l in range(1, no_interactions + 1):\n",
    "    perm = permutations(items_interacted[:no_interactions], l)    \n",
    "\n",
    "    for i in list(perm):        \n",
    "        preds = model.predict(i) \n",
    "        tensor = torch.from_numpy(preds).float()\n",
    "        preds = F.softmax(tensor, dim=0)        \n",
    "        item_pos = st.rankdata(-preds, method='ordinal')[cand]\n",
    "        if item_pos > best_inter.score:\n",
    "            best_inter.score = item_pos\n",
    "            best_inter.interactions = i\n",
    "            best_inter.items_order = sorted(enumerate(preds), key=lambda x: x[1], reverse=True)[:k]\n",
    "            best_inter.counter_found_best = counter\n",
    "\n",
    "        counter += 1\n",
    "    \n",
    "print(best_inter, f'\\nTotal iterations: {counter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status: optimal\n",
      "optimal value 1.0\n",
      "optimal var 1.0 1.570086213240983e-22\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "\n",
    "# Create two scalar optimization variables.\n",
    "x = cp.Variable()\n",
    "y = cp.Variable()\n",
    "\n",
    "# Create two constraints.\n",
    "constraints = [x + y == 1,\n",
    "               x - y >= 1]\n",
    "\n",
    "# Form objective.\n",
    "obj = cp.Minimize((x - y)**2)\n",
    "\n",
    "# Form and solve problem.\n",
    "prob = cp.Problem(obj, constraints)\n",
    "prob.solve()  # Returns the optimal value.\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)\n",
    "print(\"optimal var\", x.value, y.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value 4.141338603672535\n",
      "Optimal var\n",
      "[-4.95922264e-21  6.07571976e-21  1.34643668e-01  1.24976681e-01\n",
      " -4.57130806e-21]\n"
     ]
    }
   ],
   "source": [
    "# Solves a bounded least-squares problem.\n",
    "\n",
    "import cvxpy as cp\n",
    "import numpy\n",
    "\n",
    "# Problem data.\n",
    "m = 10\n",
    "n = 5\n",
    "numpy.random.seed(1)\n",
    "A = numpy.random.randn(m, n)\n",
    "b = numpy.random.randn(m)\n",
    "\n",
    "# Construct the problem.\n",
    "x = cp.Variable(n)\n",
    "objective = cp.Minimize(cp.sum_squares(A @ x - b))\n",
    "constraints = [0 <= x, x <= 1]\n",
    "prob = cp.Problem(objective, constraints)\n",
    "\n",
    "print(\"Optimal value\", prob.solve())\n",
    "print(\"Optimal var\")\n",
    "print(x.value) # A numpy ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['item_id', 'rating', 'timestamp', 'user_id']>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "filename = \"~/spotlight_data/movielens/v0.2.0/movielens_movielens_100K.hdf5\"\n",
    "\n",
    "with h5py.File(os.path.expanduser(filename), \"r\") as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    a_group_key = list(f.keys())[0]\n",
    "\n",
    "    # Get the data\n",
    "    data = list(f[a_group_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"jupyter nbconvert misc.ipynb --to slides\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook misc.ipynb to pdf\n",
      "[NbConvertApp] Writing 63994 bytes to notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 64232 bytes to misc.pdf\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert misc.ipynb --to pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vkaff/gits/CFExplainability/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive.ics.uci.edu\t    matrix_factorization_for_rec_expl.ipynb\n",
      "brute_force_rec_expl.ipynb  misc.ipynb\n",
      "budget_strategies.ipynb     misc.pdf\n",
      "cvxpy_usage_rec_expl.ipynb  pooling_repr_for_rec_expl.ipynb\n",
      "Dice_test.ipynb\t\t    README.md\n",
      "fair_rec\t\t    score_preds.ipynb\n",
      "helpers.ipynb\t\t    torch_rec\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code was used to debug the \"why-not\" explainability mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import scipy.stats as st\n",
    "# get currently working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# load functions from other notebooks\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb').replace(\"\\\\\", \"/\")\n",
    "%run $helpers_file\n",
    "\n",
    "\n",
    "FLOAT_MAX = np.finfo(np.float32).max\n",
    "\n",
    "\n",
    "target_pos = 5\n",
    "user_id = 1001\n",
    "top_k = 10\n",
    "brute_force_specific_cfs = None\n",
    "i = 0\n",
    "\n",
    "# while brute_force_specific_cfs == [] or brute_force_specific_cfs is None:\n",
    "#     i += 1\n",
    "#     brute_force_specific_cfs = _find_specific_cfs_(test, pretrained_models['lstm'], get_backend_strategy('brute_force'), 7, False, jaccard_sims_matrix, i, 100000, 10)\n",
    "\n",
    "brute_force_specific_cfs = _find_specific_cfs_(test, pretrained_models['lstm'], get_backend_strategy('brute_force'), target_pos, False, jaccard_sims_matrix, user_id, 1048576, top_k)\n",
    "\n",
    "user_sequences = test.sequences[test.user_ids == user_id]\n",
    "user_sequences = [sequence for sequence in user_sequences if all(value > 0 for value in sequence)]\n",
    "\n",
    "original_interactions = user_sequences[0]\n",
    "print(\"original_interactions\", original_interactions)\n",
    "\n",
    "best_interactions = brute_force_specific_cfs[0].interactions['best']\n",
    "print(\"best_interactions\", best_interactions)\n",
    "\n",
    "items_removed = np.setdiff1d(original_interactions, best_interactions)\n",
    "print(\"items_removed\", items_removed)\n",
    "\n",
    "\n",
    "original_interactions = list(original_interactions)\n",
    "predictions = -pretrained_models['lstm'].predict(original_interactions)\n",
    "predictions[original_interactions] = FLOAT_MAX\n",
    "predictions[0] = FLOAT_MAX\n",
    "target_item = predictions.argsort()[min(top_k, target_pos)]\n",
    "print(\"target_item\", target_item)\n",
    "\n",
    "print(\"===========================\")\n",
    "original_interaction_test = [2216, 1678, 509, 3016, 929, 801, 881, 2914, 944, 704, 2284, 252, 2902, 1427, 884, 1437, 2640, 1880, 2451, 271]\n",
    "\n",
    "predictions_test = -pretrained_models['lstm'].predict(original_interaction_test)\n",
    "predictions_test[original_interaction_test] = FLOAT_MAX\n",
    "predictions_test[0] = FLOAT_MAX\n",
    "target_item_test = predictions_test.argsort()[min(top_k, target_pos)]\n",
    "# rk_data = st.rankdata(-predictions_test, method='ordinal')\n",
    "print(\"target_item\", target_item)\n",
    "print(\"target_item_test\", target_item_test)\n",
    "print(\"original_interactions\", original_interactions)\n",
    "print(\"original_interaction_test\", original_interaction_test)\n",
    "print(\"============================\")\n",
    "\n",
    "predictions_reverse = -pretrained_models['lstm'].predict(best_interactions)\n",
    "predictions_reverse[best_interactions] = FLOAT_MAX\n",
    "pos_target_item_reverse = np.where(predictions_reverse.argsort() == target_item)[0][0]\n",
    "print(\"position target item in reverse mode\", pos_target_item_reverse)\n",
    "\n",
    "worst_jaccard_sample = find_sample_with_jaccard(target_item, best_interactions, jaccard_sims_matrix, 20, worst_items = True)\n",
    "print(\"worst_jacc\", worst_jaccard_sample)\n",
    "\n",
    "jaccard_sample = find_sample_with_jaccard(target_item, best_interactions, jaccard_sims_matrix, 20, worst_items = False)\n",
    "print(\"jacc\", jaccard_sample)\n",
    "rs_sample = find_sample_with_recommender(target_item, best_interactions, pretrained_models['lstm'], 20)\n",
    "if set(items_removed) <= set(jaccard_sample):\n",
    "    print(\"jaccard_sample\", jaccard_sample)\n",
    "    search_info = retrieve_solutions_specific_sequence(user_id, test, pretrained_models['lstm'], get_backend_strategy('brute_force'), 100000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, jaccard_sample)\n",
    "\n",
    "elif set(items_removed) <= set(rs_sample):\n",
    "    print(\"rs_sample\", rs_sample)\n",
    "    search_info = retrieve_solutions_specific_sequence(user_id, test, pretrained_models['lstm'], get_backend_strategy('brute_force'), 100000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, rs_sample)\n",
    "else:\n",
    "    worst_jaccard_sample[:len(items_removed)] = items_removed[:len(items_removed)]\n",
    "    print(\"modified_sample\", worst_jaccard_sample)\n",
    "    search_info = retrieve_solutions_specific_sequence(user_id, test, pretrained_models['lstm'], get_backend_strategy('brute_force'), 1048576, top_k, True, jaccard_sims_matrix, best_interactions, target_item, worst_jaccard_sample)\n",
    "\n",
    "print(\"search_info\", search_info[0].interactions['best'])\n",
    "\n",
    "items_removed2 = np.setdiff1d(search_info[0].interactions['best'], best_interactions)\n",
    "print(\"items_removed\", items_removed2)\n",
    "\n",
    "result2 = dict.fromkeys([pos_target_item_reverse])\n",
    "result2[pos_target_item_reverse] = []\n",
    "result2[pos_target_item_reverse].extend(search_info)\n",
    "\n",
    "cnt2 = defaultdict(dict)\n",
    "no_target_achieved_cases2 = defaultdict(list)\n",
    "\n",
    "\n",
    "cnt2, no_target_achieved_cases2 = convert_res_to_lists(result2, cnt2, no_target_achieved_cases2, \"random_0\", True)\n",
    "print(cnt2)\n",
    "print(no_target_achieved_cases2)\n",
    "\n",
    "result = dict.fromkeys([target_pos])\n",
    "result[target_pos] = []\n",
    "result[target_pos].extend(brute_force_specific_cfs)\n",
    "\n",
    "cnt = defaultdict(dict)\n",
    "no_target_achieved_cases = defaultdict(list)\n",
    "\n",
    "target_item = 0\n",
    "\n",
    "cnt, no_target_achieved_cases = convert_res_to_lists(result, cnt, no_target_achieved_cases, \"random_0\", False)\n",
    "print(cnt)\n",
    "print(no_target_achieved_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# get currently working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# load functions from other notebooks\n",
    "helpers_file = os.path.join(base_dir, 'helpers.ipynb').replace(\"\\\\\", \"/\")\n",
    "%run $helpers_file\n",
    "\n",
    "\n",
    "FLOAT_MAX = np.finfo(np.float32).max\n",
    "\n",
    "target_pos = 1\n",
    "user_id = 8\n",
    "top_k = 10\n",
    "combo_specific_cfs = None\n",
    "i = 0\n",
    "\n",
    "while combo_specific_cfs == [] or combo_specific_cfs is None:\n",
    "    i += 1\n",
    "    combo_specific_cfs = _find_specific_cfs_(test, pretrained_models['lstm'], get_backend_strategy('combo'), target_pos, False, jaccard_sims_matrix, i, 1000, 10, alpha=0.5, normalization='default')\n",
    "\n",
    "# combo_specific_cfs = _find_specific_cfs_(test, pretrained_models['lstm'], get_backend_strategy('combo'), target_pos, False, jaccard_sims_matrix, user_id, 1000, top_k)\n",
    "print(\"user_id = \", i)\n",
    "user_sequences = test.sequences[test.user_ids == user_id]\n",
    "user_sequences = [sequence for sequence in user_sequences if all(value > 0 for value in sequence)]\n",
    "\n",
    "original_interactions = user_sequences[0]\n",
    "print(\"original_interactions\", original_interactions)\n",
    "\n",
    "best_interactions = combo_specific_cfs[0].interactions['best']\n",
    "print(\"best_interactions\", best_interactions)\n",
    "\n",
    "items_removed = np.setdiff1d(original_interactions, best_interactions)\n",
    "print(\"items_removed\", items_removed)\n",
    "\n",
    "predictions = -pretrained_models['lstm'].predict(original_interactions)\n",
    "predictions[original_interactions] = FLOAT_MAX\n",
    "target_item = predictions.argsort()[min(top_k, target_pos)]\n",
    "print(\"target_item\", target_item)\n",
    "\n",
    "predictions_reverse = -pretrained_models['lstm'].predict(best_interactions)\n",
    "predictions_reverse[best_interactions] = FLOAT_MAX\n",
    "pos_target_item_reverse = np.where(predictions_reverse.argsort() == target_item)[0][0]\n",
    "print(\"position target item in reverse mode\", pos_target_item_reverse)\n",
    "\n",
    "worst_jaccard_sample = find_sample_with_jaccard(target_item, best_interactions, jaccard_sims_matrix, 20, worst_items = True)\n",
    "print(\"worst_jacc\", worst_jaccard_sample)\n",
    "\n",
    "jaccard_sample = find_sample_with_jaccard(target_item, best_interactions, jaccard_sims_matrix, 20, worst_items = True)\n",
    "print(\"jacc\", jaccard_sample)\n",
    "rs_sample = find_sample_with_recommender(target_item, best_interactions, pretrained_models['lstm'], 20)\n",
    "if set(items_removed) <= set(jaccard_sample):\n",
    "    print(\"jaccard_sample\", jaccard_sample)\n",
    "    search_info = retrieve_solutions_specific_sequence(i, test, pretrained_models['lstm'], get_backend_strategy('combo'), 1000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, jaccard_sample)\n",
    "\n",
    "elif set(items_removed) <= set(rs_sample):\n",
    "    print(\"rs_sample\", rs_sample)\n",
    "    search_info = retrieve_solutions_specific_sequence(i, test, pretrained_models['lstm'], get_backend_strategy('combo'), 1000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, rs_sample)\n",
    "else:\n",
    "    worst_jaccard_sample[:len(items_removed)] = items_removed[:len(items_removed)]\n",
    "    print(\"modified_sample\", worst_jaccard_sample)\n",
    "    search_info = retrieve_solutions_specific_sequence(i, test, pretrained_models['lstm'], get_backend_strategy('combo'), 1000, top_k, True, jaccard_sims_matrix, best_interactions, target_item, worst_jaccard_sample)\n",
    "\n",
    "print(\"search_info\", search_info[0].interactions['best'])\n",
    "\n",
    "result2 = dict.fromkeys([pos_target_item_reverse])\n",
    "result2[pos_target_item_reverse] = []\n",
    "result2[pos_target_item_reverse].extend(search_info)\n",
    "\n",
    "cnt2 = defaultdict(dict)\n",
    "no_target_achieved_cases2 = defaultdict(list)\n",
    "\n",
    "\n",
    "cnt2, no_target_achieved_cases2 = convert_res_to_lists(result2, cnt2, no_target_achieved_cases2, \"random_0\", True)\n",
    "print(cnt2)\n",
    "print(no_target_achieved_cases2)\n",
    "\n",
    "result = dict.fromkeys([target_pos])\n",
    "result[target_pos] = []\n",
    "result[target_pos].extend(combo_specific_cfs)\n",
    "\n",
    "cnt = defaultdict(dict)\n",
    "no_target_achieved_cases = defaultdict(list)\n",
    "\n",
    "target_item = 0\n",
    "\n",
    "cnt, no_target_achieved_cases = convert_res_to_lists(result, cnt, no_target_achieved_cases, \"random_0\", False)\n",
    "print(cnt)\n",
    "print(no_target_achieved_cases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
